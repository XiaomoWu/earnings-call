{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: /home/yu/OneDrive/CC\n",
      "DATA_DIR: /home/yu/OneDrive/CC/data\n",
      "\n",
      "2 GPUs found:\n",
      "    GeForce RTX 2080 Ti (cuda0)\n",
      "    GeForce RTX 2080 Ti (cuda1)\n",
      "\n",
      "GPU memory:\n",
      "GPU 0:  0.00/ 10.76 (GB)\n",
      "GPU 1:  0.00/ 10.76 (GB)\n",
      "\n",
      "CPU count (physical): 16\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import comet_ml\n",
    "import datatable as dt\n",
    "import gc\n",
    "import json\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import pyarrow.feather as feather\n",
    "import re\n",
    "import spacy\n",
    "# import sentence_transformers\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from argparse import Namespace\n",
    "from collections import OrderedDict, defaultdict\n",
    "from datatable import f, update, by\n",
    "from itertools import chain\n",
    "from spacy.lang.en import English\n",
    "from scipy.sparse import coo_matrix\n",
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from transformers import BertModel, BertTokenizer, BertTokenizerFast, GPT2Model, GPT2Tokenizer, RobertaTokenizer, RobertaModel, LongformerModel, LongformerTokenizerFast\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# working directory\n",
    "ROOT_DIR = '/home/yu/OneDrive/CC'\n",
    "DATA_DIR = f'{ROOT_DIR}/data'\n",
    "WRDS_DOWNLOAD_DIR = f'{DATA_DIR}/WRDS-download'\n",
    "print(f'ROOT_DIR: {ROOT_DIR}')\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "\n",
    "# set random seed\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42);\n",
    "torch.backends.cudnn.deterministic = False;\n",
    "torch.backends.cudnn.benchmark = True;\n",
    "\n",
    "# set device 'cuda' or 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    n_cuda = torch.cuda.device_count();\n",
    "\n",
    "    def log_gpu_memory(verbose=False):\n",
    "        torch.cuda.empty_cache()\n",
    "        if verbose:\n",
    "            for _ in range(n_cuda):\n",
    "                print(f'GPU {_}:')\n",
    "                print(f'{torch.cuda.memory_summary(_, abbreviated=True)}')\n",
    "        else:\n",
    "            for _ in range(n_cuda):\n",
    "                memory_total = torch.cuda.get_device_properties(_).total_memory/(1024**3)\n",
    "                memory_allocated = torch.cuda.memory_allocated(_)/(1024**3)\n",
    "                print(f'GPU {_}: {memory_allocated: .2f}/{memory_total: .2f} (GB)')\n",
    "\n",
    "    print(f'\\n{n_cuda} GPUs found:');\n",
    "    for _ in range(n_cuda):\n",
    "        globals()[f'cuda{_}'] = torch.device(f'cuda:{_}');\n",
    "        print(f'    {torch.cuda.get_device_name(_)} (cuda{_})');\n",
    "        \n",
    "    print('\\nGPU memory:');\n",
    "    log_gpu_memory();\n",
    "else:\n",
    "    print('GPU NOT enabled');\n",
    "    \n",
    "cpu = torch.device('cpu');\n",
    "n_cpu = int(mp.cpu_count()/2);\n",
    "\n",
    "print(f'\\nCPU count (physical): {n_cpu}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: refresh cuda memory\n",
    "def refresh_cuda_memory():\n",
    "    \"\"\"\n",
    "    Re-allocate all cuda memory to help alleviate fragmentation\n",
    "    \"\"\"\n",
    "    # Run a full garbage collect first so any dangling tensors are released\n",
    "    gc.collect()\n",
    "\n",
    "    # Then move all tensors to the CPU\n",
    "    for obj in gc.get_objects():\n",
    "        if isinstance(obj, torch.Tensor) and obj.device!=torch.device('cpu'):\n",
    "            obj.data = torch.empty(0)\n",
    "            if isinstance(obj, torch.nn.Parameter) and obj.grad is not None:\n",
    "                obj.grad.data = torch.empty(0)\n",
    "\n",
    "    # Now empty the cache to flush the allocator\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "def elapsed_time(start,end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(f'{int(hours)}h {int(minutes)}min {seconds:.1f}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The encoding part is in \"task-longformer-component-encode.py\".\n",
    "\n",
    "> After Feb 5, 2021, we no longer merge/filter the embeddings in \"C-preEncode.ipynb\". Instead, we'll put it in the Dataset module in \"C-model\".\n",
    "\n",
    "> After Mar 1, 2021, pre-embedding of every transcript will be save into an independent file on disk, and will be read as needed in \"C-model\". (Like reading individual images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "- Merge \"rank0\" and \"rank1\"\n",
    "- Save pre-embedding of every transript into a seperate file.\n",
    "\n",
    "Note:\n",
    "- Save embeddings as \"numpy.ndarray\" instead of \"Tensor\" because the ndarray is MUCH smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-03 04:18:30 PM, Loading \"preembeddings_longformer_rank0.pt\"...\n",
      "2021-03-03 04:19:01 PM, Loading \"preembeddings_longformer_rank1.pt\"...\n",
      "Merging completes!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def load_preembeddings(preembedding_name):\n",
    "        \n",
    "    # find the embedding files\n",
    "    emb_paths = [path for path in os.listdir('data/Embeddings')\n",
    "                 if re.search(f'{preembedding_name}_rank', path)]\n",
    "    emb_paths.sort()\n",
    "    assert len(emb_paths)==2, \"Expect two files: rank0 and rank1\"\n",
    "\n",
    "    # load the embedding files\n",
    "    print(f'{datetime.now().strftime(\"%Y-%m-%d %I:%M:%S %p\")}, Loading \"{emb_paths[0]}\"...')\n",
    "    emb0 = torch.load(f\"{DATA_DIR}/Embeddings/{emb_paths[0]}\")\n",
    "    print(f'{datetime.now().strftime(\"%Y-%m-%d %I:%M:%S %p\")}, Loading \"{emb_paths[1]}\"...')\n",
    "    emb1 = torch.load(f\"{DATA_DIR}/Embeddings/{emb_paths[1]}\")\n",
    "\n",
    "    # merge two ranks into one (update emb0 with emb1)\n",
    "    for tid, cid_emb in emb1.items():\n",
    "        for cid, emb in cid_emb.items():\n",
    "            emb0[tid].update({cid:emb})\n",
    "    print('Merging completes!')\n",
    "\n",
    "    # write embedding to globals()\n",
    "    return emb0\n",
    "\n",
    "emb = load_preembeddings('preembeddings_longformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f3a85419d84da4b94628488e7b754e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "svdir = '/home/yu/OneDrive/CC/data/Embeddings/longformer'\n",
    "for i, (tid, components) in enumerate(tqdm(emb.items())):\n",
    "    \n",
    "    for cid in components:\n",
    "        if not isinstance(components[cid]['embedding'], np.ndarray):\n",
    "            components[cid]['embedding'] = components[cid]['embedding'].numpy()\n",
    "    \n",
    "    torch.save(components, f'{svdir}/{tid}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# finBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This section is just an **interactive, non-parallel, test** version for finBERT encoding. For the final version, please refer to `task-finBERT-encode.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"dt_sents_sp500.feather\" (1.0 GB) loaded as \"dt_sents\" (8s)\n",
      "N sentences: 19913851\n",
      "N transcriptid: 37630\n"
     ]
    }
   ],
   "source": [
    "# load raw text\n",
    "ld('dt_sents_sp500', ldname='dt_sents', force=True)\n",
    "print(f'N sentences: {dt_sents.nrows}')\n",
    "print(f'N transcriptid: {len(set(dt_sents[:,f.transcriptid].to_list()[0]))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: refresh cuda memory\n",
    "def refresh_cuda_memory():\n",
    "    \"\"\"\n",
    "    Re-allocate all cuda memory to help alleviate fragmentation\n",
    "    \"\"\"\n",
    "    # Run a full garbage collect first so any dangling tensors are released\n",
    "    gc.collect()\n",
    "\n",
    "    # Then move all tensors to the CPU\n",
    "    for obj in gc.get_objects():\n",
    "        if isinstance(obj, torch.Tensor) and obj.device!=torch.device('cpu'):\n",
    "            obj.data = torch.empty(0)\n",
    "            if isinstance(obj, torch.nn.Parameter) and obj.grad is not None:\n",
    "                obj.grad.data = torch.empty(0)\n",
    "\n",
    "    # Now empty the cache to flush the allocator\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# helper: print elapsed time (given start and end)\n",
    "def elapsed_time(start, end):\n",
    "    hours, rem = divmod(end-start, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "    print(f'{int(hours)}h {int(minutes)}min {seconds:.1f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ld('sents_sp500', ldname='sents', force=True)\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('./data/finBERT', return_dict=True)\n",
    "model.eval()\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# code WITHOUT batch\n",
    "# --------------------------\n",
    "\n",
    "output = {}\n",
    "\n",
    "for tid, cid, sid, text in tqdm(sents[:200]):\n",
    "    # print(text)\n",
    "    tokens = tokenizer(text,return_tensors='pt', truncation=True, max_length=384)\n",
    "    tokens = tokens.to('cuda')\n",
    "    # print(tokens.input_ids)\n",
    "    \n",
    "    # create mask\n",
    "    mask = tokens.attention_mask[:,:-1].float() # (B, S)\n",
    "    mask = F.softmax(mask, dim=-1).unsqueeze(-1).float() # (B, S, 1)\n",
    "    \n",
    "    embedding = model(**tokens).last_hidden_state[:,:-1,:].transpose(-1, 1) # (B, E, S)\n",
    "    \n",
    "    embedding_pool = torch.bmm(embedding, mask).squeeze().detach() # (B, E)\n",
    "    \n",
    "    output[f'{tid}_{sid}'] = embedding_pool\n",
    "    \n",
    "output['108_83']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# compute embedding WITH batch\n",
    "# ----------------------------\n",
    "\n",
    "sentence_ids = ciq_components_sentencized['sentence_id']\n",
    "texts = ciq_components_sentencized['text']\n",
    "\n",
    "batch = 1\n",
    "output = {}\n",
    "n_batches = int(len(texts)/batch)+1\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(f'{DATA_DIR}/finBERT', return_dict=True)\n",
    "model.to('cuda')\n",
    "\n",
    "for batch_idx in tqdm(range(n_batches)):\n",
    "    if batch_idx>=2:\n",
    "        break\n",
    "                      \n",
    "    # For every 1/10 of data, \n",
    "    # - release cuda memory\n",
    "    # - save results\n",
    "    # - empty output\n",
    "    # if batch_idx<=209860:\n",
    "    #     continue\n",
    "        \n",
    "    if (batch_idx%(n_batches//100)==0) or (batch_idx==(n_batches-1)):\n",
    "\n",
    "        refresh_cuda_memory()\n",
    "\n",
    "        # create model and tokenizer\n",
    "        tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "        model = BertModel.from_pretrained('data/finBERT', return_dict=True)\n",
    "        model = torch.nn.DataParallel(model)\n",
    "        model.to('cuda')\n",
    "\n",
    "        sv_name = f'preembeddings_finbert_nocls_{batch_idx}.pt'\n",
    "        print(f'Saving to {sv_name}')\n",
    "        torch.save(output, f'data/Embeddings/{sv_name}')\n",
    "        output = {}\n",
    "\n",
    "    sids = sentence_ids[batch_idx*batch:(batch_idx+1)*batch].to_list()\n",
    "    text = texts[batch_idx*batch:(batch_idx+1)*batch].to_list()\n",
    "\n",
    "    # tokenize\n",
    "    tokens = tokenizer(text,return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    tokens = tokens.to('cuda')\n",
    "    \n",
    "    # get mask\n",
    "    mask = tokens.attention_mask.float() # (B, S)\n",
    "    valid_seq_len = torch.sum(mask==1, dim=1) # (B,)\n",
    "\n",
    "    # Option 1:\n",
    "    # - the 1st and last token are special token, set to zero\n",
    "    # - devide mask by (seq_len-2)\n",
    "    # for i, l in enumerate(valid_seq_len):\n",
    "    #     mask[i, [0, l-1]] = 0\n",
    "    #     mask[i] /= (l-2)\n",
    "        \n",
    "    # Option 2:\n",
    "    # - all tokens (including [CLS] and [EOS]) are preserved\n",
    "    # - devide mask by (seq_len)\n",
    "    for i, l in enumerate(valid_seq_len):\n",
    "        mask[i] /= l\n",
    "    \n",
    "    mask = mask.unsqueeze(-1) # (B, S, 1)\n",
    "\n",
    "    # compute embedding\n",
    "    embedding = model(**tokens).last_hidden_state.transpose(-1, 1) # (B, E, S)\n",
    "    embedding_pool = torch.bmm(embedding, mask).squeeze().detach().to('cpu') # (B, E)   \n",
    "    if len(embedding_pool.shape)==1:\n",
    "        embedding_pool = embedding_pool.unsqueeze(0)\n",
    "    \n",
    "\n",
    "    del embedding, mask, tokens\n",
    "\n",
    "    for _ in range(len(sids)):\n",
    "        output[sids[_]] = embedding_pool[_,...]\n",
    "    \n",
    "print(output)\n",
    "\n",
    "torch.save(output, 'data/Embeddings/preembeddings_fibert_no_cls.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove invalid sentences\n",
    "(too short or too long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"sentenceid_longerThan10Char.feather\" (136.2 MB) loaded (5s)\n",
      "Found embeddings: ['preembeddings_finbert_onlyCLS_rank0.pt', 'preembeddings_finbert_onlyCLS_rank1.pt']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bb94f0880a4470960f538b68b3aa98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f52b990a64948d0851e413498e50990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9956926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9956926 -> 8554583 (85.9)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b585768117f4298bcbcedf6171ce905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9956926 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9956926 -> 8549346 (85.9)\n",
      "N sentences left: 17103928\n"
     ]
    }
   ],
   "source": [
    "# load sentenceids that are longer than 10 char\n",
    "ld('sentenceid_longerThan10Char', force=True)\n",
    "sentenceid_longerThan10Char = set(sentenceid_longerThan10Char.to_list()[0])\n",
    "\n",
    "# find the embedding paths\n",
    "embedding_paths = [file for file in os.listdir(f'{DATA_DIR}/Embeddings') \n",
    "                   if re.search(f'preembeddings_finbert_onlyCLS_rank', file)]\n",
    "assert len(embedding_paths)==2\n",
    "print(f'Found embeddings: {embedding_paths}')\n",
    "\n",
    "# load and filter\n",
    "embeddings = {}\n",
    "for embedding_path in tqdm(embedding_paths):\n",
    "    embedding = torch.load(f'{DATA_DIR}/Embeddings/{embedding_path}')\n",
    "    \n",
    "    n_before = len(embedding)\n",
    "    embedding = {k: v['embedding'] for k, v in tqdm(embedding.items()) \n",
    "                 if k in sentenceid_longerThan10Char}\n",
    "    n_after = len(embedding)\n",
    "    print(f'{n_before} -> {n_after} ({n_after/n_before*100:.1f}%)')\n",
    "    \n",
    "    embeddings.update(embedding)\n",
    "    \n",
    "    del embedding\n",
    "    \n",
    "print(f'N sentences left: {len(embeddings)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings, 'data/Embeddings/preembeddings_finbert_onlyCLS.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create different versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "- find the valid `sentence_id` and `transcriptid`, and use them to filter the original preembeddings\n",
    "\n",
    "Steps 2:\n",
    "- Stack sentence embeddings with the same `transcriptid`, and save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>transcriptid</th>\n",
       "      <th>transcriptcomponentid</th>\n",
       "      <th>sentence_order_id</th>\n",
       "      <th>componentorder</th>\n",
       "      <th>transcriptcomponenttypeid</th>\n",
       "      <th>transcriptpersonid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30184-0</td>\n",
       "      <td>108</td>\n",
       "      <td>30184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30184-1</td>\n",
       "      <td>108</td>\n",
       "      <td>30184</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30184-2</td>\n",
       "      <td>108</td>\n",
       "      <td>30184</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_id  transcriptid  transcriptcomponentid  sentence_order_id  \\\n",
       "0     30184-0           108                  30184                  0   \n",
       "1     30184-1           108                  30184                  1   \n",
       "2     30184-2           108                  30184                  2   \n",
       "\n",
       "   componentorder  transcriptcomponenttypeid  transcriptpersonid  \n",
       "0               1                          1                 1.0  \n",
       "1               1                          1                 1.0  \n",
       "2               1                          1                 1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ciq_components_sentencized_withouttext = feather.read_feather(f'{DATA_DIR}/ciq_components_sentencized_withouttext.feather')\n",
    "ciq_components_sentencized_withouttext.iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# load preembeddings\n",
    "# the preembedding is in the form of {sentence_id: {seq_len:, embedding:}\n",
    "\n",
    "# preemb_name = 'preembeddings_finBERT_without_special_tokens'\n",
    "preemb_name = 'preembeddings_finBERT_with_special_tokens'\n",
    "\n",
    "preembeddings = torch.load(f'data/Embeddings/{preemb_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 17.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --------------------------------------------------------\n",
    "# Collect `valid_sentence_ids` and `valid_transcript_ids`\n",
    "# --------------------------------------------------------\n",
    "\n",
    "# Sort sentences\n",
    "ciq_components_sentencized_withouttext.sort_values(['transcriptid', 'componentorder', 'sentence_order_id'], inplace=True)\n",
    "\n",
    "# valid_ids = ciq_components_sentencized_withouttext.loc[\n",
    "#     ciq_components_sentencized_withouttext.transcriptcomponenttypeid.isin([4]), \n",
    "#     ['transcriptid', 'sentence_id']]\n",
    "\n",
    "valid_ids = ciq_components_sentencized_withouttext[['transcriptid', 'sentence_id']]\n",
    "\n",
    "# the valid sentence_id must also be present in preembeddings\n",
    "valid_ids = valid_ids.loc[valid_ids.sentence_id.isin(preembeddings.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52186f31ea2440b82b480d3e5fa11f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=35077.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------------------------------\n",
    "# Select subset of preembeddings by `valid_transcriptids` and `valid_sentence_ids`\n",
    "# -------------------------------------------------------------------------------\n",
    "preembeddings_new = {}\n",
    "\n",
    "for tid, group in tqdm(valid_ids.groupby('transcriptid')):\n",
    "    sids = group.sentence_id.tolist()\n",
    "    emb = torch.stack([preembeddings[sid]['embedding'] for sid in sids])\n",
    "    preembeddings_new[tid] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save subset of preembeddings\n",
    "preemb_new_name = 'preembeddings_finBERT_with_special_tokens_test'\n",
    "torch.save(preembeddings_new, f'data/Embeddings/{preemb_new_name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{transcript_id_1: [...],\n",
    " transcript_id_2: [...]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{sentence_id_1: {transcript_id:int,\n",
    "                 sentence_type:str,\n",
    "                 embedding:[...]},\n",
    " sentence_id_2: {transcript_id:int,\n",
    "                 sentence_type:str,\n",
    "                 embedding:[...]}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# SBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0:  1.32/ 11.00 (GB)\n",
      "GPU 1:  0.00/ 11.00 (GB)\n"
     ]
    }
   ],
   "source": [
    "model_path = \"C:/Users/rossz/.cache/torch/sentence_transformers/public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_roberta-large-nli-stsb-mean-tokens.zip\"\n",
    "\n",
    "with open(os.path.join(model_path, 'modules.json')) as fIn:\n",
    "    contained_modules = json.load(fIn)\n",
    "    \n",
    "sbert_modules = OrderedDict()\n",
    "for module_config in contained_modules:\n",
    "    module_class = sentence_transformers.util.import_from_string(module_config['type'])\n",
    "    module = module_class.load(os.path.join(model_path, module_config['path']))\n",
    "    sbert_modules[module_config['name']] = module\n",
    "    \n",
    "sbert_pad_token_id = 1\n",
    "\n",
    "sbert_model = nn.Sequential(sbert_modules)\n",
    "sbert_model = nn.DataParallel(sbert_model)\n",
    "sbert_model.to(cuda0);\n",
    "log_gpu_memory();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Tokenize():\n",
    "    def __init__(self, modules, pad_token_id, max_seq_len):\n",
    "        '''\n",
    "        max_seq_len: There're still ass-cover statement in the call, which are very long.\n",
    "            I remove every sentence which are longer than `max_seq_len`\n",
    "        pad_token_id: for empty sentences, set length to 1 and fill with `pad_token_id`\n",
    "        '''\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.pad_token_id = pad_token_id\n",
    "        self.modules = modules\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        transcriptid, sentenceid, sent = sample\n",
    "        sent = self.modules[next(iter(self.modules))].tokenize(sent)\n",
    "        \n",
    "        if len(sent) == 0 or len(sent) < self.max_seq_len:\n",
    "            return transcriptid, sentenceid, sent\n",
    "        else:\n",
    "            return transcriptid, sentenceid, [self.pad_token_id]        \n",
    "\n",
    "\n",
    "class CCDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            df: DataFrame \n",
    "        '''\n",
    "        self.transform = transform\n",
    "        self.df = df\n",
    "        self.length_sorted_idx = np.argsort([len(sent) for sent in df['text'].tolist()])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        # sample: (transcripid, sentenceid, text)\n",
    "        sample = tuple(self.df.iloc[self.length_sorted_idx[idx]])\n",
    "            \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "# MAX_SENT_LEN = 256\n",
    "# ds = CCDataset(text_present_sentencized, transform=Tokenize(sbert_tokenizer, modules, pad_token_id=0, max_seq_len=MAX_SENT_LEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# --------------------------- Create DataLoader--------------------------\n",
    "def collate_fn(data: list, modules):\n",
    "    '''\n",
    "    Returns:\n",
    "        featurs: a list of features. {'input_ids', 'input_mask', 'sentence_lengths'}\n",
    "    '''\n",
    "    transcriptids, sentenceids, sents = list(zip(*data))\n",
    "    meta = (transcriptids, sentenceids)\n",
    "\n",
    "    # valid seq_len\n",
    "    valid_seq_len = [len(sent) for sent in sents]\n",
    "    longest_seq_len = max(valid_seq_len)\n",
    "    \n",
    "    # pad\n",
    "    features = {}\n",
    "    for sent in sents:\n",
    "        sentence_features = modules[next(iter(modules))].get_sentence_features(sent, longest_seq_len)\n",
    "        \n",
    "        for feature_name in sentence_features:\n",
    "            if feature_name not in features:\n",
    "                features[feature_name] = []\n",
    "            features[feature_name].append(sentence_features[feature_name])\n",
    "            \n",
    "    for feature_name in features:\n",
    "        features[feature_name] = torch.tensor(np.asarray(features[feature_name]))\n",
    "            \n",
    "    return {'features': features, 'meta': meta}\n",
    "\n",
    "# dl = DataLoader(ds, batch_size=32,\n",
    "#                 shuffle=False, num_workers=0,\n",
    "#                 collate_fn=partial(collate_fn, modules=modules),\n",
    "#                 drop_last=False,\n",
    "#                 pin_memory=False)\n",
    "# one_batch = next(iter(dl))\n",
    "# one_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pre_encode_sbert(dl, model, save_path, start):\n",
    "    with torch.no_grad():\n",
    "        res = []\n",
    "        for batch in tqdm(dl):\n",
    "            features = batch['features']\n",
    "            transcriptids, sentenceids = batch['meta']\n",
    "            embeddings = model(features)['sentence_embedding'].to(cpu).numpy()\n",
    "            \n",
    "            for transcriptid, sentenceid, embedding in zip(transcriptids, sentenceids, embeddings):\n",
    "                res.append((transcriptid, sentenceid, embedding))\n",
    "            \n",
    "        # save every chunk\n",
    "        torch.save(res, f'{save_path}_{start}.pt')   \n",
    "        \n",
    "    return res\n",
    "\n",
    "\n",
    "text_df = pd.read_feather(f'{DATA_DIR}/text_present_sentencized.feather')\n",
    "start = 800000\n",
    "stop = len(text_df)\n",
    "chunksize = 400000 # 400000 for 1/10 to tatal \n",
    "MAX_SENT_LEN = 256\n",
    "PREENCODE_BATCH_SIZE = 512\n",
    "\n",
    "res = []\n",
    "for i in range(start, stop, chunksize):\n",
    "    print(f'Processing {i}/{stop}...{i/stop*100: .1f}% {Now()}')\n",
    "    \n",
    "    try:\n",
    "        df = text_df.iloc[i:min(i+chunksize, stop)]\n",
    "        if min(i+chunksize, stop) % 2 != 0:\n",
    "            df = df.iloc[:-1]\n",
    "\n",
    "        ds = CCDataset(df, transform=Tokenize(sbert_modules, pad_token_id=sbert_pad_token_id, max_seq_len=MAX_SENT_LEN))\n",
    "        dl = DataLoader(ds, batch_size=PREENCODE_BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=0,\n",
    "                        collate_fn=partial(collate_fn, modules=sbert_modules),\n",
    "                        drop_last=False,\n",
    "                        pin_memory=True)\n",
    "\n",
    "        res.extend(pre_encode_sbert(dl, model=sbert_model, save_path='./data/text_present_sbert_roberta_nlistsb_encoded', start=i))\n",
    "    except Exception as e:\n",
    "        print(f'Exception i={i}')\n",
    "        print(f'   {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true"
   },
   "source": [
    "## Merge embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true"
   },
   "source": [
    "### merge pre-embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def merge_preembeddings(preembedding_type, text_type):\n",
    "    # load text_sentencied, (tid, sid, text)\n",
    "    # which is used for checking embedding number\n",
    "    if f'text_{text_type}_sentencized' not in globals():\n",
    "        text_sentencized = pd.read_feather(f'{DATA_DIR}/text_{text_type}_sentencized.feather')\n",
    "    \n",
    "    # load preembeddings\n",
    "    embedding_paths = [file for file in os.listdir(f'{DATA_DIR}/embeddings') if re.search(f'text_{preembedding_type}', file)]\n",
    "    for path in embedding_paths: print(path)\n",
    "        \n",
    "    print(f'Loading preembeddings...')\n",
    "    preembeddings_tmp = []\n",
    "    for embedding_path in tqdm(embedding_paths):\n",
    "        preembeddings_tmp.extend(torch.load(f'{DATA_DIR}/embeddings/{embedding_path}'))\n",
    "        \n",
    "    emb_dim = preembeddings_tmp[0][2].shape[0]\n",
    "        \n",
    "    # check if every sentence in `text_sentencized` has been preencoded\n",
    "    # for every missing sentences, replacing with torch.zeros(1024)\n",
    "    # The reason that some sentences have not been encoded is that the batch_size is \n",
    "    # an even number while the total number of sentences may be odd, in which case\n",
    "    # the last sentence of the dataset will be removed.\n",
    "    tid_sid_from_text_sentencized = set(f'{tid}-{sid}' for tid, sid in zip(text_sentencized.transcriptid, text_sentencized.sentenceid))\n",
    "\n",
    "    tid_sid_from_preembeddings = set(f'{tid}-{sid}' for tid, sid, _ in preembeddings_tmp)\n",
    "\n",
    "    for tid_sid in tid_sid_from_text_sentencized:\n",
    "        if tid_sid not in tid_sid_from_preembeddings:\n",
    "            tid, sid = tid_sid.split('-')\n",
    "            tid = int(tid)\n",
    "            sid = int(sid)\n",
    "            text = text_sentencized.loc[(text_sentencized.transcriptid==tid) & (text_sentencized.sentenceid==sid)]['text'].values[0]\n",
    "            print('Not found:')\n",
    "            print(f'  trascriptid: {tid}  sentenceid: {sid}')\n",
    "            print(f'  text: {text}')\n",
    "            print(f'-----------')\n",
    "\n",
    "            preembeddings_tmp.append((tid, sid, np.zeros(emb_dim)))\n",
    "            \n",
    "    assert len(preembeddings_tmp)==len(text_sentencized), 'preembedding # != sentence #'\n",
    "        \n",
    "    # sort by (transcriptid, sentenceid)\n",
    "    print(f'sorting by (transcriptid, sentenceid)')\n",
    "    preembeddings_tmp.sort(key=itemgetter(0,1))\n",
    "    \n",
    "    # group by transcriptid\n",
    "    preembeddings_bytid = defaultdict(list)\n",
    "    for transcriptid, _, emb in preembeddings_tmp:\n",
    "        preembeddings_bytid[transcriptid].append(emb)\n",
    "\n",
    "    preembeddings_bytid_stacked = {}\n",
    "    print('Stacking embeddings...')\n",
    "    for k, v in tqdm(preembeddings_bytid.items()):\n",
    "        preembeddings_bytid_stacked[k] = torch.tensor(np.array(v))\n",
    "    print(f'N call event: {len(preembeddings_bytid_stacked)}')\n",
    "\n",
    "    return preembeddings_bytid_stacked\n",
    "\n",
    "\n",
    "\n",
    "for text_type in ['all']:\n",
    "    # merge preembeddings\n",
    "    preembedding_type = f'{text_type}_sbert_roberta_nlistsb_encoded'\n",
    "    preembedding_name = f'preembeddings_{preembedding_type}'\n",
    "    preembeddings = merge_preembeddings(preembedding_type, text_type)\n",
    "    # save preembeddings\n",
    "    print(f'saving preembeddings...')\n",
    "    torch.save(preembeddings, f'{DATA_DIR}/embeddings/{preembedding_name}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save valid preembeddings keys\n",
    "> I found some `transcriptid`s in `targets_df` are NOT in `preembeddings`. So I save all valid preembeddings keys and use that to filter out invalid obervations `targets_df` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers: load preembeddings\n",
    "def load_preembeddings(preembedding_type):\n",
    "    if 'preembeddings' not in globals():\n",
    "        print(f'Loading preembeddings...@{Now()}')\n",
    "        globals()['preembeddings'] = torch.load(f\"{DATA_DIR}/embeddings/preembeddings_{preembedding_type}.pt\")\n",
    "        print(f'Loading finished. @{Now()}')\n",
    "        \n",
    "load_preembeddings('all_sbert_roberta_nlistsb_encoded')\n",
    "\n",
    "valid_preembedding_keys_all = pd.DataFrame({'valid_keys_all':list(set(preembeddings.keys()))})\n",
    "feather.write_feather(valid_preembedding_keys_all, 'data/valid_preembedding_keys_all.feather', compression='uncompressed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true"
   },
   "source": [
    "### check `id-text` pair "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Task: final check that id-text are correctly matched\n",
    ">\n",
    "> Check **Pass!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_model = SentenceTransformer('roberta-large-nli-stsb-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sentencized = pd.read_feather(f'{DATA_DIR}/text_all_sentencized.feather')\n",
    "targets_df = pd.read_feather(f'{DATA_DIR}/f_sue_keydevid_car_finratio_transcriptid_text.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5312, 1.3299, 0.4254,  ..., 0.1801, 0.9385, 0.5650])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preembeddings[1441428][123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.531192  , 1.3299239 , 0.42536   , ..., 0.18007116, 0.9384972 ,\n",
       "        0.56497455], dtype=float32)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = text_sentencized[(text_sentencized.transcriptid==1441428) & (text_sentencized.sentenceid==123)]\n",
    "text = text['text'].tolist()\n",
    "\n",
    "cpu_model.encode(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, preembeddings: list, targets_df, split_window, split_type, transcriptids=None, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            preembeddings: list of embeddings. Each element is a tensor (S, E) where S is number of sentences in a call\n",
    "            targets_df: DataFrame of targets variables.\n",
    "            split_window: str. e.g., \"roll-09\"\n",
    "            split_type: str. 'train' or 'test'\n",
    "            transcriptids: list. If provided, only the given transcripts will be used in generating the Dataset. `transcriptids` is applied **on top of** `split_window` and `split_type`\n",
    "        '''\n",
    "\n",
    "        # get split dates from `split_df`\n",
    "        _, train_start, train_end, test_start, test_end = tuple(split_df.loc[split_df.window==split_window].iloc[0])\n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d').date()\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d').date()\n",
    "        test_start = datetime.strptime(test_start, '%Y-%m-%d').date()\n",
    "        test_end = datetime.strptime(test_end, '%Y-%m-%d').date()\n",
    "        \n",
    "        # select valid transcriptids (preemb_keys) according to split dates \n",
    "        if split_type=='train':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(train_start, train_end)].transcriptid.tolist()\n",
    "        elif split_type=='test':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(test_start, test_end)].transcriptid.tolist()\n",
    "\n",
    "        self.valid_preemb_keys = set(transcriptids).intersection(set(preembeddings.keys()))\n",
    "        \n",
    "        if transcriptids is not None:\n",
    "            self.valid_preemb_keys = self.valid_preemb_keys.intersection(set(transcriptids))\n",
    "        \n",
    "        # self attributes\n",
    "        self.targets_df = targets_df\n",
    "        self.preembeddings = preembeddings\n",
    "        self.transform = transform\n",
    "        self.sent_len = sorted([(k, preembeddings[k].shape[0]) \n",
    "            for k in self.valid_preemb_keys],\n",
    "            key=itemgetter(1))\n",
    "        self.train_start = train_start\n",
    "        self.train_end = train_end\n",
    "        self.test_start = test_start\n",
    "        self.test_end = test_end\n",
    "        self.n_samples = len(self.sent_len)\n",
    "        self.split_window = split_window\n",
    "        self.split_type = split_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.valid_preemb_keys))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        transcriptid = self.sent_len[idx][0]\n",
    "        targets = self.targets_df[self.targets_df.transcriptid==transcriptid].iloc[0]\n",
    "        \n",
    "        # inputs: preembeddings\n",
    "        embeddings = self.preembeddings[transcriptid]\n",
    "        \n",
    "        # all of the following targests are\n",
    "        # of type `numpy.float64`\n",
    "        mcap = targets.mcap\n",
    "        sue = targets.sue\n",
    "        suelag = targets.sue_lag1\n",
    "        selag = targets.se_lag1\n",
    "        se = targets.se\n",
    "        selead = targets.se_lead1\n",
    "        sestlag = targets.sest_lag1\n",
    "        sest = targets.sest\n",
    "        car_0_30 = targets.car_0_30\n",
    "        car_0_30_lag = targets.car_0_30_lag1\n",
    "        \n",
    "        return transcriptid, embeddings, mcap, suelag, sue, car_0_30_lag, car_0_30, se, selead, sestlag, sest\n",
    "\n",
    "\n",
    "# # test DataSet...\n",
    "# targets_df_path = f'{DATA_DIR}/f_sue_keydevid_car_finratio_transcriptid_text.feather'\n",
    "# preembedding_type = 'ques_sbert_roberta_nlistsb_encoded'\n",
    "\n",
    "# # load preembeddings\n",
    "# if 'preembeddings' not in globals():\n",
    "#     print(f'Loading preembeddings...{Now()}')\n",
    "#     preembeddings = torch.load(f'{DATA_DIR}/embeddings/preembeddings_{preembedding_type}.pt')\n",
    "#     print(f'Loading finished. {Now()}')\n",
    "    \n",
    "# # load targets_df\n",
    "# if 'targets_df' not in globals():\n",
    "#     targets_df = pd.read_feather(targets_df_path)\n",
    "\n",
    "# # choose train/val split\n",
    "# split_df = pd.read_csv(f'{DATA_DIR}/split_dates.csv')\n",
    "\n",
    "# # create Dataset\n",
    "# test_ds = CCDataset(preembeddings, targets_df, split_window='roll-19', split_type='train')\n",
    "\n",
    "# test_ds[876]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
