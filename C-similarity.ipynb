{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "transient": {
       "display_id": "datatable:css"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "transient": {
       "display_id": "datatable:css"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from datatable import f\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dt.init_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Doc to \"text tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DocBin from disk\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "docs = []\n",
    "for _ in range(4):\n",
    "    docs.extend(list(DocBin(store_user_data=True).from_disk(f'data/doc_sp500_sm_{_}.spacy').get_docs(nlp.vocab)))\n",
    "\n",
    "# register extension for Doc\n",
    "Doc.set_extension('transcriptid', default=None, force=True)\n",
    "\n",
    "# Register extension for Span\n",
    "Span.set_extension('transcriptid', default=None, force=True)\n",
    "Span.set_extension('componentid', default=None, force=True)\n",
    "Span.set_extension('componentorder', default=None, force=True)\n",
    "Span.set_extension('componenttypeid', default=None, force=True)\n",
    "Span.set_extension('speakerid', default=None, force=True)\n",
    "Span.set_extension('speakertypeid', default=None, force=True)\n",
    "Span.set_extension('is_component', default=False, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"text_component_sp500.feather\" (978.0 MB) loaded as \"text_component\" (2s)\n"
     ]
    }
   ],
   "source": [
    "# Select componentid that belongs to MD and QA\n",
    "ld('text_component_sp500', ldname='text_component')\n",
    "text_component = dt.Frame(text_component)\n",
    "\n",
    "# componentid: Management Discussion\n",
    "componentids_md = text_component[(f.transcriptcomponenttypeid==2) & (f.speakertypeid==2), f.transcriptcomponentid].to_list()[0]\n",
    "\n",
    "# componentid: Q & A\n",
    "componentids_qa = text_component[((f.transcriptcomponenttypeid==3) | (f.transcriptcomponenttypeid==4)) & ((f.speakertypeid==2)|(f.speakertypeid==3)), f.transcriptcomponentid].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Doc to \"text tokens\"\n",
    "\n",
    "# Filtering Rule:\n",
    "# - only keep lemma\n",
    "# - KEEP stop words (stop words is informative while comparing)\n",
    "# - no punctuation\n",
    "# - no \"like number\"\n",
    "\n",
    "def make_text_tokens(docs, componentids):\n",
    "    texttoken = {}\n",
    "    \n",
    "    # For every doc, join the required spans into a list of str\n",
    "    for doc in docs:\n",
    "        txttok = []\n",
    "        for span in doc.spans['components']:\n",
    "            if span._.componentid in componentids:\n",
    "                txttok.extend([t.lemma_ for t in span \n",
    "                if ((not t.is_punct) & (not t.like_num))])\n",
    "\n",
    "        # If no text found, add an empty str\n",
    "        if len(txttok)==0:\n",
    "            txttok = ['']\n",
    "\n",
    "        # return\n",
    "        texttoken[doc._.transcriptid] = txttok\n",
    "    \n",
    "    return texttoken\n",
    "\n",
    "texttoken_md = make_text_tokens(docs, componentids_md)\n",
    "texttoken_qa = make_text_tokens(docs, componentids_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%capture` not found (But cell magic `%%capture` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert to DTM\n",
    "\n",
    "# Setting:\n",
    "# - keep ALL tokens\n",
    "vectorizer = CountVectorizer(preprocessor=lambda x: x,\n",
    "                             tokenizer=lambda x: x,\n",
    "                             lowercase=False,\n",
    "                             ngram_range=(1,2))\n",
    "\n",
    "# Learn vocabulary \n",
    "vectorizer.fit(texttoken_md.values())\n",
    "vectorizer.fit(texttoken_qa.values())\n",
    "\n",
    "# Make DTM\n",
    "dtm_md = vectorizer.transform(texttoken_md.values())\n",
    "dtm_qa = vectorizer.transform(texttoken_qa.values())\n",
    "\n",
    "# Compute similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = np.diag(cosine_similarity(dtm_md, dtm_qa))\n",
    "similarity\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}