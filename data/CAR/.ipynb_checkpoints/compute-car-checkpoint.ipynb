{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date\n",
    "from io import StringIO as StringIO_StringIO\n",
    "from json import (\n",
    "    dumps as json_dumps,\n",
    "    dump as json_dump,\n",
    "    load as json_load,\n",
    "    JSONEncoder as json_JSONEncoder,\n",
    ")\n",
    "import os\n",
    "\n",
    "from pandas import (\n",
    "    DataFrame as pd_DataFrame,\n",
    "    ExcelWriter as pd_ExcelWriter,\n",
    ")\n",
    "from numpy import (\n",
    "    abs as np_abs,\n",
    "    nan as np_nan,\n",
    "    mean as np_mean,\n",
    "    std as np_std,\n",
    "    sqrt as np_sqrt,\n",
    "    ndarray as np_ndarray,\n",
    ")\n",
    "from statsmodels.api import (\n",
    "    OLS as sm_OLS,\n",
    "    add_constant as sm_add_constant\n",
    ")\n",
    "from tabulate import tabulate\n",
    "import wrds\n",
    "\n",
    "\n",
    "class EncoderJson(json_JSONEncoder):\n",
    "    \"\"\"\n",
    "    Class used to encodes to JSON data format\n",
    "    \"\"\"\n",
    "\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np_ndarray):\n",
    "            return obj.tolist()\n",
    "        elif isinstance(obj, datetime):\n",
    "            return obj.__str__()\n",
    "        elif isinstance(obj, date):\n",
    "            return obj.__str__()\n",
    "\n",
    "        return json_JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "class EventStudy(object):\n",
    "    \"\"\"\n",
    "    Main class that runs the event study.\n",
    "    \"\"\"\n",
    "\n",
    "    ###################################################\n",
    "    #  STEP 0 - AUTHENTICATE AND CONNECT TO POSTGRES  #\n",
    "    ###################################################\n",
    "\n",
    "    # parameters when the class is initialized.\n",
    "    # pass an explicit output path for result file\n",
    "    def __init__(self, output_path=''):\n",
    "        if len(output_path) <= 0:\n",
    "            self.output_path = os.path.expanduser('~')\n",
    "        else:\n",
    "            self.output_path = output_path\n",
    "\n",
    "        self.wconn = wrds.Connection(wrds_username='xiaomowu')\n",
    "        \n",
    "    # Connect to the Postgres database\n",
    "    # Code assumes pgpass file has been created\n",
    "    def connect(self):\n",
    "        \"\"\"\n",
    "        Connect to the Postgres via WRDS.\n",
    "        \"\"\"\n",
    "        self.wrdsconn = wrds.Connection(wrds_username='xiaomowu')\n",
    "        # self.wrdsconn.create_pgpass_file()\n",
    "#         self.conn = self.wrdsconn.connect()\n",
    "\n",
    "        return self.wrdsconn\n",
    "\n",
    "    # This is the method that gets called to run the event study. The \"heavy lifting\" happens here.\n",
    "    def eventstudy(self, data=None, model='m', estwin=100, gap=50, evtwins=-10, evtwine=10, minval=70, output='df', use_download=False):\n",
    "        \"\"\"\n",
    "            Paramaters passed to the event study method.\n",
    "            \n",
    "            data        =   event data (event date & permno combinations)\n",
    "            model       =   madj (market-adjusted model)\n",
    "                            m (market model)\n",
    "                            ff (fama french)\n",
    "                            ffm (fama french with momentum factor)\n",
    "            estwin      =   estimation window\n",
    "            gap         =   gap between estimation window and event window\n",
    "            evtwins =   days preceding event date to begin event window\n",
    "            evtwine =   days after event date to close the event window\n",
    "            minval      =   minimum number of non-missing return observations (per event) to be regressed on\n",
    "            output      =   output format of the event study results\n",
    "                            xls (output an excel file to output path)\n",
    "                            csv (output a csv file to output path)\n",
    "                            json (output a json file to output path)\n",
    "                            df (returns a dictionary of pandas dataframes)\n",
    "                            print (outputs results to the console - not available via qsub)\n",
    "        \"\"\"\n",
    "\n",
    "        #  STEP 1 - SET ESTIMATION, EVENT, AND GAP WINDOWS AND GRAB DATA FROM EVENTS FILE  #\n",
    "        ####################################################################################\n",
    "\n",
    "        estwins = (estwin + gap + np_abs(evtwins))  # Estimation window start\n",
    "        estwine = (gap + np_abs(evtwins) + 1)       # Estimation window end\n",
    "        evtwinx = (estwins + 1)                     # evt time value (0=event date, -10=window start, 10=window end)\n",
    "        evtwins = np_abs(evtwins)                   # convert the negative to positive as we will use lag function)\n",
    "        evtrang = (evtwins + evtwine + 1)           # total event window days (lag + lead + the day itself)\n",
    "\n",
    "        \"\"\"\n",
    "            With the event date as a fixed point, calculate the number of days needed to pass\n",
    "            to sql lag and lead functions to identify estimation window, gap, and event window.\n",
    "\n",
    "            evtwins:    event date minus number of preceding days\n",
    "                        (\"event date\" - \"number of days before event to start [evtwins parameter]\")\n",
    "\n",
    "            evtwine:    event date plus number of following days\n",
    "                        (\"event date\" + \"number of days after event to end [evtwine parameter]\")\n",
    "\n",
    "            gap:    number of days between the end of the \"estimation window\"\n",
    "                    and the beginning of the \"event window\"\n",
    "\n",
    "            estwins:     start date of the estimation window\n",
    "                        (\"event date\" - \"number of days before event to start [evtwins parameter]\"\n",
    "                                      - \"number of days in gap [gap parameter]\"\n",
    "                                      - \"number of days in estimation window [estwin parameter]\")\n",
    "\n",
    "            evtrang:    entire time range of the event study even from estimate start, through gap,\n",
    "                        until event window end\n",
    "                        (evtwins + evtwine + 1)\n",
    "        \"\"\"\n",
    "\n",
    "        # default the event data in case it was not passed, otherwise read what was passed\n",
    "        evtdata = [{\"edate\": \"05/29/2012\", \"permno\": \"10002\"}]\n",
    "        if data is not None:\n",
    "            evtdata = json_dumps(data)\n",
    "\n",
    "        # init values wrapped up to be passed to sql statement\n",
    "        params = {'estwins': estwins, 'estwine': estwine, 'evtwins': evtwins, 'evtwine': evtwine, 'evtwinx': evtwinx, 'evtdata': evtdata}\n",
    "\n",
    "        #############################################\n",
    "        #  STEP 2 - GET RETURNS DATA FROM POSTGRES  #\n",
    "        #############################################\n",
    "\n",
    "#         # Create a database connection\n",
    "        wconn = self.wconn\n",
    "\n",
    "        ##############################################################################\n",
    "        #  Get the initial data from the database and put it in a pandas dataframe   #\n",
    "        ##############################################################################\n",
    "\n",
    "        # create a pandas dataframe that will hold data\n",
    "#         print(f'Start downloading: {Now()}')\n",
    "        \n",
    "        if use_download is False:\n",
    "            df = wconn.raw_sql(\"\"\"\n",
    "            SELECT\n",
    "                    a.*,\n",
    "                    x.*,\n",
    "                    c.date as rdate,\n",
    "                    c.ret as ret1,\n",
    "                    (f.mktrf+f.rf) as mkt,\n",
    "                    f.mktrf,\n",
    "                    f.rf,\n",
    "                    f.smb,\n",
    "                    f.hml,\n",
    "                    f.umd,\n",
    "                    (1+c.ret)*(coalesce(d.dlret,0.00)+1)-1-(f.mktrf+f.rf) as exret,\n",
    "                    (1+c.ret)*(coalesce(d.dlret,0.00)+1)-1 as ret,\n",
    "                    case when c.date between a.estwin1 and a.estwin2 then 1 else 0 end as isest,\n",
    "                    case when c.date between a.evtwin1 and a.evtwin2 then 1 else 0 end as isevt,\n",
    "                    case\n",
    "                      when c.date between a.evtwin1 and a.evtwin2 then (rank() OVER (PARTITION BY x.evtid ORDER BY c.date)-%(evtwinx)s)\n",
    "                      else (rank() OVER (PARTITION BY x.evtid ORDER BY c.date))\n",
    "                    end as evttime\n",
    "            FROM\n",
    "              (\n",
    "                SELECT\n",
    "                  date,\n",
    "                  lag(date, %(estwins)s ) over (order by date) as estwin1,\n",
    "                  lag(date, %(estwine)s )  over (order by date) as estwin2,\n",
    "                  lag(date, %(evtwins)s )  over (order by date) as evtwin1,\n",
    "                  lead(date, %(evtwine)s )  over (order by date) as evtwin2\n",
    "                FROM crsp_a_stock.dsi\n",
    "              ) as a\n",
    "            JOIN\n",
    "            (select\n",
    "                    to_char(x.edate, 'ddMONYYYY') || trim(to_char(x.permno,'999999999')) as evtid,\n",
    "                    x.permno,\n",
    "                    x.edate\n",
    "            from\n",
    "            json_to_recordset('%(evtdata)s') as x(edate date, permno int)\n",
    "            ) as x\n",
    "              ON a.date=x.edate\n",
    "            JOIN crsp_a_stock.dsf c\n",
    "                ON x.permno=c.permno\n",
    "                AND c.date BETWEEN a.estwin1 and a.evtwin2\n",
    "            JOIN ff_all.factors_daily f\n",
    "                ON c.date=f.date\n",
    "            LEFT JOIN crsp_a_stock.dsedelist d\n",
    "                ON x.permno=d.permno\n",
    "                AND c.date=d.dlstdt\n",
    "            WHERE f.mktrf is not null\n",
    "            AND c.ret is not null\n",
    "            ORDER BY x.evtid, x.permno, a.date, c.date\n",
    "            \"\"\" % params)\n",
    "#             print(f'Downloading finished {Now()}')\n",
    "        \n",
    "        # Columns coming from the database query\n",
    "        df.columns = ['date', 'estwin1', 'estwin2', 'evtwin1', 'evtwin2',\n",
    "                      'evtid', 'permno', 'edate', 'rdate', 'ret1', 'mkt',\n",
    "                      'mktrf', 'rf', 'smb', 'hml', 'umd', 'exret', 'ret',\n",
    "                      'isest', 'isevt', 'evttime']\n",
    "\n",
    "        # Additional columns that will hold computed values (post-query)\n",
    "        addcols = ['RMSE', 'INTERCEPT', 'var_estp', 'expret', 'abret',\n",
    "                   'alpha', '_nobs', '_p_', '_edf_', 'rsq', 'cret',\n",
    "                   'cexpret', 'car', 'scar', 'sar', 'pat_scale', 'bhar',\n",
    "                   'lastevtwin', 'cret_edate', 'scar_edate', 'car_edate',\n",
    "                   'bhar_edate', 'pat_scale_edate', 'xyz']\n",
    "\n",
    "        # Add them to the dataframe\n",
    "        for c in addcols:\n",
    "            if c == 'lastevtwin':\n",
    "                df[c] = 0\n",
    "            else:\n",
    "                df[c] = np_nan\n",
    "\n",
    "        ###################################################################################\n",
    "        #  STEP 3 - FOR EACH EVENT, CALCULATE ABNORMAL RETURN BASED ON CHOSEN RISK MODEL  #\n",
    "        ###################################################################################\n",
    "\n",
    "        # Loop on every category\n",
    "        for i, evt in enumerate(data):\n",
    "#             if i % 1000 == 0:\n",
    "#                 print(f'{i+1}/{len(data)} {Now()}')\n",
    "\n",
    "            permno = evt['permno']\n",
    "            xdate = evt['edate']\n",
    "            edate = datetime.strptime(xdate, \"%m/%d/%Y\").date()\n",
    "\n",
    "            est_mask = (df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)\n",
    "            evt_mask = (df['permno'] == permno) & (df['edate'] == edate) & (df['isevt'] == 1)\n",
    "\n",
    "            #######################################################\n",
    "            #  Check to see it meets the min obs for est window   #\n",
    "            #######################################################\n",
    "            _nobs = df[\"ret\"][est_mask].count()\n",
    "\n",
    "            # Only carry out the analysis if the number of obsevations meets the minimum threshold\n",
    "            if _nobs >= minval:\n",
    "\n",
    "                #######################################################\n",
    "                #  Regression based on model choices=''               #\n",
    "                #######################################################\n",
    "\n",
    "                # Market-Adjusted Model\n",
    "                if model == 'madj':\n",
    "                    # Set y to the estimation window records\n",
    "                    y = df[\"exret\"][est_mask]\n",
    "\n",
    "                    # Calculate mean and standard deviation of returns for the estimation period\n",
    "                    mean = np_mean(y)\n",
    "                    stdv = np_std(y, ddof=1)\n",
    "\n",
    "                    # Update the columns in the original dataframe (reusing the names from SAS code to help with continuity)\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = mean\n",
    "                    df.loc[evt_mask, 'RMSE'] = stdv\n",
    "                    df.loc[evt_mask, '_nobs'] = len(y)\n",
    "                    df.loc[evt_mask, 'var_estp'] = stdv ** 2\n",
    "                    df.loc[evt_mask, 'alpha'] = mean\n",
    "                    df.loc[evt_mask, 'rsq'] = 0\n",
    "                    df.loc[evt_mask, '_p_'] = 1\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 1)\n",
    "                    df.loc[evt_mask, 'expret'] = df.loc[evt_mask, 'mkt']\n",
    "                    df.loc[evt_mask, 'abret'] = df.loc[evt_mask, 'exret']\n",
    "                    df_est = df[est_mask]\n",
    "                    _nobs = len(df_est[df_est.ret.notnull()])\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "\n",
    "                # Market Model\n",
    "                elif model == 'm':\n",
    "                    # Set y to the estimation window records\n",
    "                    X = df[\"mktrf\"][est_mask]\n",
    "                    y = df[\"ret\"][est_mask]\n",
    "\n",
    "                    # Fit an OLS model with intercept on mktrf\n",
    "                    X = sm_add_constant(X)\n",
    "                    est = sm_OLS(y, X).fit()\n",
    "\n",
    "                    # Set the variables from the output\n",
    "                    df_est = df[(df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)]\n",
    "                    _nobs = len(df_est[df_est.ret.notnull()])   # not null observations\n",
    "\n",
    "                    # aggregate variables\n",
    "                    # cret_edate = np_nan\n",
    "                    # scar_edate = np_nan\n",
    "                    # car_edate = np_nan\n",
    "                    # bhar_edate = np_nan\n",
    "                    # pat_scale_edate = np_nan\n",
    "                    alpha = est.params.__getitem__('const')\n",
    "                    beta1 = est.params.__getitem__('mktrf')\n",
    "\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = alpha\n",
    "                    df.loc[evt_mask, 'alpha'] = alpha\n",
    "                    df.loc[evt_mask, 'RMSE'] = np_sqrt(est.mse_resid)\n",
    "                    df.loc[evt_mask, '_nobs'] = _nobs\n",
    "                    df.loc[evt_mask, 'var_estp'] = est.mse_resid\n",
    "                    df.loc[evt_mask, 'rsq'] = est.rsquared\n",
    "                    df.loc[evt_mask, '_p_'] = 2\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 2)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'const': 0}\n",
    "\n",
    "                    def f_expret(row):\n",
    "                        return (nloc['alpha'] + (nloc['beta1'] * row['mktrf']))\n",
    "                    df.loc[evt_mask, 'expret'] = df[evt_mask].apply(f_expret, axis=1)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'const': 0}\n",
    "\n",
    "                    def f_abret(row):\n",
    "                        return (row['ret'] - (nloc['alpha'] + (nloc['beta1'] * row['mktrf'])))\n",
    "                    df.loc[evt_mask, 'abret'] = df[evt_mask].apply(f_abret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        # nonlocal const\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "\n",
    "                # Fama-French Three Factor Model\n",
    "                elif model == 'ff':\n",
    "                    # Set y to the estimation window records\n",
    "                    df_est = df[(df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)]\n",
    "                    X = df_est[['smb', 'hml', 'mktrf']]\n",
    "                    y = df_est['ret']\n",
    "\n",
    "                    # Fit an OLS model with intercept on mktrf, smb, hml\n",
    "                    X = sm_add_constant(X)\n",
    "                    est = sm_OLS(y, X).fit()\n",
    "                    # est = smf.ols(formula='ret ~ smb + hml + mktrf', data=df_est).fit()\n",
    "\n",
    "                    alpha = est.params.__getitem__('const')\n",
    "                    beta1 = est.params.__getitem__('mktrf')\n",
    "                    beta2 = est.params.__getitem__('smb')\n",
    "                    beta3 = est.params.__getitem__('hml')\n",
    "\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = alpha\n",
    "                    df.loc[evt_mask, 'alpha'] = alpha\n",
    "                    df.loc[evt_mask, 'RMSE'] = np_sqrt(est.mse_resid)\n",
    "                    df.loc[evt_mask, '_nobs'] = _nobs\n",
    "                    df.loc[evt_mask, 'var_estp'] = est.mse_resid\n",
    "                    df.loc[evt_mask, 'rsq'] = est.rsquared\n",
    "                    df.loc[evt_mask, '_p_'] = 2\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 2)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'const': 0}\n",
    "\n",
    "                    def f_expret(row):\n",
    "                        return ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml'])))\n",
    "                    df.loc[evt_mask, 'expret'] = df[evt_mask].apply(f_expret, axis=1)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'const': 0}\n",
    "\n",
    "                    def f_abret(row):\n",
    "                        return (row['ret'] - ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml']))))\n",
    "                    df.loc[evt_mask, 'abret'] = df[evt_mask].apply(f_abret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "\n",
    "                # Fama-French Plus Momentum\n",
    "                elif model == 'ffm':\n",
    "                    # Set y to the estimation window records\n",
    "                    df_est = df[(df['permno'] == permno) & (df['edate'] == edate) & (df['isest'] == 1)]\n",
    "\n",
    "                    X = df_est[['mktrf', 'smb', 'hml', 'umd']]  # indicator variables\n",
    "                    y = df_est['ret']                           # response variables\n",
    "\n",
    "                    # Fit an OLS (ordinary least squares) model with intercept on mktrf, smb, hml, and umd\n",
    "                    X = sm_add_constant(X)\n",
    "                    est = sm_OLS(y, X).fit()\n",
    "\n",
    "                    alpha = est.params.__getitem__('const')\n",
    "                    beta1 = est.params.__getitem__('mktrf')\n",
    "                    beta2 = est.params.__getitem__('smb')\n",
    "                    beta3 = est.params.__getitem__('hml')\n",
    "                    beta4 = est.params.__getitem__('umd')\n",
    "\n",
    "                    df.loc[evt_mask, 'INTERCEPT'] = alpha\n",
    "                    df.loc[evt_mask, 'alpha'] = alpha\n",
    "                    df.loc[evt_mask, 'RMSE'] = np_sqrt(est.mse_resid)\n",
    "                    df.loc[evt_mask, '_nobs'] = _nobs\n",
    "                    df.loc[evt_mask, 'var_estp'] = est.mse_resid\n",
    "                    df.loc[evt_mask, 'rsq'] = est.rsquared\n",
    "                    df.loc[evt_mask, '_p_'] = 2\n",
    "                    df.loc[evt_mask, '_edf_'] = (len(y) - 2)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'beta4': beta4, 'const': 0}\n",
    "\n",
    "                    def f_expret(row):\n",
    "                        return ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml']) + (nloc['beta4'] * row['umd'])))\n",
    "                    df.loc[evt_mask, 'expret'] = df[evt_mask].apply(f_expret, axis=1)\n",
    "\n",
    "                    nloc = {'alpha': alpha, 'beta1': beta1, 'beta2': beta2, 'beta3': beta3, 'beta4': beta4, 'const': 0}\n",
    "\n",
    "                    def f_abret(row):\n",
    "                        return (row['ret'] - ((nloc['alpha'] + (nloc['beta1'] * row['mktrf']) + (nloc['beta2'] * row['smb']) + (nloc['beta3'] * row['hml']) + (nloc['beta4'] * row['umd']))))\n",
    "                    df.loc[evt_mask, 'abret'] = df[evt_mask].apply(f_abret, axis=1)\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cret(row):\n",
    "                        tmp = ((row['ret'] * nloc['const']) + (row['ret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cret'] = df[evt_mask].apply(f_cret, axis=1)\n",
    "                    df.loc[evt_mask, 'cret_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_cexpret(row):\n",
    "                        tmp = ((row['expret'] * nloc['const']) + (row['expret'] + nloc['const']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'cexpret'] = df[evt_mask].apply(f_cexpret, axis=1)\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_car(row):\n",
    "                        tmp = (row['abret'] + nloc['const'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'car'] = df[evt_mask].apply(f_car, axis=1)\n",
    "                    df.loc[evt_mask, 'car_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_sar(row):\n",
    "                        tmp = (row['abret'] / np_sqrt(row['var_estp']))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'sar'] = df[evt_mask].apply(f_sar, axis=1)\n",
    "                    df.loc[evt_mask, 'sar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0, 'evtrang': evtrang}\n",
    "\n",
    "                    def f_scar(row):\n",
    "                        tmp = (row['car'] / np_sqrt((evtrang * row['var_estp'])))\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'scar'] = df[evt_mask].apply(f_scar, axis=1)\n",
    "                    df.loc[evt_mask, 'scar_edate'] = nloc['const']\n",
    "\n",
    "                    nloc = {'const': 0}\n",
    "\n",
    "                    def f_bhar(row):\n",
    "                        tmp = (row['cret'] - row['cexpret'])\n",
    "                        nloc['const'] = tmp\n",
    "                        return tmp\n",
    "                    df.loc[evt_mask, 'bhar'] = df[evt_mask].apply(f_bhar, axis=1)\n",
    "                    df.loc[evt_mask, 'bhar_edate'] = nloc['const']\n",
    "\n",
    "                    df.loc[evt_mask, 'pat_scale'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                    df.loc[evt_mask, 'pat_scale_edate'] = (_nobs - 2.00) / (_nobs - 4.00)\n",
    "                # Something erroneous was passed\n",
    "                else:\n",
    "                    df['isest'][evt_mask] = -2\n",
    "\n",
    "        #################################\n",
    "        #  STEP 4 - OUTPUT THE RESULTS  #\n",
    "        #################################\n",
    "        df_sta = df[df['isevt'] == 1]\n",
    "        levt = df_sta['evttime'].unique()\n",
    "\n",
    "        '''\n",
    "        columns = ['evttime',\n",
    "                   'car_m',\n",
    "                   'ret_m',\n",
    "                   'abret_m',\n",
    "                   'abret_t',\n",
    "                   'sar_t',\n",
    "                   'pat_ar',\n",
    "                   'cret_edate_m',\n",
    "                   'car_edate_m',\n",
    "                   'pat_car_edate_m',\n",
    "                   'car_edate_t',\n",
    "                   'scar_edate_t',\n",
    "                   'bhar_edate_m']\n",
    "\n",
    "        idxlist = list(levt)\n",
    "        df_stats = pd_DataFrame(index=idxlist, columns=columns)\n",
    "        df_stats = df_stats.fillna(0.00000000)  # with 0s rather than NaNs\n",
    "\n",
    "        # Event\n",
    "        df_stats['evttime'] = df_sta.groupby(['evttime'])['evttime'].unique()\n",
    "        # Means\n",
    "        df_stats['abret_m'] = df_sta.groupby(['evttime'])['abret'].mean()\n",
    "        df_stats['bhar_edate_m'] = df_sta.groupby(['evttime'])['bhar_edate'].mean()\n",
    "        df_stats['car_edate_m'] = df_sta.groupby(['evttime'])['car_edate'].mean()\n",
    "        df_stats['car_m'] = df_sta.groupby(['evttime'])['car'].mean()\n",
    "        df_stats['cret_edate_m'] = df_sta.groupby(['evttime'])['cret_edate'].mean()\n",
    "        df_stats['pat_scale_m'] = df_sta.groupby(['evttime'])['pat_scale'].mean()\n",
    "        df_stats['pat_car_edate_mean'] = 0\n",
    "        df_stats['ret_m'] = df_sta.groupby(['evttime'])['ret'].mean()\n",
    "        df_stats['sar_m'] = df_sta.groupby(['evttime'])['sar'].mean()\n",
    "        df_stats['scar_edate_m'] = df_sta.groupby(['evttime'])['scar_edate'].mean()\n",
    "        df_stats['scar_m'] = df_sta.groupby(['evttime'])['scar'].mean()\n",
    "        # Standard deviations\n",
    "        df_stats['car_v'] = df_sta.groupby(['evttime'])['car'].std()\n",
    "        df_stats['abret_v'] = df_sta.groupby(['evttime'])['abret'].std()\n",
    "        df_stats['sar_v'] = df_sta.groupby(['evttime'])['sar'].std()\n",
    "        df_stats['pat_scale_v'] = df_sta.groupby(['evttime'])['pat_scale'].std()\n",
    "        df_stats['car_edate_v'] = df_sta.groupby(['evttime'])['car_edate'].std()\n",
    "        df_stats['scar_edate_v'] = df_sta.groupby(['evttime'])['scar_edate'].std()\n",
    "        df_stats['scar_v'] = df_sta.groupby(['evttime'])['scar'].std()\n",
    "        # Counts\n",
    "        df_stats['scar_n'] = df_sta.groupby(['evttime'])['scar'].count()\n",
    "        df_stats['scar_edate_n'] = df_sta.groupby(['evttime'])['scar_edate'].count()\n",
    "        df_stats['sar_n'] = df_sta.groupby(['evttime'])['sar'].count()\n",
    "        df_stats['car_n'] = df_sta.groupby(['evttime'])['car'].count()\n",
    "        df_stats['n'] = df_sta.groupby(['evttime'])['evttime'].count()\n",
    "        # Sums\n",
    "        df_stats['pat_scale_edate_s'] = df_sta.groupby(['evttime'])['pat_scale_edate'].sum()\n",
    "        df_stats['pat_scale_s'] = df_sta.groupby(['evttime'])['pat_scale'].sum()\n",
    "\n",
    "        # T statistics 1\n",
    "        def tstat(row, m, v, n):\n",
    "            return row[m] / (row[v] / np_sqrt(row[n]))\n",
    "\n",
    "        df_stats['abret_t'] = df_stats.apply(tstat, axis=1, args=('abret_m', 'abret_v', 'n'))\n",
    "        df_stats['sar_t'] = df_stats.apply(tstat, axis=1, args=('sar_m', 'sar_v', 'n'))\n",
    "        df_stats['car_edate_t'] = df_stats.apply(tstat, axis=1, args=('car_edate_m', 'car_edate_v', 'n'))\n",
    "        df_stats['scar_edate_t'] = df_stats.apply(tstat, axis=1, args=('scar_edate_m', 'scar_edate_v', 'scar_edate_n'))\n",
    "\n",
    "        # T statistics 2\n",
    "        def tstat2(row, m, s, n):\n",
    "            return row[m] / (np_sqrt(row[s]) / row[n])\n",
    "\n",
    "        df_stats['pat_car'] = df_stats.apply(tstat2, axis=1, args=('scar_m', 'pat_scale_s', 'scar_n'))\n",
    "        df_stats['pat_car_edate_m'] = df_stats.apply(tstat2, axis=1, args=('scar_edate_m', 'pat_scale_edate_s', 'scar_edate_n'))\n",
    "        df_stats['pat_ar'] = df_stats.apply(tstat2, axis=1, args=('sar_m', 'pat_scale_s', 'sar_n'))\n",
    "        '''\n",
    "        \n",
    "        # FILE 2\n",
    "        # EVENT WINDOW\n",
    "#         df_evtw = df.ix[(df['isevt'] == 1), ['permno', 'edate', 'rdate', 'evttime', 'ret', 'abret']]\n",
    "        df_evtw = df.loc[:, ['isevt', 'permno', 'edate', 'rdate', 'evttime', 'ret', 'abret', 'alpha', '_nobs']]\n",
    "    \n",
    "        df_evtw.sort_values(['permno', 'evttime'], ascending=[True, True])\n",
    "\n",
    "        '''\n",
    "        # FILE 1\n",
    "        # EVENT DATE\n",
    "        maxv = max(levt)\n",
    "#         df_evtd = df.ix[(df['isevt'] == 1) & (df['evttime'] == maxv), ['permno', 'edate', 'cret', 'car', 'bhar']]\n",
    "        df_evtd = df.loc[(df['isevt'] == 1) & (df['evttime'] == maxv), ['permno', 'edate', 'cret', 'car', 'bhar']]\n",
    "        df_evtd.sort_values(['permno', 'edate'], ascending=[True, True])\n",
    "        '''\n",
    "        \n",
    "        if output == 'df':\n",
    "            retval = {}\n",
    "            # retval['event_stats'] = df_stats\n",
    "            retval['event_window'] = df_evtw\n",
    "            # retval['event_date'] = df_evtd\n",
    "            return retval\n",
    "        elif output == 'print':\n",
    "            retval = {}\n",
    "            print(tabulate(df_evtd.sort_values(['permno', 'edate'], ascending=[True, True]), headers='keys', tablefmt='psql'))\n",
    "            print(tabulate(df_evtw, headers='keys', tablefmt='psql'))\n",
    "            print(tabulate(df_stats, headers='keys', tablefmt='psql'))\n",
    "            return retval\n",
    "        elif output == 'json':\n",
    "            retval = {}\n",
    "            retval['event_stats'] = df_stats.to_dict(orient='split')\n",
    "            retval['event_window'] = df_evtw.to_dict(orient='split')\n",
    "            retval['event_date'] = df_evtd.to_dict(orient='split')\n",
    "            # Write this to a file\n",
    "            with open(os.path.join(self.output_path, 'EventStudy.json'), 'w') as outfile:\n",
    "                json_dump(retval, outfile, cls=EncoderJson)\n",
    "            # Return the output in case they are doing something programmatically\n",
    "            return json_dumps(retval, cls=EncoderJson)\n",
    "        elif output == 'csv':\n",
    "            retval = ''\n",
    "            es = StringIO_StringIO()\n",
    "            df_stats.to_csv(es)\n",
    "            retval += es.getvalue()\n",
    "            ew = StringIO_StringIO()\n",
    "            df_evtw.to_csv(ew)\n",
    "            retval += \"\\r\"\n",
    "            retval += ew.getvalue()\n",
    "            ed = StringIO_StringIO()\n",
    "            df_evtd.to_csv(ed)\n",
    "            retval += ed.getvalue()\n",
    "\n",
    "            # write this to a file\n",
    "            with open(os.path.join(self.output_path, 'EventStudy.csv'), 'w') as outfile:\n",
    "                outfile.write(retval)\n",
    "\n",
    "            # return the output in case they are doing something programmatically\n",
    "            return retval\n",
    "        elif output == 'xls':\n",
    "            retval = {}\n",
    "            xlswriter = pd_ExcelWriter(os.path.join(self.output_path, 'EventStudy.xls'))\n",
    "            df_stats.to_excel(xlswriter, 'Stats')\n",
    "            df_evtw.to_excel(xlswriter, 'Event Window')\n",
    "            df_evtd.to_excel(xlswriter, 'Event Date')\n",
    "            xlswriter.save()\n",
    "            return retval\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading library list...\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb9a03321724a3f924db11f14006941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4037), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#################################################\n",
    "#  Instantiate the class and call the function  #\n",
    "#################################################\n",
    "# Use absolute path: /home/[institution]/[username]/ (e.g. /home/wharton/jwharton/)\n",
    "eventstudy = EventStudy(output_path='./')\n",
    "batch_size = 10\n",
    "\n",
    "with open('event_samples_earnings_call.json') as data_file:\n",
    "    events_call = json_load(data_file)\n",
    "    \n",
    "cars_30d_call = []\n",
    "for i, events in enumerate(tqdm(list(chunks(events_call, batch_size)))):\n",
    "    if i>=1: break\n",
    "    car = eventstudy.eventstudy(data=events, model='ff', estwin=125, gap=0, evtwins=-30, evtwine=125, minval=50, output='df')\n",
    "    cars_30d_call.append(car['event_window'])\n",
    "    \n",
    "# concat into one DF\n",
    "cars_30d_call = pd.concat(cars_30d_call)\n",
    "\n",
    "# save DF as csv\n",
    "cars_30d_call.to_csv('cars_30d_call.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isevt</th>\n",
       "      <th>permno</th>\n",
       "      <th>edate</th>\n",
       "      <th>rdate</th>\n",
       "      <th>evttime</th>\n",
       "      <th>ret</th>\n",
       "      <th>abret</th>\n",
       "      <th>alpha</th>\n",
       "      <th>_nobs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-12</td>\n",
       "      <td>121</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-13</td>\n",
       "      <td>122</td>\n",
       "      <td>-0.010023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-14</td>\n",
       "      <td>123</td>\n",
       "      <td>-0.023228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-17</td>\n",
       "      <td>124</td>\n",
       "      <td>-0.008537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-18</td>\n",
       "      <td>125</td>\n",
       "      <td>0.026445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-19</td>\n",
       "      <td>-30</td>\n",
       "      <td>-0.061114</td>\n",
       "      <td>-0.040172</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-20</td>\n",
       "      <td>-29</td>\n",
       "      <td>0.022336</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-24</td>\n",
       "      <td>-28</td>\n",
       "      <td>0.021848</td>\n",
       "      <td>0.010089</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-25</td>\n",
       "      <td>-27</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-26</td>\n",
       "      <td>-26</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-27</td>\n",
       "      <td>-25</td>\n",
       "      <td>-0.034001</td>\n",
       "      <td>-0.023727</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-28</td>\n",
       "      <td>-24</td>\n",
       "      <td>-0.011942</td>\n",
       "      <td>-0.003767</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-03-31</td>\n",
       "      <td>-23</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>-0.012956</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-01</td>\n",
       "      <td>-22</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-02</td>\n",
       "      <td>-21</td>\n",
       "      <td>-0.002500</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-03</td>\n",
       "      <td>-20</td>\n",
       "      <td>-0.000627</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-04</td>\n",
       "      <td>-19</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-07</td>\n",
       "      <td>-18</td>\n",
       "      <td>-0.013750</td>\n",
       "      <td>-0.012424</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-08</td>\n",
       "      <td>-17</td>\n",
       "      <td>-0.032953</td>\n",
       "      <td>-0.028192</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-09</td>\n",
       "      <td>-16</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>0.014953</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-10</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.005202</td>\n",
       "      <td>-0.008275</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-11</td>\n",
       "      <td>-14</td>\n",
       "      <td>-0.005882</td>\n",
       "      <td>0.012323</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-14</td>\n",
       "      <td>-13</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>-12</td>\n",
       "      <td>-0.019117</td>\n",
       "      <td>-0.019706</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-16</td>\n",
       "      <td>-11</td>\n",
       "      <td>0.017473</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-17</td>\n",
       "      <td>-10</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>0.008610</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-18</td>\n",
       "      <td>-9</td>\n",
       "      <td>0.016404</td>\n",
       "      <td>0.002999</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-21</td>\n",
       "      <td>-8</td>\n",
       "      <td>0.018722</td>\n",
       "      <td>0.019709</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-22</td>\n",
       "      <td>-7</td>\n",
       "      <td>-0.010773</td>\n",
       "      <td>-0.002477</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-23</td>\n",
       "      <td>-6</td>\n",
       "      <td>-0.012172</td>\n",
       "      <td>-0.015957</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-24</td>\n",
       "      <td>-5</td>\n",
       "      <td>0.014267</td>\n",
       "      <td>0.012869</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-25</td>\n",
       "      <td>-4</td>\n",
       "      <td>-0.007673</td>\n",
       "      <td>-0.011161</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-28</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.006443</td>\n",
       "      <td>0.009925</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-29</td>\n",
       "      <td>-2</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>0.007369</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-04-30</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042784</td>\n",
       "      <td>0.032158</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-05-02</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.226087</td>\n",
       "      <td>-0.227285</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-05-05</td>\n",
       "      <td>2</td>\n",
       "      <td>0.026270</td>\n",
       "      <td>0.031271</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-05-06</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>-0.002611</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>10078</td>\n",
       "      <td>2008-05-01</td>\n",
       "      <td>2008-05-07</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.011556</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>-0.001652</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     isevt  permno       edate       rdate  evttime       ret     abret  \\\n",
       "120      0   10078  2008-05-01  2008-03-12      121  0.002364       NaN   \n",
       "121      0   10078  2008-05-01  2008-03-13      122 -0.010023       NaN   \n",
       "122      0   10078  2008-05-01  2008-03-14      123 -0.023228       NaN   \n",
       "123      0   10078  2008-05-01  2008-03-17      124 -0.008537       NaN   \n",
       "124      0   10078  2008-05-01  2008-03-18      125  0.026445       NaN   \n",
       "125      1   10078  2008-05-01  2008-03-19      -30 -0.061114 -0.040172   \n",
       "126      1   10078  2008-05-01  2008-03-20      -29  0.022336  0.007946   \n",
       "127      1   10078  2008-05-01  2008-03-24      -28  0.021848  0.010089   \n",
       "128      1   10078  2008-05-01  2008-03-25      -27  0.000611 -0.000499   \n",
       "129      1   10078  2008-05-01  2008-03-26      -26  0.005495  0.013121   \n",
       "130      1   10078  2008-05-01  2008-03-27      -25 -0.034001 -0.023727   \n",
       "131      1   10078  2008-05-01  2008-03-28      -24 -0.011942 -0.003767   \n",
       "132      1   10078  2008-05-01  2008-03-31      -23 -0.012087 -0.012956   \n",
       "133      1   10078  2008-05-01  2008-04-01      -22  0.030264  0.004174   \n",
       "134      1   10078  2008-05-01  2008-04-02      -21 -0.002500  0.000248   \n",
       "135      1   10078  2008-05-01  2008-04-03      -20 -0.000627 -0.000415   \n",
       "136      1   10078  2008-05-01  2008-04-04      -19  0.003135  0.002183   \n",
       "137      1   10078  2008-05-01  2008-04-07      -18 -0.013750 -0.012424   \n",
       "138      1   10078  2008-05-01  2008-04-08      -17 -0.032953 -0.028192   \n",
       "139      1   10078  2008-05-01  2008-04-09      -16  0.007864  0.014953   \n",
       "140      1   10078  2008-05-01  2008-04-10      -15 -0.005202 -0.008275   \n",
       "141      1   10078  2008-05-01  2008-04-11      -14 -0.005882  0.012323   \n",
       "142      1   10078  2008-05-01  2008-04-14      -13 -0.002630  0.001308   \n",
       "143      1   10078  2008-05-01  2008-04-15      -12 -0.019117 -0.019706   \n",
       "144      1   10078  2008-05-01  2008-04-16      -11  0.017473  0.002558   \n",
       "145      1   10078  2008-05-01  2008-04-17      -10  0.006605  0.008610   \n",
       "146      1   10078  2008-05-01  2008-04-18       -9  0.016404  0.002999   \n",
       "147      1   10078  2008-05-01  2008-04-21       -8  0.018722  0.019709   \n",
       "148      1   10078  2008-05-01  2008-04-22       -7 -0.010773 -0.002477   \n",
       "149      1   10078  2008-05-01  2008-04-23       -6 -0.012172 -0.015957   \n",
       "150      1   10078  2008-05-01  2008-04-24       -5  0.014267  0.012869   \n",
       "151      1   10078  2008-05-01  2008-04-25       -4 -0.007673 -0.011161   \n",
       "152      1   10078  2008-05-01  2008-04-28       -3  0.006443  0.009925   \n",
       "153      1   10078  2008-05-01  2008-04-29       -2  0.002561  0.007369   \n",
       "154      1   10078  2008-05-01  2008-04-30       -1  0.000000  0.004095   \n",
       "155      1   10078  2008-05-01  2008-05-01        0  0.042784  0.032158   \n",
       "156      1   10078  2008-05-01  2008-05-02        1 -0.226087 -0.227285   \n",
       "157      1   10078  2008-05-01  2008-05-05        2  0.026270  0.031271   \n",
       "158      1   10078  2008-05-01  2008-05-06        3  0.000771 -0.002611   \n",
       "159      1   10078  2008-05-01  2008-05-07        4 -0.011556  0.002717   \n",
       "\n",
       "        alpha  _nobs  \n",
       "120       NaN    NaN  \n",
       "121       NaN    NaN  \n",
       "122       NaN    NaN  \n",
       "123       NaN    NaN  \n",
       "124       NaN    NaN  \n",
       "125 -0.001652  125.0  \n",
       "126 -0.001652  125.0  \n",
       "127 -0.001652  125.0  \n",
       "128 -0.001652  125.0  \n",
       "129 -0.001652  125.0  \n",
       "130 -0.001652  125.0  \n",
       "131 -0.001652  125.0  \n",
       "132 -0.001652  125.0  \n",
       "133 -0.001652  125.0  \n",
       "134 -0.001652  125.0  \n",
       "135 -0.001652  125.0  \n",
       "136 -0.001652  125.0  \n",
       "137 -0.001652  125.0  \n",
       "138 -0.001652  125.0  \n",
       "139 -0.001652  125.0  \n",
       "140 -0.001652  125.0  \n",
       "141 -0.001652  125.0  \n",
       "142 -0.001652  125.0  \n",
       "143 -0.001652  125.0  \n",
       "144 -0.001652  125.0  \n",
       "145 -0.001652  125.0  \n",
       "146 -0.001652  125.0  \n",
       "147 -0.001652  125.0  \n",
       "148 -0.001652  125.0  \n",
       "149 -0.001652  125.0  \n",
       "150 -0.001652  125.0  \n",
       "151 -0.001652  125.0  \n",
       "152 -0.001652  125.0  \n",
       "153 -0.001652  125.0  \n",
       "154 -0.001652  125.0  \n",
       "155 -0.001652  125.0  \n",
       "156 -0.001652  125.0  \n",
       "157 -0.001652  125.0  \n",
       "158 -0.001652  125.0  \n",
       "159 -0.001652  125.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_30d_call.iloc[120:160]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
