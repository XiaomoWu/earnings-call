{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import comet_ml\n",
    "\n",
    "from argparse import Namespace\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "\n",
    "# working directory\n",
    "ROOT_DIR = '.'\n",
    "DATA_DIR = f'{ROOT_DIR}/data'\n",
    "CHECKPOINT_DIR = 'd:/checkpoints/earnings-call'\n",
    "CHECKPOINT_TEMP_DIR = f'{ROOT_DIR}/checkpoint/earnings-call/temp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `val` and `train` are of same period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Txt + Fin-ratio\n",
    "class CCDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, split_window, split_type, text_in_dataset, roll_type, print_window, preembeddings, targets_df, split_df, valid_transcriptids=None):\n",
    "        '''\n",
    "        Args:\n",
    "            preembeddings (from globals): list of embeddings. Each element is a tensor (S, E) where S is number of sentences in a call\n",
    "            targets_df (from globals): DataFrame of targets variables.\n",
    "            split_df (from globals):\n",
    "            split_window: str. e.g., \"roll-09\"\n",
    "            split_type: str. 'train' or 'test'\n",
    "            text_only: only output CAR and transcripts if true, otherwise also output financial ratios\n",
    "            transcriptids: list. If provided, only the given transcripts will be used in generating the Dataset. `transcriptids` is applied **on top of** `split_window` and `split_type`\n",
    "        '''\n",
    "\n",
    "        # get split dates from `split_df`\n",
    "        _, train_start, train_end, test_start, test_end, _ = tuple(split_df.loc[(split_df.window==split_window) & (split_df.roll_type==roll_type)].iloc[0])\n",
    "        # print current window\n",
    "        if print_window:\n",
    "            print(f'Current window: {split_window} ({roll_type}) \\n(train: {train_start} to {train_end}) (test: {test_start} to {test_end})')\n",
    "        \n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d').date()\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d').date()\n",
    "        test_start = datetime.strptime(test_start, '%Y-%m-%d').date()\n",
    "        test_end = datetime.strptime(test_end, '%Y-%m-%d').date()\n",
    "        \n",
    "        # select valid transcriptids (preemb_keys) according to split dates \n",
    "        if split_type=='train':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(train_start, train_end)].transcriptid.sample(frac=1, random_state=42).tolist()\n",
    "            transcriptids = transcriptids[:int(len(transcriptids)*0.9)]\n",
    "            \n",
    "        if split_type=='val':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(train_start, train_end)].transcriptid.sample(frac=1, random_state=42).tolist()\n",
    "            transcriptids = transcriptids[int(len(transcriptids)*0.9):]\n",
    "\n",
    "        elif split_type=='test':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(test_start, test_end)].transcriptid.tolist()\n",
    "\n",
    "        self.valid_preemb_keys = set(transcriptids).intersection(set(preembeddings.keys()))\n",
    "        \n",
    "        if valid_transcriptids is not None:\n",
    "            self.valid_preemb_keys = self.valid_preemb_keys.intersection(set(valid_transcriptids))\n",
    "        \n",
    "        # self attributes\n",
    "        self.text_in_dataset = text_in_dataset\n",
    "        if text_in_dataset:\n",
    "            self.preembeddings = preembeddings\n",
    "        self.targets_df = targets_df\n",
    "        self.sent_len = sorted([(k, preembeddings[k].shape[0]) for k in self.valid_preemb_keys], key=itemgetter(1))\n",
    "        self.train_start = train_start\n",
    "        self.train_end = train_end\n",
    "        self.test_start = test_start\n",
    "        self.test_end = test_end\n",
    "        self.n_samples = len(self.sent_len)\n",
    "        self.split_window = split_window\n",
    "        self.split_type = split_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.valid_preemb_keys))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        transcriptid = self.sent_len[idx][0]\n",
    "        targets = self.targets_df[self.targets_df.transcriptid==transcriptid].iloc[0]\n",
    "        \n",
    "        # all of the following targests are\n",
    "        # of type `numpy.float64`\n",
    "        docid = targets.docid\n",
    "        \n",
    "        sue = targets.sue\n",
    "        sest = targets.sest\n",
    "        car_0_30 = targets.car_0_30\n",
    "        car_0_30_norm = targets.car_0_30_norm\n",
    "        revision = targets.revision\n",
    "        revision_norm = targets.revision_norm\n",
    "        inflow = targets.inflow\n",
    "        inflow_norm = targets.inflow_norm\n",
    "        \n",
    "        alpha = targets.alpha\n",
    "        volatility = targets.volatility\n",
    "        mcap = targets.mcap/1e6\n",
    "        bm = targets.bm\n",
    "        roa = targets.roa\n",
    "        debt_asset = targets.debt_asset\n",
    "        numest = targets.numest\n",
    "        smedest = targets.smedest\n",
    "        sstdest = targets.sstdest\n",
    "        car_m1_m1 = targets.car_m1_m1\n",
    "        car_m2_m2 = targets.car_m2_m2\n",
    "        car_m30_m3 = targets.car_m30_m3\n",
    "        volume = targets.volume\n",
    "        \n",
    "        if self.text_in_dataset:\n",
    "            # inputs: preembeddings\n",
    "            embeddings = self.preembeddings[transcriptid]\n",
    "            \n",
    "            return car_0_30, car_0_30_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "                   transcriptid, embeddings, \\\n",
    "                   [alpha, car_m1_m1, car_m2_m2, car_m30_m3, sest, sue, numest, sstdest, smedest, mcap, roa, bm, debt_asset, volatility, volume]\n",
    "        else:\n",
    "            return docid, \\\n",
    "                   torch.tensor(car_0_30,dtype=torch.float32), \\\n",
    "                   torch.tensor(car_0_30_norm,dtype=torch.float32), \\\n",
    "                   torch.tensor([alpha, car_m1_m1, car_m2_m2, car_m30_m3, sest, sue, numest, sstdest, smedest, mcap, roa, bm, debt_asset, volatility, volume], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: position encoder\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # pe: (max_len, 1, d_model)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :] # (S, N, E)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "# Model: Base\n",
    "class CC(pl.LightningModule):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hparams = Namespace(**hparams)\n",
    "        # self.text_in_dataset will be filled during instanciating.\n",
    "        \n",
    "        global preembeddings, targets_df, split_df\n",
    "        self.preembeddings = preembeddings\n",
    "        self.targets_df = targets_df\n",
    "        self.split_df = split_df\n",
    "\n",
    "    # forward\n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    # loss\n",
    "    def mse_loss(self, y, t):\n",
    "        return F.mse_loss(y, t)\n",
    "        \n",
    "    # validation step\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        mse = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "        rmse = torch.sqrt(mse)\n",
    "        \n",
    "        log_dict = {'val_rmse': rmse}\n",
    "        \n",
    "        if 'val_loss_car' in outputs[0]:\n",
    "            rmse_car = torch.sqrt(torch.stack([x['val_loss_car'] for x in outputs]).mean())\n",
    "            log_dict['val_rmse_car'] = rmse_car\n",
    "            \n",
    "        if 'val_loss_inflow' in outputs[0]:\n",
    "            rmse_inflow = torch.sqrt(torch.stack([x['val_loss_inflow'] for x in outputs]).mean())\n",
    "            log_dict['val_rmse_inflow'] = rmse_inflow\n",
    "\n",
    "        if 'val_loss_revision' in outputs[0]:\n",
    "            rmse_revision = torch.sqrt(torch.stack([x['val_loss_revision'] for x in outputs]).mean())\n",
    "            log_dict['val_rmse_revision'] = rmse_revision\n",
    "\n",
    "        return {'val_loss': mse, 'log': log_dict}\n",
    "    \n",
    "    # test step\n",
    "    def test_epoch_end(self, outputs):\n",
    "        mse = torch.stack([x['test_loss'] for x in outputs]).mean()\n",
    "        rmse = torch.sqrt(mse)\n",
    "        \n",
    "        log_dict = {'test_rmse': rmse}\n",
    "        \n",
    "        if 'test_loss_car' in outputs[0]:\n",
    "            rmse_car = torch.sqrt(torch.stack([x['test_loss_car'] for x in outputs]).mean())\n",
    "            log_dict['test_rmse_car'] = rmse_car\n",
    "\n",
    "        if 'test_loss_inflow' in outputs[0]:\n",
    "            rmse_inflow = torch.sqrt(torch.stack([x['test_loss_inflow'] for x in outputs]).mean())\n",
    "            log_dict['test_rmse_inflow'] = rmse_inflow\n",
    "            \n",
    "        if 'test_loss_revision' in outputs[0]:\n",
    "            rmse_revision = torch.sqrt(torch.stack([x['test_loss_revision'] for x in outputs]).mean())\n",
    "            log_dict['test_rmse_revision'] = rmse_revision\n",
    "            \n",
    "        return {'test_loss': mse, 'log': log_dict, 'progress_bar':log_dict}\n",
    "    \n",
    "    # Dataset\n",
    "    def prepare_data(self):\n",
    "        \n",
    "        self.train_dataset = CCDataset(self.hparams.window, split_type='train', text_in_dataset=self.text_in_dataset,\n",
    "                                       roll_type=self.hparams.roll_type, print_window=True, preembeddings=self.preembeddings,\n",
    "                                       targets_df=self.targets_df, split_df=self.split_df)\n",
    "        self.val_dataset = CCDataset(self.hparams.window, split_type='val', text_in_dataset=self.text_in_dataset,\n",
    "                                     roll_type=self.hparams.roll_type, print_window=False, preembeddings=self.preembeddings,\n",
    "                                       targets_df=self.targets_df, split_df=self.split_df)\n",
    "        self.test_dataset = CCDataset(self.hparams.window, split_type='test', text_in_dataset=self.text_in_dataset, \n",
    "                                      roll_type=self.hparams.roll_type, print_window=False, preembeddings=self.preembeddings,\n",
    "                                       targets_df=self.targets_df, split_df=self.split_df)\n",
    "\n",
    "    # DataLoader\n",
    "    def train_dataloader(self):\n",
    "        # Caution:\n",
    "        # - If you enable `BatchNorm`, then must set `drop_last=True`.\n",
    "\n",
    "        collate_fn = self.collate_fn if self.text_in_dataset else None\n",
    "        return DataLoader(self.train_dataset, batch_size=self.hparams.batch_size, shuffle=True, drop_last=True, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        # Caution: \n",
    "        # - To improve the validation speed, I'll set val_batch_size to 4. \n",
    "        # - Must set `drop_last=True`, otherwise the `val_loss` tensors for different batches won't match and hence give you error.\n",
    "        # - Not to set `val_batch_size` too large (e.g., 16), otherwise you'll lose precious validation data points\n",
    "        \n",
    "        collate_fn = self.collate_fn if self.text_in_dataset else None\n",
    "        return DataLoader(self.val_dataset, batch_size=self.hparams.val_batch_size, num_workers=0, pin_memory=True, collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        collate_fn = self.collate_fn if self.text_in_dataset else None\n",
    "        return DataLoader(self.test_dataset, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        '''create mini-batch\n",
    "\n",
    "        Retures:\n",
    "            embeddings: tensor, (N, S, E)\n",
    "            mask: tensor, (N, S)\n",
    "            sue,car,selead,sest: tensor, (N,)\n",
    "        '''\n",
    "        \n",
    "        # embeddings: (N, S, E)\n",
    "        car_0_30, car_0_30_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, \\\n",
    "        fin_ratios = zip(*data)\n",
    "        \n",
    "        # pad sequence\n",
    "        # the number of `padding_value` is irrelevant, since we'll \n",
    "        # apply a mask in the Transformer encoder, which will \n",
    "        # eliminate the padded positions.\n",
    "        valid_seq_len = [emb.shape[-2] for emb in embeddings]\n",
    "        embeddings = pad_sequence(embeddings, batch_first=True, padding_value=0) # (N, T, E)\n",
    "\n",
    "        # mask: (N, T)\n",
    "        mask = torch.ones((embeddings.shape[0], embeddings.shape[1]))\n",
    "        for i, length in enumerate(valid_seq_len):\n",
    "            mask[i, :length] = 0\n",
    "        mask = mask == 1\n",
    "        \n",
    "        return torch.tensor(car_0_30, dtype=torch.float32), torch.tensor(car_0_30_norm, dtype=torch.float32), \\\n",
    "               torch.tensor(inflow, dtype=torch.float32), torch.tensor(inflow_norm, dtype=torch.float32), \\\n",
    "               torch.tensor(revision, dtype=torch.float32), torch.tensor(revision_norm, dtype=torch.float32), \\\n",
    "               torch.tensor(transcriptid, dtype=torch.float32), embeddings.float(), mask, \\\n",
    "               torch.tensor(fin_ratios, dtype=torch.float32)\n",
    "        \n",
    "    # optimizer\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers: load targets\n",
    "def load_targets(targets_name):\n",
    "    if 'targets_df' not in globals():\n",
    "        print(f'Loading targets...@{Now()}')\n",
    "        globals()['targets_df'] = pd.read_feather(f'{DATA_DIR}/{targets_name}.feather')\n",
    "        print(f'Loading finished. @{Now()}')\n",
    "        \n",
    "# helpers: load preembeddings\n",
    "def load_preembeddings(preembedding_type):\n",
    "    if 'preembeddings' not in globals():\n",
    "        print(f'Loading preembeddings...@{Now()}')\n",
    "        globals()['preembeddings'] = torch.load(f\"{DATA_DIR}/embeddings/preembeddings_{preembedding_type}.pt\")\n",
    "        print(f'Loading finished. @{Now()}')\n",
    "        \n",
    "# helpers: load split_df\n",
    "def load_split_df(roll_type):\n",
    "    split_df = pd.read_csv(f'{DATA_DIR}/split_dates.csv')\n",
    "    globals()['split_df'] = split_df.loc[split_df.roll_type==roll_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_hparams = {\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded', # key!\n",
    "    'targets_name': 'f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_text_norm', # key!\n",
    "    'roll_type': '3y',  # key!\n",
    "}    \n",
    "\n",
    "# load split_df\n",
    "load_split_df(model_hparams['roll_type'])\n",
    "    \n",
    "# load targets_df\n",
    "load_targets(model_hparams['targets_name'])\n",
    "\n",
    "# load preembeddings\n",
    "load_preembeddings(model_hparams['preembedding_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (MTL, hardshare) x*car + (1-x)*inf ~ txt + fr\n",
    "class CCTransformerMTLInfHard(CC):\n",
    "    def __init__(self, hparams):\n",
    "        # `self.hparams` will be created by super().__init__\n",
    "        super().__init__(hparams)\n",
    "        \n",
    "        # specify model type\n",
    "        self.model_type = 'TSFM'\n",
    "        self.target_type = 'car+inf'\n",
    "        self.feature_type = 'txt+fr'\n",
    "        self.emb_share = 'hard'\n",
    "        self.normalize_target = True\n",
    "        \n",
    "        self.attn_type = 'dotprod'\n",
    "        self.text_in_dataset = True if self.feature_type!='fr' else False \n",
    "        self.n_covariate = 15\n",
    "        \n",
    "        # positional encoding\n",
    "        self.encoder_pos = PositionalEncoding(self.hparams.d_model, self.hparams.attn_dropout)\n",
    "        \n",
    "        # encoder layers for input, expert, nonexpert\n",
    "        encoder_layers_expert = nn.TransformerEncoderLayer(self.hparams.d_model, self.hparams.n_head_encoder, self.hparams.dff, self.hparams.attn_dropout)\n",
    "        \n",
    "        # atten layers\n",
    "        self.attn_layers_car = nn.Linear(self.hparams.d_model, 1)\n",
    "        self.attn_dropout_1 = nn.Dropout(self.hparams.attn_dropout)\n",
    "        \n",
    "        # Build Encoder\n",
    "        self.encoder_expert = nn.TransformerEncoder(encoder_layers_expert, self.hparams.n_layers_encoder)\n",
    "        \n",
    "        # linear layer to produce final result\n",
    "        self.linear_car_1 = nn.Linear(self.hparams.d_model, self.hparams.d_model)\n",
    "        self.linear_car_2 = nn.Linear(self.hparams.d_model, self.hparams.final_tdim)\n",
    "        self.linear_car_3 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        self.linear_car_4 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        self.linear_car_5 = nn.Linear(self.hparams.final_tdim+self.n_covariate, 1)\n",
    "        \n",
    "        self.linear_inflow = nn.Linear(self.hparams.final_tdim, 1)\n",
    "        # self.linear_revision = nn.Linear(hparam.final_tdim, 1)\n",
    "        \n",
    "        # dropout for final fc layers\n",
    "        self.final_dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        self.final_dropout_2 = nn.Dropout(self.hparams.dropout)\n",
    "        self.final_dropout_3 = nn.Dropout(self.hparams.dropout)\n",
    "        \n",
    "        # layer normalization\n",
    "        if self.hparams.normalize_layer:\n",
    "            self.layer_norm = nn.LayerNorm(self.hparams.final_tdim+self.n_covariate)\n",
    "            \n",
    "        # batch normalization\n",
    "        if self.hparams.normalize_batch:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.n_covariate)\n",
    "\n",
    "    # forward\n",
    "    def forward(self, embeddings, src_key_padding_mask, fin_ratios):\n",
    "        \n",
    "        bsz, embed_dim = embeddings.size(0), embeddings.size(2)\n",
    "        \n",
    "        # if S is longer than max_seq_len, cut\n",
    "        embeddings = embeddings[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        src_key_padding_mask = src_key_padding_mask[:,:self.hparams.max_seq_len] # (N, S)\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1) # (S, N, E)\n",
    "        \n",
    "        # positional encoding\n",
    "        x = self.encoder_pos(embeddings) # (S, N, E)\n",
    "        \n",
    "        # encode\n",
    "        x_expert = self.encoder_expert(x, src_key_padding_mask=src_key_padding_mask).transpose(0,1) # (N, S, E)\n",
    "        \n",
    "        # multiply with attn\n",
    "        x_attn = self.attn_dropout_1(F.softmax(self.attn_layers_car(x_expert), dim=1)) # (N, S, 1)\n",
    "        x_expert = torch.bmm(x_expert.transpose(-1,-2), x_attn).squeeze(-1) # (N, E)\n",
    "        \n",
    "        # mix with covariate\n",
    "        x_expert = self.final_dropout_1(F.relu(self.linear_car_1(x_expert))) # (N, E)\n",
    "        x_expert = F.relu(self.linear_car_2(x_expert)) # (N, final_tdim)\n",
    "        \n",
    "        # batch normalization\n",
    "        if self.hparams.normalize_batch:\n",
    "            fin_ratio = self.batch_norm(fin_ratios)\n",
    "        \n",
    "        x_car = torch.cat([x_expert, fin_ratios], dim=-1) # (N, X + final_tdim) where X is the number of covariate (n_covariate)\n",
    "\n",
    "        # ouput y\n",
    "        y_inflow = self.linear_inflow(x_expert)\n",
    "        \n",
    "        x_car = self.final_dropout_2(F.relu(self.linear_car_3(x_car))) # (N, X + final_tdim)\n",
    "        y_car = self.linear_car_5(x_car) # (N,1)\n",
    "        \n",
    "        # final output\n",
    "        return y_car, y_inflow\n",
    "    \n",
    "    # traning step\n",
    "    def training_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # get batch size\n",
    "        bsz = fin_ratios.size(0)\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_inflow = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        \n",
    "        assert self.hparams.car_weight+self.hparams.inflow_weight==1, 'car_weight + inflow_weight != 1'\n",
    "        \n",
    "        loss = self.hparams.car_weight*loss_car + self.hparams.inflow_weight*loss_inflow\n",
    "        \n",
    "        # logging\n",
    "        return {'loss': loss, 'log': {'train_loss': loss}}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # get batch size\n",
    "        bsz = fin_ratios.size(0)\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_inflow = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = loss_car + loss_inflow\n",
    "        \n",
    "        # logging\n",
    "        return {'val_loss': loss, 'val_loss_car': loss_car, 'val_loss_inflow': loss_inflow}\n",
    "\n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # get batch size\n",
    "        bsz = fin_ratios.size(0)\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_inflow = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = loss_car + loss_inflow\n",
    "\n",
    "        # logging\n",
    "        return {'test_loss': loss, 'test_loss_car': loss_car, 'test_loss_inflow': loss_inflow}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STL-text-fr\n",
    "class CCTransformerSTLTxtFr(CC):\n",
    "    def __init__(self, hparams):\n",
    "        # `self.hparams` will be created by super().__init__\n",
    "        super().__init__(hparams)\n",
    "        \n",
    "        # specify model type\n",
    "        self.model_type = 'TSFM'\n",
    "        self.target_type = 'car'\n",
    "        self.feature_type = 'txt+fr'\n",
    "        self.normalize_target = True\n",
    "        self.attn_type = 'dotprod'\n",
    "        self.text_in_dataset = True if self.feature_type!='fr' else False \n",
    "\n",
    "        self.n_covariate = 15\n",
    "        \n",
    "        # positional encoding\n",
    "        self.encoder_pos = PositionalEncoding(self.hparams.d_model, self.hparams.attn_dropout)\n",
    "        \n",
    "        # encoder layers for input, expert, nonexpert\n",
    "        encoder_layers_expert = nn.TransformerEncoderLayer(self.hparams.d_model, self.hparams.n_head_encoder, self.hparams.dff, self.hparams.attn_dropout)\n",
    "        \n",
    "        # atten layers for SUE, CAR, SELEAD, SEST\n",
    "        self.attn_layers_car = nn.Linear(self.hparams.d_model, 1)\n",
    "        self.attn_dropout_1 = nn.Dropout(self.hparams.attn_dropout)\n",
    "        \n",
    "        # Build Encoder and Decoder\n",
    "        self.encoder_expert = nn.TransformerEncoder(encoder_layers_expert, self.hparams.n_layers_encoder)\n",
    "        \n",
    "        # linear layer to produce final result\n",
    "        self.fc_1 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        self.fc_2 = nn.Linear(self.hparams.final_tdim+self.n_covariate, 1)\n",
    "        \n",
    "        # dropout for final fc layers\n",
    "        self.fc_dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        \n",
    "        # layer normalization\n",
    "        if self.hparams.normalize_layer:\n",
    "            self.layer_norm = nn.LayerNorm(self.hparams.final_tdim+self.n_covariate)\n",
    "            \n",
    "        # batch normalization\n",
    "        if self.hparams.normalize_batch:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.n_covariate)\n",
    "\n",
    "    # forward\n",
    "    def forward(self, embeddings, src_key_padding_mask, fin_ratios):\n",
    "        \n",
    "        bsz, embed_dim = embeddings.size(0), embeddings.size(2)\n",
    "        \n",
    "        # if S is longer than max_seq_len, cut\n",
    "        embeddings = embeddings[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        src_key_padding_mask = src_key_padding_mask[:,:self.hparams.max_seq_len] # (N, S)\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1) # (S, N, E)\n",
    "        \n",
    "        # positional encoding\n",
    "        x = self.encoder_pos(embeddings) # (S, N, E)\n",
    "        \n",
    "        # encode\n",
    "        x_expert = self.encoder_expert(x, src_key_padding_mask=src_key_padding_mask).transpose(0,1) # (N, S, E)\n",
    "        \n",
    "        # decode with attn\n",
    "        x_attn = self.attn_dropout_1(F.softmax(self.attn_layers_car(x_expert), dim=1)) # (N, S, 1)\n",
    "        x_expert = torch.bmm(x_expert.transpose(-1,-2), x_attn).squeeze(-1) # (N, E)\n",
    "        \n",
    "        # batch norm fin-ratios\n",
    "        if self.hparams.normalize_batch:\n",
    "            fin_ratios = self.batch_norm(fin_ratios)\n",
    "        \n",
    "        x_final = torch.cat([x_expert, fin_ratios], dim=-1) # (N, E+X) where X is the number of covariate (n_covariate)\n",
    "\n",
    "        # final FC\n",
    "        x_final = self.fc_dropout_1(F.relu(self.fc_1(x_final))) # (N, E+X)\n",
    "        y_car = self.fc_2(x_final) # (N, 1)\n",
    "        \n",
    "        # final output\n",
    "        return y_car\n",
    "    \n",
    "    # traning step\n",
    "    def training_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # get batch size\n",
    "        bsz = fin_ratios.size(0)\n",
    "        \n",
    "        # forward\n",
    "        y_car = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "\n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        # logging\n",
    "        return {'loss': loss_car, 'log': {'train_loss': loss_car}}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # get batch size\n",
    "        bsz = fin_ratios.size(0)\n",
    "\n",
    "        # forward\n",
    "        y_car = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "\n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "\n",
    "        # logging\n",
    "        return {'val_loss': loss_car}\n",
    "\n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # get batch size\n",
    "        bsz = fin_ratios.size(0)\n",
    "\n",
    "        # forward\n",
    "        y_car = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "\n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "\n",
    "        # logging\n",
    "        return {'test_loss': loss_car}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CCTransformerMTLInfHard.load_from_checkpoint('D:\\Checkpoints\\earnings-call\\MTL-01-3y-(0.5car+0.5inf~txt+fr)-hardshare-norm\\TSFM_roll-01_epoch=9_v0.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CCTransformerMTLInfHard' object has no attribute 'to_json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-74d572bd2453>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    592\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[1;32m--> 594\u001b[1;33m             type(self).__name__, name))\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'CCTransformerMTLInfHard' object has no attribute 'to_json'"
     ]
    }
   ],
   "source": [
    "model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'checkpoint_callback_best_model_score', 'checkpoint_callback_best_model_path', 'early_stop_callback_state_dict', 'optimizer_states', 'lr_schedulers', 'state_dict', 'hparams_name', 'hyper_parameters'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('attn_layers_car.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0046,  0.0055, -0.0117,  ...,  0.0156, -0.0165,  0.0100]])),\n",
       " ('attn_layers_car.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0113])),\n",
       " ('encoder_expert.layers.0.self_attn.in_proj_weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0253,  0.0111,  0.0024,  ..., -0.0128,  0.0160,  0.0131],\n",
       "          [-0.0076,  0.0186,  0.0307,  ...,  0.0360,  0.0151, -0.0067],\n",
       "          [ 0.0061, -0.0210, -0.0229,  ...,  0.0360,  0.0047,  0.0012],\n",
       "          ...,\n",
       "          [-0.0027, -0.0244,  0.0181,  ..., -0.0186,  0.0206, -0.0331],\n",
       "          [-0.0326,  0.0123, -0.0187,  ..., -0.0085,  0.0278,  0.0149],\n",
       "          [-0.0099, -0.0041,  0.0366,  ..., -0.0118,  0.0052, -0.0353]])),\n",
       " ('encoder_expert.layers.0.self_attn.in_proj_bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 2.0374e-04, -1.1255e-03,  4.5907e-04,  ...,  7.6145e-05,\n",
       "           6.2435e-04, -7.0612e-04])),\n",
       " ('encoder_expert.layers.0.self_attn.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0222,  0.0276, -0.0091,  ..., -0.0133, -0.0287, -0.0174],\n",
       "          [ 0.0181, -0.0054,  0.0144,  ...,  0.0018,  0.0067,  0.0289],\n",
       "          [ 0.0141,  0.0065, -0.0059,  ...,  0.0154, -0.0186,  0.0157],\n",
       "          ...,\n",
       "          [-0.0150,  0.0159,  0.0135,  ..., -0.0212, -0.0050, -0.0188],\n",
       "          [ 0.0238, -0.0129,  0.0219,  ...,  0.0003, -0.0212,  0.0204],\n",
       "          [ 0.0283, -0.0226, -0.0058,  ...,  0.0132,  0.0252, -0.0256]])),\n",
       " ('encoder_expert.layers.0.self_attn.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.5672e-03,  7.8503e-04, -1.8246e-05,  ...,  3.8972e-05,\n",
       "           6.8003e-05,  9.3040e-04])),\n",
       " ('encoder_expert.layers.0.linear1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0223, -0.0252, -0.0088,  ..., -0.0123,  0.0135,  0.0254],\n",
       "          [ 0.0221,  0.0217,  0.0252,  ...,  0.0029,  0.0082, -0.0260],\n",
       "          [ 0.0133,  0.0015, -0.0055,  ..., -0.0001, -0.0157, -0.0237],\n",
       "          ...,\n",
       "          [ 0.0024, -0.0167,  0.0201,  ..., -0.0261,  0.0006,  0.0012],\n",
       "          [ 0.0192, -0.0202,  0.0153,  ..., -0.0094,  0.0298, -0.0017],\n",
       "          [-0.0233, -0.0179, -0.0240,  ...,  0.0039,  0.0015,  0.0306]])),\n",
       " ('encoder_expert.layers.0.linear1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0043, -0.0227, -0.0204,  ..., -0.0290, -0.0209,  0.0250])),\n",
       " ('encoder_expert.layers.0.linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0136,  0.0203,  0.0104,  ..., -0.0213,  0.0017,  0.0035],\n",
       "          [ 0.0112,  0.0163,  0.0192,  ..., -0.0089,  0.0138, -0.0123],\n",
       "          [ 0.0153,  0.0077, -0.0221,  ..., -0.0126,  0.0171,  0.0022],\n",
       "          ...,\n",
       "          [-0.0091, -0.0047,  0.0105,  ..., -0.0176,  0.0209,  0.0126],\n",
       "          [-0.0028, -0.0078,  0.0146,  ...,  0.0156, -0.0192,  0.0210],\n",
       "          [-0.0098,  0.0119, -0.0204,  ..., -0.0042,  0.0104,  0.0177]])),\n",
       " ('encoder_expert.layers.0.linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0088,  0.0198,  0.0035,  ..., -0.0201, -0.0166,  0.0057])),\n",
       " ('encoder_expert.layers.0.norm1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0006, 0.9994, 0.9998,  ..., 1.0002, 0.9999, 1.0009])),\n",
       " ('encoder_expert.layers.0.norm1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.4571e-03,  8.0428e-04,  6.0770e-05,  ..., -5.8794e-05,\n",
       "           4.3141e-05,  9.2116e-04])),\n",
       " ('encoder_expert.layers.0.norm2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0009, 1.0000, 0.9995,  ..., 1.0001, 1.0000, 1.0010])),\n",
       " ('encoder_expert.layers.0.norm2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.2394e-03,  5.3444e-04,  8.2111e-05,  ..., -4.9233e-06,\n",
       "          -1.0422e-04,  9.4840e-04])),\n",
       " ('encoder_expert.layers.1.self_attn.in_proj_weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0259,  0.0107,  0.0023,  ..., -0.0125,  0.0157,  0.0132],\n",
       "          [-0.0080,  0.0204,  0.0309,  ...,  0.0360,  0.0154, -0.0065],\n",
       "          [ 0.0069, -0.0224, -0.0227,  ...,  0.0361,  0.0046,  0.0011],\n",
       "          ...,\n",
       "          [-0.0030, -0.0246,  0.0178,  ..., -0.0184,  0.0204, -0.0330],\n",
       "          [-0.0334,  0.0131, -0.0186,  ..., -0.0085,  0.0277,  0.0151],\n",
       "          [-0.0098, -0.0034,  0.0365,  ..., -0.0117,  0.0052, -0.0353]])),\n",
       " ('encoder_expert.layers.1.self_attn.in_proj_bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0003, -0.0009,  0.0004,  ...,  0.0001,  0.0008, -0.0007])),\n",
       " ('encoder_expert.layers.1.self_attn.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0220,  0.0277, -0.0062,  ..., -0.0127, -0.0288, -0.0183],\n",
       "          [ 0.0178, -0.0052,  0.0130,  ...,  0.0013,  0.0063,  0.0293],\n",
       "          [ 0.0149,  0.0059, -0.0071,  ...,  0.0158, -0.0181,  0.0147],\n",
       "          ...,\n",
       "          [-0.0149,  0.0159,  0.0155,  ..., -0.0204, -0.0047, -0.0180],\n",
       "          [ 0.0244, -0.0138,  0.0213,  ...,  0.0010, -0.0206,  0.0206],\n",
       "          [ 0.0286, -0.0230, -0.0084,  ...,  0.0126,  0.0254, -0.0259]])),\n",
       " ('encoder_expert.layers.1.self_attn.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.6448e-03,  4.3125e-04,  2.7933e-05,  ...,  2.8473e-04,\n",
       "           7.2577e-04,  9.5754e-04])),\n",
       " ('encoder_expert.layers.1.linear1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0218, -0.0254, -0.0099,  ..., -0.0117,  0.0125,  0.0255],\n",
       "          [ 0.0219,  0.0212,  0.0249,  ...,  0.0030,  0.0079, -0.0259],\n",
       "          [ 0.0141,  0.0005, -0.0055,  ..., -0.0002, -0.0169, -0.0243],\n",
       "          ...,\n",
       "          [ 0.0017, -0.0165,  0.0207,  ..., -0.0265,  0.0010,  0.0013],\n",
       "          [ 0.0186, -0.0202,  0.0153,  ..., -0.0094,  0.0298, -0.0018],\n",
       "          [-0.0223, -0.0179, -0.0240,  ...,  0.0038,  0.0017,  0.0304]])),\n",
       " ('encoder_expert.layers.1.linear1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0044, -0.0226, -0.0210,  ..., -0.0289, -0.0210,  0.0248])),\n",
       " ('encoder_expert.layers.1.linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0131,  0.0195,  0.0087,  ..., -0.0219,  0.0020,  0.0035],\n",
       "          [ 0.0112,  0.0166,  0.0185,  ..., -0.0086,  0.0135, -0.0128],\n",
       "          [ 0.0148,  0.0083, -0.0209,  ..., -0.0120,  0.0171,  0.0020],\n",
       "          ...,\n",
       "          [-0.0092, -0.0047,  0.0110,  ..., -0.0174,  0.0209,  0.0132],\n",
       "          [-0.0013, -0.0069,  0.0164,  ...,  0.0160, -0.0185,  0.0217],\n",
       "          [-0.0100,  0.0125, -0.0190,  ..., -0.0031,  0.0103,  0.0176]])),\n",
       " ('encoder_expert.layers.1.linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0091,  0.0197,  0.0036,  ..., -0.0200, -0.0157,  0.0059])),\n",
       " ('encoder_expert.layers.1.norm1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0009, 0.9995, 0.9994,  ..., 1.0002, 0.9987, 1.0011])),\n",
       " ('encoder_expert.layers.1.norm1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0017,  0.0005,  0.0001,  ...,  0.0002,  0.0008,  0.0011])),\n",
       " ('encoder_expert.layers.1.norm2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0006, 0.9998, 0.9992,  ..., 0.9999, 0.9987, 1.0011])),\n",
       " ('encoder_expert.layers.1.norm2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.6409e-03,  4.6970e-04,  2.6815e-04,  ...,  9.7226e-06,\n",
       "           8.0383e-04,  1.1783e-03])),\n",
       " ('encoder_expert.layers.2.self_attn.in_proj_weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0254,  0.0104,  0.0019,  ..., -0.0114,  0.0148,  0.0140],\n",
       "          [-0.0077,  0.0202,  0.0306,  ...,  0.0365,  0.0149, -0.0063],\n",
       "          [ 0.0062, -0.0221, -0.0227,  ...,  0.0361,  0.0045,  0.0012],\n",
       "          ...,\n",
       "          [-0.0027, -0.0253,  0.0173,  ..., -0.0180,  0.0201, -0.0330],\n",
       "          [-0.0346,  0.0124, -0.0172,  ..., -0.0088,  0.0280,  0.0154],\n",
       "          [-0.0101, -0.0026,  0.0361,  ..., -0.0116,  0.0050, -0.0353]])),\n",
       " ('encoder_expert.layers.2.self_attn.in_proj_bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0011, -0.0007,  0.0005,  ...,  0.0001,  0.0011, -0.0008])),\n",
       " ('encoder_expert.layers.2.self_attn.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0222,  0.0273, -0.0066,  ..., -0.0129, -0.0287, -0.0185],\n",
       "          [ 0.0178, -0.0054,  0.0127,  ...,  0.0013,  0.0064,  0.0293],\n",
       "          [ 0.0152,  0.0056, -0.0082,  ...,  0.0165, -0.0181,  0.0148],\n",
       "          ...,\n",
       "          [-0.0148,  0.0161,  0.0159,  ..., -0.0198, -0.0048, -0.0180],\n",
       "          [ 0.0244, -0.0138,  0.0213,  ...,  0.0010, -0.0204,  0.0208],\n",
       "          [ 0.0286, -0.0233, -0.0088,  ...,  0.0133,  0.0259, -0.0261]])),\n",
       " ('encoder_expert.layers.2.self_attn.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0017,  0.0004,  0.0001,  ...,  0.0002,  0.0009,  0.0013])),\n",
       " ('encoder_expert.layers.2.linear1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 2.1408e-02, -2.5947e-02, -1.0060e-02,  ..., -1.1659e-02,\n",
       "            1.2825e-02,  2.5468e-02],\n",
       "          [ 2.0663e-02,  2.0879e-02,  2.5318e-02,  ...,  2.6828e-03,\n",
       "            7.7396e-03, -2.6029e-02],\n",
       "          [ 1.4617e-02,  9.1555e-04, -5.2383e-03,  ..., -9.6297e-04,\n",
       "           -1.5820e-02, -2.5378e-02],\n",
       "          ...,\n",
       "          [ 1.1796e-05, -1.5622e-02,  2.2136e-02,  ..., -2.7652e-02,\n",
       "            2.0374e-03,  2.0620e-03],\n",
       "          [ 1.8545e-02, -2.0271e-02,  1.5537e-02,  ..., -9.7313e-03,\n",
       "            3.0025e-02, -1.9490e-03],\n",
       "          [-2.0980e-02, -1.7839e-02, -2.4119e-02,  ...,  3.3823e-03,\n",
       "            2.0220e-03,  3.0117e-02]])),\n",
       " ('encoder_expert.layers.2.linear1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0045, -0.0227, -0.0217,  ..., -0.0280, -0.0212,  0.0244])),\n",
       " ('encoder_expert.layers.2.linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0129,  0.0188,  0.0102,  ..., -0.0218,  0.0024,  0.0043],\n",
       "          [ 0.0116,  0.0171,  0.0191,  ..., -0.0080,  0.0135, -0.0127],\n",
       "          [ 0.0148,  0.0089, -0.0214,  ..., -0.0113,  0.0170,  0.0020],\n",
       "          ...,\n",
       "          [-0.0088, -0.0050,  0.0092,  ..., -0.0181,  0.0209,  0.0133],\n",
       "          [-0.0012, -0.0068,  0.0170,  ...,  0.0161, -0.0184,  0.0217],\n",
       "          [-0.0099,  0.0130, -0.0203,  ..., -0.0019,  0.0102,  0.0176]])),\n",
       " ('encoder_expert.layers.2.linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0091,  0.0199,  0.0039,  ..., -0.0205, -0.0157,  0.0064])),\n",
       " ('encoder_expert.layers.2.norm1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0012, 0.9994, 0.9986,  ..., 1.0001, 0.9983, 1.0013])),\n",
       " ('encoder_expert.layers.2.norm1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.8149e-03,  6.1272e-04,  2.9228e-04,  ...,  1.3158e-05,\n",
       "           8.8708e-04,  1.6371e-03])),\n",
       " ('encoder_expert.layers.2.norm2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0005, 0.9998, 0.9986,  ..., 1.0000, 0.9985, 1.0015])),\n",
       " ('encoder_expert.layers.2.norm2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0016,  0.0008,  0.0006,  ..., -0.0005,  0.0009,  0.0020])),\n",
       " ('encoder_expert.layers.3.self_attn.in_proj_weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0255,  0.0110,  0.0018,  ..., -0.0131,  0.0166,  0.0127],\n",
       "          [-0.0065,  0.0197,  0.0303,  ...,  0.0370,  0.0134, -0.0066],\n",
       "          [ 0.0059, -0.0222, -0.0230,  ...,  0.0363,  0.0043,  0.0013],\n",
       "          ...,\n",
       "          [-0.0017, -0.0255,  0.0169,  ..., -0.0176,  0.0197, -0.0328],\n",
       "          [-0.0348,  0.0127, -0.0155,  ..., -0.0099,  0.0291,  0.0159],\n",
       "          [-0.0093, -0.0025,  0.0355,  ..., -0.0110,  0.0044, -0.0352]])),\n",
       " ('encoder_expert.layers.3.self_attn.in_proj_bias',\n",
       "  Parameter containing:\n",
       "  tensor([-8.9266e-05, -1.1498e-03,  5.8212e-04,  ...,  1.4776e-04,\n",
       "           2.0780e-03, -6.3819e-04])),\n",
       " ('encoder_expert.layers.3.self_attn.out_proj.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0228,  0.0267, -0.0063,  ..., -0.0129, -0.0285, -0.0190],\n",
       "          [ 0.0175, -0.0055,  0.0121,  ...,  0.0016,  0.0067,  0.0288],\n",
       "          [ 0.0143,  0.0064, -0.0075,  ...,  0.0158, -0.0192,  0.0158],\n",
       "          ...,\n",
       "          [-0.0153,  0.0171,  0.0171,  ..., -0.0190, -0.0058, -0.0183],\n",
       "          [ 0.0243, -0.0133,  0.0223,  ...,  0.0013, -0.0210,  0.0217],\n",
       "          [ 0.0283, -0.0239, -0.0094,  ...,  0.0142,  0.0272, -0.0265]])),\n",
       " ('encoder_expert.layers.3.self_attn.out_proj.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0015,  0.0008, -0.0003,  ..., -0.0007,  0.0004,  0.0024])),\n",
       " ('encoder_expert.layers.3.linear1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0220, -0.0265, -0.0105,  ..., -0.0109,  0.0126,  0.0251],\n",
       "          [ 0.0224,  0.0216,  0.0255,  ...,  0.0024,  0.0092, -0.0277],\n",
       "          [ 0.0145,  0.0011, -0.0060,  ..., -0.0005, -0.0154, -0.0251],\n",
       "          ...,\n",
       "          [-0.0020, -0.0133,  0.0236,  ..., -0.0297,  0.0031,  0.0042],\n",
       "          [ 0.0189, -0.0203,  0.0156,  ..., -0.0102,  0.0304, -0.0024],\n",
       "          [-0.0197, -0.0189, -0.0253,  ...,  0.0039,  0.0011,  0.0288]])),\n",
       " ('encoder_expert.layers.3.linear1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0049, -0.0243, -0.0220,  ..., -0.0261, -0.0218,  0.0229])),\n",
       " ('encoder_expert.layers.3.linear2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0127,  0.0183,  0.0110,  ..., -0.0222,  0.0027,  0.0065],\n",
       "          [ 0.0113,  0.0173,  0.0193,  ..., -0.0079,  0.0135, -0.0137],\n",
       "          [ 0.0156,  0.0067, -0.0245,  ..., -0.0138,  0.0168,  0.0035],\n",
       "          ...,\n",
       "          [-0.0097, -0.0050,  0.0051,  ..., -0.0197,  0.0210,  0.0164],\n",
       "          [-0.0016, -0.0088,  0.0153,  ...,  0.0144, -0.0183,  0.0190],\n",
       "          [-0.0095,  0.0138, -0.0181,  ...,  0.0006,  0.0099,  0.0165]])),\n",
       " ('encoder_expert.layers.3.linear2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0090,  0.0204,  0.0028,  ..., -0.0213, -0.0166,  0.0083])),\n",
       " ('encoder_expert.layers.3.norm1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1.0005, 0.9992, 0.9971,  ..., 1.0004, 0.9972, 1.0024])),\n",
       " ('encoder_expert.layers.3.norm1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-1.5656e-03,  9.8470e-04, -5.6310e-04,  ..., -9.5282e-04,\n",
       "           6.8204e-05,  3.1441e-03])),\n",
       " ('encoder_expert.layers.3.norm2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([0.9935, 0.9959, 0.9950,  ..., 0.9955, 0.9949, 0.9980])),\n",
       " ('encoder_expert.layers.3.norm2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0031, -0.0017, -0.0023,  ...,  0.0030, -0.0023, -0.0011])),\n",
       " ('linear_car_1.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0017,  0.0235, -0.0312,  ...,  0.0274, -0.0136,  0.0145],\n",
       "          [-0.0231,  0.0116,  0.0070,  ..., -0.0197,  0.0085,  0.0041],\n",
       "          [-0.0160, -0.0074, -0.0088,  ...,  0.0242, -0.0250,  0.0109],\n",
       "          ...,\n",
       "          [ 0.0296,  0.0151,  0.0279,  ...,  0.0266,  0.0125,  0.0019],\n",
       "          [ 0.0163,  0.0108, -0.0014,  ..., -0.0169, -0.0252,  0.0097],\n",
       "          [-0.0137,  0.0063, -0.0244,  ...,  0.0113,  0.0179,  0.0155]])),\n",
       " ('linear_car_1.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0189,  0.0052, -0.0118,  ...,  0.0199,  0.0011,  0.0079])),\n",
       " ('linear_car_2.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0191,  0.0156,  0.0228,  ..., -0.0257, -0.0226,  0.0141],\n",
       "          [-0.0095, -0.0014, -0.0214,  ..., -0.0217,  0.0133,  0.0082],\n",
       "          [-0.0272,  0.0184, -0.0069,  ...,  0.0229,  0.0237, -0.0100],\n",
       "          ...,\n",
       "          [ 0.0276, -0.0306,  0.0256,  ..., -0.0081, -0.0125, -0.0039],\n",
       "          [ 0.0303,  0.0125,  0.0074,  ...,  0.0203, -0.0131,  0.0258],\n",
       "          [ 0.0254, -0.0232, -0.0306,  ...,  0.0067, -0.0003,  0.0249]])),\n",
       " ('linear_car_2.bias',\n",
       "  Parameter containing:\n",
       "  tensor([-0.0002,  0.0117,  0.0271,  ...,  0.0225,  0.0192, -0.0257])),\n",
       " ('linear_car_3.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0130,  0.0297,  0.0149,  ..., -0.0168, -0.0270,  0.0197],\n",
       "          [ 0.0125, -0.0124,  0.0024,  ..., -0.0248, -0.0378,  0.0261],\n",
       "          [-0.0178,  0.0320,  0.0249,  ..., -0.0177,  0.0344, -0.0154],\n",
       "          ...,\n",
       "          [ 0.0230,  0.0239, -0.0239,  ...,  0.0083,  0.0109,  0.0224],\n",
       "          [-0.0256, -0.0096,  0.0280,  ...,  0.0153,  0.0198, -0.0156],\n",
       "          [-0.0144, -0.0286,  0.0183,  ..., -0.0212, -0.0099, -0.0153]])),\n",
       " ('linear_car_3.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0072, -0.0231, -0.0211,  ..., -0.0052, -0.0110, -0.0367])),\n",
       " ('linear_car_4.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0282,  0.0154,  0.0302,  ..., -0.0130,  0.0213,  0.0137],\n",
       "          [-0.0107,  0.0272,  0.0185,  ..., -0.0185, -0.0220,  0.0128],\n",
       "          [-0.0017, -0.0287, -0.0187,  ..., -0.0291,  0.0189, -0.0221],\n",
       "          ...,\n",
       "          [ 0.0030,  0.0180,  0.0070,  ..., -0.0044, -0.0138, -0.0021],\n",
       "          [-0.0241,  0.0127, -0.0265,  ..., -0.0113, -0.0171,  0.0269],\n",
       "          [ 0.0229,  0.0103, -0.0263,  ...,  0.0089,  0.0266,  0.0095]])),\n",
       " ('linear_car_4.bias',\n",
       "  Parameter containing:\n",
       "  tensor([ 0.0047,  0.0055,  0.0007,  ...,  0.0193, -0.0192, -0.0003])),\n",
       " ('linear_car_5.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[ 0.0077,  0.0286,  0.0374,  ...,  0.0231, -0.0194, -0.0234]])),\n",
       " ('linear_car_5.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0027])),\n",
       " ('linear_inflow.weight',\n",
       "  Parameter containing:\n",
       "  tensor([[-0.0218,  0.0102,  0.0071,  ...,  0.0004,  0.0241,  0.0015]])),\n",
       " ('linear_inflow.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0.0062])),\n",
       " ('batch_norm.weight',\n",
       "  Parameter containing:\n",
       "  tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       " ('batch_norm.bias',\n",
       "  Parameter containing:\n",
       "  tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(children)\n",
    "len(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing children\n",
      "------------------------------\n",
      "[Sequential(\n",
      "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Linear(in_features=10, out_features=2, bias=True)]\n",
      "\n",
      "\n",
      "Printing Modules\n",
      "------------------------------\n",
      "[myNet(\n",
      "  (convBN): Sequential(\n",
      "    (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (linear): Linear(in_features=10, out_features=2, bias=True)\n",
      "), Sequential(\n",
      "  (0): Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "), Conv2d(10, 10, kernel_size=(3, 3), stride=(1, 1)), BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), Linear(in_features=10, out_features=2, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.convBN =  nn.Sequential(nn.Conv2d(10,10,3), nn.BatchNorm2d(10))\n",
    "        self.linear =  nn.Linear(10,2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        pass\n",
    "\n",
    "Net = myNet()\n",
    "\n",
    "print(\"Printing children\\n------------------------------\")\n",
    "print(list(Net.children()))\n",
    "print(\"\\n\\nPrinting Modules\\n------------------------------\")\n",
    "print(list(Net.modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
