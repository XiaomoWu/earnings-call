{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "transient": {
       "display_id": "datatable:css"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "transient": {
       "display_id": "datatable:css"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import spacy\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from datatable import f\n",
    "from spacy.attrs import ORTH\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# set working directory\n",
    "WORK_DIR = '/home/yu/OneDrive/CC'\n",
    "DATA_DIR = '/home/yu/OneDrive/CC/data'\n",
    "\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "# initialize data.table\n",
    "dt.init_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Doc in spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# Add a simple sentencizer\\nnlp.add_pipe(\\'sentencizer\\')\\n\\n# add [EOC] as special case in tokenization\\nspecial_case = [{ORTH: \"[EOC]\"}]\\nnlp.tokenizer.add_special_case(\"[EOC]\", special_case)\\n'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the simpliest pipeline\n",
    "# 'tok2vec', 'parser', 'lemmatizer', 'tagger', 'attribute_ruler'\n",
    "nlp = spacy.load(\"en_core_web_lg\", disable=['ner'])\n",
    "\n",
    "'''\n",
    "# Add a simple sentencizer\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "# add [EOC] as special case in tokenization\n",
    "special_case = [{ORTH: \"[EOC]\"}]\n",
    "nlp.tokenizer.add_special_case(\"[EOC]\", special_case)\n",
    "'''\n",
    "\n",
    "# register extension for Span\n",
    "Span.set_extension('transcriptid', default=None, force=True)\n",
    "Span.set_extension('componentid', default=None, force=True)\n",
    "Span.set_extension('componentorder', default=None, force=True)\n",
    "Span.set_extension('componenttypeid', default=None, force=True)\n",
    "Span.set_extension('speakerid', default=None, force=True)\n",
    "Span.set_extension('speakertypeid', default=None, force=True)\n",
    "Span.set_extension('is_component', default=False, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"text_component_sp500.feather\" (978.0 MB) loaded as \"text_component\" (2s)\n"
     ]
    }
   ],
   "source": [
    "# Load components as a 2D table\n",
    "ld('text_component_sp500', ldname='text_component', force=True)\n",
    "text_component = dt.Frame(text_component)\n",
    "\n",
    "# conver 2D table to tuples\n",
    "text_component = text_component[:100,:].to_tuples()\n",
    "text_component = [(line[6], \n",
    "                   {'transcriptid': line[2],\n",
    "                    'componentid': line[0],\n",
    "                    'componenttypeid': line[4],\n",
    "                    'componentorder': line[3],\n",
    "                    'speakerid': int(line[5]) if line[5]!=None else None,\n",
    "                    'speakertypeid': int(line[1]) if line[1]!=None else None\n",
    "                   }) for line in text_component]\n",
    "\n",
    "text_component_grouped = {}\n",
    "for text, context in text_component:\n",
    "    tid = context['transcriptid']\n",
    "    if tid in text_component_grouped:\n",
    "        text_component_grouped[tid].append((text, context))\n",
    "    else:\n",
    "        text_component_grouped[tid] = [(text, context)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Only need to run this sectoin **ONCE**. It will hold all the ground truth and will never be altered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.73it/s]\n"
     ]
    }
   ],
   "source": [
    "# Final output holder\n",
    "docs = []\n",
    "\n",
    "# Iterate through every transcriptid\n",
    "for line in tqdm(text_component_grouped.values(), total=len(text_component_grouped)):\n",
    "\n",
    "    # Output holder\n",
    "    components = []\n",
    "\n",
    "    # Within every transcriptid, iterature through every component\n",
    "    for component, context in nlp.pipe(line, as_tuples=True):\n",
    "        \n",
    "        # Assign component-level attributes\n",
    "        component[:]._.is_component = True\n",
    "        component[:]._.transcriptid = context['transcriptid']\n",
    "        component[:]._.componentid = context['componentid']\n",
    "        component[:]._.componenttypeid = context['componenttypeid']\n",
    "        component[:]._.componentorder = context['componentorder']\n",
    "        component[:]._.speakerid = context['speakerid']\n",
    "        component[:]._.speakertypeid = context['speakertypeid']\n",
    "\n",
    "        # Assign sentence-level attributes\n",
    "        for sent in component.sents:\n",
    "            sent._.componentid = context['componentid']\n",
    "\n",
    "        # return\n",
    "        components.append(component)\n",
    "\n",
    "    # join components into one Doc\n",
    "    doc = Doc.from_docs(components)\n",
    "\n",
    "    # create SpanGroup \"components\" for doc\n",
    "    spans_component = []\n",
    "    for k, v in doc.user_data.items():\n",
    "        if k[1]=='is_component':\n",
    "            if v==True:\n",
    "                spans_component.append(doc.char_span(k[2], k[3]))\n",
    "\n",
    "    doc.spans['components'] = spans_component \n",
    "\n",
    "    # return     \n",
    "    docs.append(doc)\n",
    "\n",
    "# DocBin(store_user_data=True, docs=docs).to_disk('data/doc_sp500.spacy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "30184"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].spans['components'][0]._.componentid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save DocBin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Warnings**\n",
    "\n",
    "> When saving DocBin, you must also save the nlp object for recovery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocBin(store_user_data=True, docs=docs).to_disk('data/doc_sp500.spacy')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}