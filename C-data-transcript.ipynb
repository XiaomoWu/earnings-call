{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import time\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from datatable import f\n",
    "from functools import partial\n",
    "from multiprocessing import Process\n",
    "from tqdm import tqdm\n",
    "\n",
    "# set working directory\n",
    "WORK_DIR = '/home/yu/OneDrive/CC'\n",
    "DATA_DIR = f'{WORK_DIR}/data'\n",
    "WRDS_DOWNLOAD_DIR = f'{DATA_DIR}/WRDS-download'\n",
    "\n",
    "os.chdir(WORK_DIR)\n",
    "\n",
    "# initialize data.table\n",
    "dt.init_styles()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Doc in spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register span.ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load spacy into GPU\n",
    "import spacy\n",
    "spacy.require_gpu(0)\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "from spacy.attrs import ORTH\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "\n",
    "# Use the simpliest pipeline\n",
    "# 'tok2vec', 'parser', 'lemmatizer', 'tagger', 'attribute_ruler'\n",
    "# nlp = spacy.load(\"en_core_web_lg\", disable=['ner', 'parser', 'tok2vec', 'tagger', 'lemmatizer', 'attribute_ruler'])\n",
    "# nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "# Add a simple sentencizer\n",
    "# nlp.add_pipe('sentencizer')\n",
    "\n",
    "# register extension for Doc\n",
    "Doc.set_extension('transcriptid', default=None, force=True)\n",
    "\n",
    "# register extension for Span\n",
    "Span.set_extension('transcriptid', default=None, force=True)\n",
    "Span.set_extension('componentid', default=None, force=True)\n",
    "Span.set_extension('componentorder', default=None, force=True)\n",
    "Span.set_extension('componenttypeid', default=None, force=True)\n",
    "Span.set_extension('speakerid', default=None, force=True)\n",
    "Span.set_extension('speakertypeid', default=None, force=True)\n",
    "Span.set_extension('is_component', default=False, force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"text_component_sp500.feather\" (978.0 MB) loaded as \"text_component\" (2s)\n"
     ]
    }
   ],
   "source": [
    "# Load components as a 2D table\n",
    "ld('text_component_sp500', ldname='text_component', force=True)\n",
    "text_component = dt.Frame(text_component)\n",
    "\n",
    "# conver 2D table to tuples\n",
    "text_component = text_component.to_tuples()\n",
    "text_component = [(line[6], \n",
    "                   {'transcriptid': line[2],\n",
    "                    'componentid': line[0],\n",
    "                    'componenttypeid': line[4],\n",
    "                    'componentorder': line[3],\n",
    "                    'speakerid': int(line[5]) if line[5]!=None else None,\n",
    "                    'speakertypeid': int(line[1]) if line[1]!=None else None\n",
    "                   }) for line in text_component]\n",
    "\n",
    "text_component_grouped = {}\n",
    "for text, context in text_component:\n",
    "    tid = context['transcriptid']\n",
    "    if tid in text_component_grouped:\n",
    "        text_component_grouped[tid].append((text, context))\n",
    "    else:\n",
    "        text_component_grouped[tid] = [(text, context)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Only need to run this sectoin **ONCE**. It will hold all the ground truth and will never be altered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_one_doc(line):\n",
    "    '''Convert list of components into a single Doc\n",
    "    '''\n",
    "    # Output holder\n",
    "    components = []\n",
    "\n",
    "    # Within every transcriptid, iterature through every component\n",
    "    for component, context in nlp.pipe(line, as_tuples=True):\n",
    "        \n",
    "        # Assign component-level attributes\n",
    "        component[:]._.is_component = True\n",
    "        component[:]._.transcriptid = context['transcriptid']\n",
    "        component[:]._.componentid = context['componentid']\n",
    "        component[:]._.componenttypeid = context['componenttypeid']\n",
    "        component[:]._.componentorder = context['componentorder']\n",
    "        component[:]._.speakerid = context['speakerid']\n",
    "        component[:]._.speakertypeid = context['speakertypeid']\n",
    "\n",
    "        # Assign sentence-level attributes\n",
    "        for sent in component.sents:\n",
    "            sent._.componentid = context['componentid']\n",
    "\n",
    "        # return\n",
    "        components.append(component)\n",
    "\n",
    "    # join components into one Doc\n",
    "    doc = Doc.from_docs(components)\n",
    "\n",
    "    # Add Doc-level attribute: \"transcriptid\"\n",
    "    doc._.transcriptid = context['transcriptid']\n",
    "\n",
    "    # create SpanGroup \"components\" for doc\n",
    "    spans_component = []\n",
    "    for k, v in doc.user_data.items():\n",
    "        if k[1]=='is_component':\n",
    "            if v==True:\n",
    "                spans_component.append(doc.char_span(k[2], k[3]))\n",
    "\n",
    "    doc.spans['components'] = spans_component \n",
    "\n",
    "    # return     \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 825/3764 [05:00<24:36,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 54029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1673/3764 [10:00<12:44,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 78277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2519/3764 [15:00<06:57,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 96555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 3392/3764 [20:00<02:41,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 110216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [22:13<00:00,  2.82it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 183/3764 [01:02<21:36,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 117913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1020/3764 [06:03<19:03,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 127268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1871/3764 [11:03<12:45,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 135640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2766/3764 [16:03<04:46,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 145171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 3653/3764 [21:03<00:37,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 154834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [21:41<00:00,  2.89it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 475/3764 [02:38<16:22,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 160858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1389/3764 [07:38<14:50,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 167734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2304/3764 [12:38<08:25,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 174189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 3207/3764 [17:38<02:29,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 180070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:44<00:00,  3.02it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 42/3764 [00:12<19:27,  3.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 183716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 952/3764 [05:12<13:59,  3.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 189066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 1837/3764 [10:12<10:57,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 193706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 2723/3764 [15:12<06:00,  2.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 198119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 3640/3764 [20:12<00:38,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 202495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:53<00:00,  3.00it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 452/3764 [02:35<26:34,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 205183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1341/3764 [07:35<13:19,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 209231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2268/3764 [12:35<09:07,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 212998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3176/3764 [17:36<02:55,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 216804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:49<00:00,  3.01it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/3764 [00:02<18:31,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 219296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 904/3764 [05:02<14:43,  3.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 222964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 1834/3764 [10:02<11:03,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 226667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2761/3764 [15:02<05:15,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 230246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 3653/3764 [20:02<00:35,  3.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 233465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:39<00:00,  3.04it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 492/3764 [02:39<20:54,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 235593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1418/3764 [07:39<16:35,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 238865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2322/3764 [12:40<09:48,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 242144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 3250/3764 [17:40<02:28,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 245269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:24<00:00,  3.07it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 95/3764 [00:33<25:21,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 247383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1021/3764 [05:33<16:22,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 250486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 1964/3764 [10:33<11:26,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 253615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 2902/3764 [15:34<04:11,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 256859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:12<00:00,  3.10it/s]\n",
      "  0%|          | 0/3764 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 9/10\n",
      "len(vocab): 259539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 933/3764 [05:00<15:29,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 262544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1873/3764 [10:00<09:25,  3.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 265439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 2799/3764 [15:00<04:05,  3.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 268435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 3739/3764 [20:01<00:06,  3.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 271507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3764/3764 [20:08<00:00,  3.11it/s]\n",
      "  0%|          | 0/3754 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunks: 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 604/3754 [03:10<20:27,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 273486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 1555/3754 [08:10<11:43,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 276298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 2435/3754 [13:11<06:29,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 278799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 3328/3754 [18:11<01:49,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(vocab): 281296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3754/3754 [20:27<00:00,  3.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# ------------- With Chunks -------------------\n",
    "# Because of memory limitation, we split the data into chunks and process/store one by one.\n",
    "\n",
    "n_chunks = 10\n",
    "chunk_size = len(text_component_grouped)//n_chunks+1\n",
    "\n",
    "text_component_grouped_chunked = list(chunks(list(text_component_grouped.values()), chunk_size))\n",
    "\n",
    "del text_component, text_component_grouped\n",
    "\n",
    "# Parse\n",
    "time_start = time.perf_counter()\n",
    "for i in range(n_chunks):\n",
    "\n",
    "    print(f'Processing chunks: {i+1}/{n_chunks}')\n",
    "    \n",
    "    data = text_component_grouped_chunked[i]\n",
    "\n",
    "    # parse\n",
    "    docs = []\n",
    "    for comps in tqdm(data):\n",
    "        # print len(nlp.vocab)\n",
    "        time_gap = time.perf_counter()-time_start\n",
    "        if time_gap >= 300: # every 5min\n",
    "            print(f'len(vocab): {len(nlp.vocab)}')\n",
    "            time_start = time.perf_counter()\n",
    "            \n",
    "        docs.append(make_one_doc(comps))\n",
    "    \n",
    "    # save Doc\n",
    "    docbin = DocBin(store_user_data=True, docs=docs, attrs=['ORTH', 'LEMMA', 'MORPH', 'POS', 'TAG', 'HEAD', 'DEP', 'ENT_IOB', 'ENT_TYPE'])\n",
    "    docbin.to_disk(f'data/doc_sp500_lg_{i}.spacy')\n",
    "\n",
    "    del docs, docbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save nlp pipeline\n",
    "nlp_dir = 'data/nlp_lg_gpu'\n",
    "if not os.path.exists(nlp_dir):\n",
    "    os.makedirs(nlp_dir)\n",
    "\n",
    "# save nlp meta data\n",
    "lang = nlp.config[\"nlp\"][\"lang\"]\n",
    "pipeline = nlp.config[\"nlp\"][\"pipeline\"]\n",
    "\n",
    "with open(f'{nlp_dir}/nlp_metadata.txt', 'w+') as f:\n",
    "    f.write(f'lang: {lang}\\n')\n",
    "    f.write(f'pipeline: {str(pipeline)}')\n",
    "    \n",
    "# save nlp\n",
    "nlp.to_disk(nlp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentencize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "# spacy.require_gpu(0)\n",
    "nlp_dir = 'data/nlp_lg_gpu'\n",
    "nlp = spacy.load(nlp_dir)\n",
    "\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "\n",
    "\n",
    "# register extension for Doc\n",
    "Doc.set_extension('transcriptid', default=None, force=True)\n",
    "\n",
    "# Register extension for Span\n",
    "Span.set_extension('transcriptid', default=None, force=True)\n",
    "Span.set_extension('componentid', default=None, force=True)\n",
    "Span.set_extension('componentorder', default=None, force=True)\n",
    "Span.set_extension('componenttypeid', default=None, force=True)\n",
    "Span.set_extension('speakerid', default=None, force=True)\n",
    "Span.set_extension('speakertypeid', default=None, force=True)\n",
    "Span.set_extension('is_component', default=False, force=True)\n",
    "\n",
    "# results holder\n",
    "sents = []\n",
    "\n",
    "# fill results\n",
    "for _ in tqdm(range(10)): # last 10%\n",
    "    # load doc\n",
    "    docs_chunk = list(DocBin(store_user_data=True)\\\n",
    "                      .from_disk(f'data/doc_sp500_lg_{_}.spacy')\\\n",
    "                      .get_docs(nlp.vocab))\n",
    "    print(f'Chunk {_}: N_doc={len(docs_chunk)}')\n",
    "\n",
    "    # get sents from doc\n",
    "    for doc in tqdm(docs_chunk):\n",
    "        for i_sent, sent in enumerate(doc.sents):\n",
    "            sents.append((doc._.transcriptid, \n",
    "                          sent._.componentid, \n",
    "                          i_sent, sent.text))\n",
    "            \n",
    "# convert results into Frame\n",
    "dt_sents = dt.Frame(sents, names=['transcriptid', 'componentid', 'sentenceid', 'text'])\n",
    "\n",
    "# save feather\n",
    "sv('dt_sents', svname='dt_sents_sp500')\n",
    "sv('sents', svname='sents_sp500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build (tid, cid) pair (R)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link: tid_cid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> `tid_cid_pair` has the form:\n",
    ">\n",
    "> `{tid:[cid1, cid2, ...]}`\n",
    ">\n",
    "> It's used to select text of interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/yu/OneDrive/CC\n",
      "f_ciq_transcript_component_sp500 (974.5 MB) already loaded, will NOT load again! (0 secs) (2021-03-03 5:28 PM)\n",
      "\"ciq_transcript_speaker.feather\" (7.8 GB) loaded (1.68 mins) (2021-03-03 5:30 PM)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "suppressMessages(suppressWarnings({\n",
    "    library(utilr)\n",
    "}))\n",
    "\n",
    "WORK_DIR = '/home/yu/OneDrive/CC'\n",
    "DATA_DIR = str_c(WORK_DIR, '/data')\n",
    "WRDS_DOWNLOAD_DIR = str_c(DATA_DIR, '/WRDS-download')\n",
    "setwd(WORK_DIR)\n",
    "cat(str_c('Current working directory: ', getwd(), '\\n'))\n",
    "\n",
    "ld(f_ciq_transcript_component_sp500)\n",
    "ld(ciq_transcript_speaker, path=WRDS_DOWNLOAD_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`speakertype`\n",
    "- 1: Operator\n",
    "- 2: Exeutives\n",
    "- 3: Analyst\n",
    "- 4: Shareholders\n",
    "- 5: Attendees\n",
    "\n",
    "`transcriptcomponenttypeid`\n",
    "- 1: Presentation Operator Message\n",
    "- 2: Presenter Speech\n",
    "- 3: Question\n",
    "- 4: Answer\n",
    "- 5: Presentation Section (NULL)\n",
    "- 6: Question and Answer Section (NULL)\n",
    "- 7: Question and Answer Operator Message\n",
    "- 8: Unknown Question and Answer Message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# text: all text\n",
    "selected_componentid = ciq_transcript_speaker[transcriptcomponenttypeid %in% c(2,3,4) & speakertypeid %in% c(2,3), unique(transcriptcomponentid)]\n",
    "\n",
    "tid_cid_pair_all = f_ciq_transcript_component_sp500[,\n",
    "      .(transcriptid, componentid=transcriptcomponentid, componentorder)\n",
    "    ][componentid %in% selected_componentid\n",
    "    ][order(transcriptid, componentorder)\n",
    "    ][, .(componentid=list(componentid)), keyby=transcriptid]\n",
    "      \n",
    "tid_cid_pair_all[1:2]\n",
    "sv(tid_cid_pair_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>transcriptid</th><th scope=col>componentid</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;list&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>108</td><td>30185, 30186, 30187, 30188</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " transcriptid & componentid\\\\\n",
       " <int> & <list>\\\\\n",
       "\\hline\n",
       "\t 108 & 30185, 30186, 30187, 30188\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 2\n",
       "\n",
       "| transcriptid &lt;int&gt; | componentid &lt;list&gt; |\n",
       "|---|---|\n",
       "| 108 | 30185, 30186, 30187, 30188 |\n",
       "\n"
      ],
      "text/plain": [
       "  transcriptid componentid               \n",
       "1 108          30185, 30186, 30187, 30188"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tid_cid_pair_md\" saved as \"tid_cid_pair_md.feather\" (853.7 KB) (0.47 secs, 2021-03-03 17:39:24)\n"
     ]
    }
   ],
   "source": [
    "# text: Only Management Discusson\n",
    "selected_componentid = ciq_transcript_speaker[transcriptcomponenttypeid==2 & speakertypeid==2, unique(transcriptcomponentid)]\n",
    "\n",
    "tid_cid_pair_md = f_ciq_transcript_component_sp500[,\n",
    "      .(transcriptid, componentid=transcriptcomponentid, componentorder)\n",
    "    ][componentid %in% selected_componentid\n",
    "    ][order(transcriptid, componentorder)\n",
    "    ][, .(componentid=list(componentid)), keyby=transcriptid]\n",
    "\n",
    "tid_cid_pair_md[1]\n",
    "sv(tid_cid_pair_md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>transcriptid</th><th scope=col>componentid</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;list&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>108</td><td>30190, 30191, 30192, 30193, 30194, 30195, 30196, 30197, 30198, 30199, 30200, 30202, 30203, 30204, 30205, 30206, 30207, 30208, 30209, 30210, 30211, 30212, 30214, 30215, 30216, 30217, 30218, 30220, 30221, 30222, 30224, 30225, 30226, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30244, 30245, 30246, 30247, 30248, 30249, 30250, 30251, 30252, 30253, 30255, 30256, 30257, 30258, 30259, 30261</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " transcriptid & componentid\\\\\n",
       " <int> & <list>\\\\\n",
       "\\hline\n",
       "\t 108 & 30190, 30191, 30192, 30193, 30194, 30195, 30196, 30197, 30198, 30199, 30200, 30202, 30203, 30204, 30205, 30206, 30207, 30208, 30209, 30210, 30211, 30212, 30214, 30215, 30216, 30217, 30218, 30220, 30221, 30222, 30224, 30225, 30226, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30244, 30245, 30246, 30247, 30248, 30249, 30250, 30251, 30252, 30253, 30255, 30256, 30257, 30258, 30259, 30261\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 2\n",
       "\n",
       "| transcriptid &lt;int&gt; | componentid &lt;list&gt; |\n",
       "|---|---|\n",
       "| 108 | 30190, 30191, 30192, 30193, 30194, 30195, 30196, 30197, 30198, 30199, 30200, 30202, 30203, 30204, 30205, 30206, 30207, 30208, 30209, 30210, 30211, 30212, 30214, 30215, 30216, 30217, 30218, 30220, 30221, 30222, 30224, 30225, 30226, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30244, 30245, 30246, 30247, 30248, 30249, 30250, 30251, 30252, 30253, 30255, 30256, 30257, 30258, 30259, 30261 |\n",
       "\n"
      ],
      "text/plain": [
       "  transcriptid\n",
       "1 108         \n",
       "  componentid                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "1 30190, 30191, 30192, 30193, 30194, 30195, 30196, 30197, 30198, 30199, 30200, 30202, 30203, 30204, 30205, 30206, 30207, 30208, 30209, 30210, 30211, 30212, 30214, 30215, 30216, 30217, 30218, 30220, 30221, 30222, 30224, 30225, 30226, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30244, 30245, 30246, 30247, 30248, 30249, 30250, 30251, 30252, 30253, 30255, 30256, 30257, 30258, 30259, 30261"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tid_cid_pair_qa\" saved as \"tid_cid_pair_qa.feather\" (8.9 MB) (0.38 secs, 2021-03-03 17:41:03)\n"
     ]
    }
   ],
   "source": [
    "selected_componentid = ciq_transcript_speaker[transcriptcomponenttypeid %in% c(3,4) & speakertypeid %in% c(2,3), unique(transcriptcomponentid)]\n",
    "\n",
    "tid_cid_pair_qa = f_ciq_transcript_component_sp500[,\n",
    "      .(transcriptid, componentid=transcriptcomponentid, componentorder)\n",
    "    ][componentid %in% selected_componentid\n",
    "    ][order(transcriptid, componentorder)\n",
    "    ][, .(componentid=list(componentid)), keyby=transcriptid]\n",
    "\n",
    "tid_cid_pair_qa[1]      \n",
    "sv(tid_cid_pair_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA_analyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>transcriptid</th><th scope=col>componentid</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;list&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>108</td><td>30190, 30192, 30194, 30196, 30198, 30200, 30202, 30204, 30206, 30208, 30210, 30212, 30214, 30216, 30218, 30220, 30222, 30225, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30245, 30247, 30249, 30251, 30253, 30255, 30257, 30259</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 2\n",
       "\\begin{tabular}{ll}\n",
       " transcriptid & componentid\\\\\n",
       " <int> & <list>\\\\\n",
       "\\hline\n",
       "\t 108 & 30190, 30192, 30194, 30196, 30198, 30200, 30202, 30204, 30206, 30208, 30210, 30212, 30214, 30216, 30218, 30220, 30222, 30225, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30245, 30247, 30249, 30251, 30253, 30255, 30257, 30259\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 2\n",
       "\n",
       "| transcriptid &lt;int&gt; | componentid &lt;list&gt; |\n",
       "|---|---|\n",
       "| 108 | 30190, 30192, 30194, 30196, 30198, 30200, 30202, 30204, 30206, 30208, 30210, 30212, 30214, 30216, 30218, 30220, 30222, 30225, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30245, 30247, 30249, 30251, 30253, 30255, 30257, 30259 |\n",
       "\n"
      ],
      "text/plain": [
       "  transcriptid\n",
       "1 108         \n",
       "  componentid                                                                                                                                                                                                                                        \n",
       "1 30190, 30192, 30194, 30196, 30198, 30200, 30202, 30204, 30206, 30208, 30210, 30212, 30214, 30216, 30218, 30220, 30222, 30225, 30227, 30229, 30231, 30233, 30235, 30237, 30239, 30241, 30243, 30245, 30247, 30249, 30251, 30253, 30255, 30257, 30259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tid_cid_pair_qa_analyst\" saved as \"tid_cid_pair_qa_analyst.feather\" (4 MB) (0.41 secs, 2021-03-03 17:41:45)\n"
     ]
    }
   ],
   "source": [
    "selected_componentid = ciq_transcript_speaker[transcriptcomponenttypeid %in% c(3) & speakertypeid %in% c(3), unique(transcriptcomponentid)]\n",
    "\n",
    "tid_cid_pair_qa_analyst = f_ciq_transcript_component_sp500[,\n",
    "      .(transcriptid, componentid=transcriptcomponentid, componentorder)\n",
    "    ][componentid %in% selected_componentid\n",
    "    ][order(transcriptid, componentorder)\n",
    "    ][, .(componentid=list(componentid)), keyby=transcriptid]\n",
    "\n",
    "tid_cid_pair_qa_analyst[1]      \n",
    "sv(tid_cid_pair_qa_analyst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>transcriptid</th><th scope=col>componentid</th><th scope=col>componentorder</th></tr>\n",
       "\t<tr><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>108</td><td>30191</td><td>8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 3\n",
       "\\begin{tabular}{lll}\n",
       " transcriptid & componentid & componentorder\\\\\n",
       " <int> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 108 & 30191 & 8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 3\n",
       "\n",
       "| transcriptid &lt;int&gt; | componentid &lt;int&gt; | componentorder &lt;int&gt; |\n",
       "|---|---|---|\n",
       "| 108 | 30191 | 8 |\n",
       "\n"
      ],
      "text/plain": [
       "  transcriptid componentid componentorder\n",
       "1 108          30191       8             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"tid_cid_pair_qa_manager\" saved as \"tid_cid_pair_qa_manager_old.feather\" (6.5 MB) (0.01 secs, 2021-03-03 17:49:57)\n"
     ]
    }
   ],
   "source": [
    "selected_componentid = ciq_transcript_speaker[transcriptcomponenttypeid %in% c(4) & speakertypeid %in% c(2), unique(transcriptcomponentid)]\n",
    "\n",
    "tid_cid_pair_qa_manager = f_ciq_transcript_component_sp500[,\n",
    "      .(transcriptid, componentid=transcriptcomponentid, componentorder)\n",
    "    ][componentid %in% selected_componentid\n",
    "    ][order(transcriptid, componentorder)\n",
    "    ][, .(componentid=list(componentid)), keyby=transcriptid]\n",
    "\n",
    "tid_cid_pair_qa_manager[1]      \n",
    "sv(tid_cid_pair_qa_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link: tid_tid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Output links in the form of `{transcript_from: [transcript_to]}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text: link to previous n qtrs\n",
    "ld(targets_final, 'targets_df')\n",
    "\n",
    "make_tid_from_to_pair <- function(n_yqtr) {\n",
    "    n_yqtr = n_yqtr - 1\n",
    "    \n",
    "    tid_from_to_pair = targets_df[order(gvkey, ciq_call_date)\n",
    "        ][, {\n",
    "          l = list()\n",
    "          for (t in 1:.N) {\n",
    "              if (t<=n_yqtr) l[[t]] = list('transcriptid_from'=transcriptid[t],\n",
    "                                      'transcriptid_to'=list(transcriptid[t:1]))\n",
    "              else l[[t]] = list('transcriptid_from'=transcriptid[t],\n",
    "                                 'transcriptid_to'=list(transcriptid[t:(t-n_yqtr)]))\n",
    "          }\n",
    "          rbindlist(l)\n",
    "          }, \n",
    "          keyby=.(gvkey)\n",
    "        ]\n",
    "}\n",
    "\n",
    "\n",
    "tid_from_to_pair_1qtr = make_tid_from_to_pair(1); sv(tid_from_to_pair_1qtr)\n",
    "tid_from_to_pair_2qtr = make_tid_from_to_pair(2); sv(tid_from_to_pair_2qtr)\n",
    "tid_from_to_pair_4qtr = make_tid_from_to_pair(4); sv(tid_from_to_pair_4qtr)\n",
    "tid_from_to_pair_8qtr = make_tid_from_to_pair(8); sv(tid_from_to_pair_8qtr)\n",
    "\n",
    "tid_from_to_pair_8qtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore transcript-speaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Switch to R kernel now!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yu's data science toolbox loaded! \n"
     ]
    }
   ],
   "source": [
    "# library\n",
    "suppressMessages(suppressWarnings({\n",
    "    library(utilr)\n",
    "}))\n",
    "\n",
    "# set working directory\n",
    "WORK_DIR = '/home/yu/OneDrive/CC'\n",
    "DATA_DIR = sprintf('%s/data', WORK_DIR)\n",
    "WRDS_DOWNLOAD_DIR = sprintf('%s/WRDS-download', DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciq_transcript_speaker (7.8 GB) already loaded, will NOT load again! (0 secs)\n",
      "ciq_transcript_detail (54.6 MB) already loaded, will NOT load again! (0 secs)\n",
      "ciq_keydev (899.8 MB) already loaded, will NOT load again! (0 secs)\n",
      "sp500_cst (24.8 KB) already loaded, will NOT load again! (0 secs)\n",
      "ciq_person (167 MB) already loaded, will NOT load again! (0 secs)\n",
      "f_ciq_transcript_detail_sp500 (2.4 MB) already loaded, will NOT load again! (0 secs)\n",
      "ciq_wrds_professional (988.3 MB) already loaded, will NOT load again! (0 secs)\n",
      "\"f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_retail_sentiment_norm_outlier.feather\" (15.9 MB) loaded as \"earnings\" (0.03 secs)\n"
     ]
    }
   ],
   "source": [
    "ld(ciq_transcript_speaker, path=WRDS_DOWNLOAD_DIR)\n",
    "ld(ciq_transcript_detail, path=WRDS_DOWNLOAD_DIR)\n",
    "ld(ciq_keydev, path=WRDS_DOWNLOAD_DIR)\n",
    "ld(sp500_cst)\n",
    "ld(ciq_person, path=WRDS_DOWNLOAD_DIR)\n",
    "ld(f_ciq_transcript_detail_sp500)\n",
    "ld(ciq_wrds_professional, path=WRDS_DOWNLOAD_DIR)\n",
    "ld(f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_retail_sentiment_norm_outlier, ldname=earnings, force=T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>transcriptid</th><th scope=col>proid</th><th scope=col>speakertypename</th><th scope=col>date</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>93162</td><td>NA</td><td>NA</td><td>2010-11-11</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 4\n",
       "\\begin{tabular}{llll}\n",
       " transcriptid & proid & speakertypename & date\\\\\n",
       " <dbl> & <dbl> & <chr> & <date>\\\\\n",
       "\\hline\n",
       "\t 93162 & NA & NA & 2010-11-11\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 4\n",
       "\n",
       "| transcriptid &lt;dbl&gt; | proid &lt;dbl&gt; | speakertypename &lt;chr&gt; | date &lt;date&gt; |\n",
       "|---|---|---|---|\n",
       "| 93162 | NA | NA | 2010-11-11 |\n",
       "\n"
      ],
      "text/plain": [
       "  transcriptid proid speakertypename date      \n",
       "1 93162        NA    NA              2010-11-11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transcriptid_sp500 = unique(f_ciq_transcript_detail_sp500$transcriptid)\n",
    "\n",
    "speaker = ciq_transcript_speaker[transcriptid %in% transcriptid_sp500\n",
    "    ][!is.na(proid),\n",
    "      .(speakertypename), keyby=.(transcriptid, proid)\n",
    "    ][ciq_transcript_detail[, .(transcriptid, date=mostimportantdateutc)], on=.(transcriptid)\n",
    "    ][!is.na(date)] %>% unique()\n",
    "\n",
    "speaker[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Q: How many executives speak in an earnings call?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".\n",
       "    1     2     3     4     5     6     7     8     9    10    11    12    14 \n",
       "  862  6198 12567  5918  3369  1441   518   162    41    13     1     1     1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "speaker[speakertypename=='Executives', .(n=uniqueN(proid)), keyby=.(transcriptid)]$n %>% table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 20</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>keydevid</th><th scope=col>companyid</th><th scope=col>transcriptid</th><th scope=col>headline</th><th scope=col>mostimportantdateutc</th><th scope=col>keydeveventtypeid</th><th scope=col>keydeveventtypename</th><th scope=col>companyname</th><th scope=col>transcriptcollectiontypeid</th><th scope=col>transcriptcollectiontypename</th><th scope=col>transcriptpresentationtypeid</th><th scope=col>transcriptpresentationtypename</th><th scope=col>transcriptcreationdate_utc</th><th scope=col>transcriptcreationtime_utc</th><th scope=col>audiolengthsec</th><th scope=col>isdelayed_flag</th><th scope=col>delayreasontypeid</th><th scope=col>delayreasontypename</th><th scope=col>latest_transcript_version</th><th scope=col>gvkey</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>654393367</td><td>313055</td><td>1936461</td><td>Walmart Inc., Q4 2020 Earnings Call, Feb 18, 2020</td><td>2020-02-18</td><td>48</td><td>Earnings Calls</td><td>Walmart Inc.</td><td>8</td><td>Audited Copy</td><td>5</td><td>Final</td><td>2020-03-13</td><td>50559</td><td>23614</td><td>0</td><td>NA</td><td>NA</td><td>8</td><td>011259</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 20\n",
       "\\begin{tabular}{llllllllllllllllllll}\n",
       " keydevid & companyid & transcriptid & headline & mostimportantdateutc & keydeveventtypeid & keydeveventtypename & companyname & transcriptcollectiontypeid & transcriptcollectiontypename & transcriptpresentationtypeid & transcriptpresentationtypename & transcriptcreationdate\\_utc & transcriptcreationtime\\_utc & audiolengthsec & isdelayed\\_flag & delayreasontypeid & delayreasontypename & latest\\_transcript\\_version & gvkey\\\\\n",
       " <dbl> & <dbl> & <dbl> & <chr> & <date> & <dbl> & <chr> & <chr> & <dbl> & <chr> & <dbl> & <chr> & <date> & <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t 654393367 & 313055 & 1936461 & Walmart Inc., Q4 2020 Earnings Call, Feb 18, 2020 & 2020-02-18 & 48 & Earnings Calls & Walmart Inc. & 8 & Audited Copy & 5 & Final & 2020-03-13 & 50559 & 23614 & 0 & NA & NA & 8 & 011259\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 20\n",
       "\n",
       "| keydevid &lt;dbl&gt; | companyid &lt;dbl&gt; | transcriptid &lt;dbl&gt; | headline &lt;chr&gt; | mostimportantdateutc &lt;date&gt; | keydeveventtypeid &lt;dbl&gt; | keydeveventtypename &lt;chr&gt; | companyname &lt;chr&gt; | transcriptcollectiontypeid &lt;dbl&gt; | transcriptcollectiontypename &lt;chr&gt; | transcriptpresentationtypeid &lt;dbl&gt; | transcriptpresentationtypename &lt;chr&gt; | transcriptcreationdate_utc &lt;date&gt; | transcriptcreationtime_utc &lt;dbl&gt; | audiolengthsec &lt;dbl&gt; | isdelayed_flag &lt;dbl&gt; | delayreasontypeid &lt;dbl&gt; | delayreasontypename &lt;chr&gt; | latest_transcript_version &lt;dbl&gt; | gvkey &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 654393367 | 313055 | 1936461 | Walmart Inc., Q4 2020 Earnings Call, Feb 18, 2020 | 2020-02-18 | 48 | Earnings Calls | Walmart Inc. | 8 | Audited Copy | 5 | Final | 2020-03-13 | 50559 | 23614 | 0 | NA | NA | 8 | 011259 |\n",
       "\n"
      ],
      "text/plain": [
       "  keydevid  companyid transcriptid\n",
       "1 654393367 313055    1936461     \n",
       "  headline                                          mostimportantdateutc\n",
       "1 Walmart Inc., Q4 2020 Earnings Call, Feb 18, 2020 2020-02-18          \n",
       "  keydeveventtypeid keydeveventtypename companyname  transcriptcollectiontypeid\n",
       "1 48                Earnings Calls      Walmart Inc. 8                         \n",
       "  transcriptcollectiontypename transcriptpresentationtypeid\n",
       "1 Audited Copy                 5                           \n",
       "  transcriptpresentationtypename transcriptcreationdate_utc\n",
       "1 Final                          2020-03-13                \n",
       "  transcriptcreationtime_utc audiolengthsec isdelayed_flag delayreasontypeid\n",
       "1 50559                      23614          0              NA               \n",
       "  delayreasontypename latest_transcript_version gvkey \n",
       "1 NA                  8                         011259"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this transriptid has 12 executives speaking!!!\n",
    "tid = speaker[speakertypename=='Executives', .(n=uniqueN(proid)), keyby=.(transcriptid)\n",
    "    ][n==12]$transcriptid\n",
    "\n",
    "f_ciq_transcript_detail_sp500[transcriptid==tid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Who asks questions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 39</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>companyid</th><th scope=col>personid</th><th scope=col>proid</th><th scope=col>profunctionid</th><th scope=col>companyname</th><th scope=col>personname</th><th scope=col>profunctionname</th><th scope=col>yearborn</th><th scope=col>yearfounded</th><th scope=col>countryid</th><th scope=col>⋯</th><th scope=col>topkeyexecflag</th><th scope=col>advisorflag</th><th scope=col>graduateflag</th><th scope=col>dealmakerflag</th><th scope=col>sponsorflag</th><th scope=col>undergraduateflag</th><th scope=col>onlyoneflag</th><th scope=col>companyflag</th><th scope=col>hideflag</th><th scope=col>committeeid</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>18493</td><td>66577</td><td>66578</td><td>10</td><td>DC Venture Partners</td><td>Wakefield, Kevin</td><td>Senior Key Executive</td><td>NA</td><td>1998</td><td>213</td><td>⋯</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td><td>NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 39\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " companyid & personid & proid & profunctionid & companyname & personname & profunctionname & yearborn & yearfounded & countryid & ⋯ & topkeyexecflag & advisorflag & graduateflag & dealmakerflag & sponsorflag & undergraduateflag & onlyoneflag & companyflag & hideflag & committeeid\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <chr> & <chr> & <chr> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 18493 & 66577 & 66578 & 10 & DC Venture Partners & Wakefield, Kevin & Senior Key Executive & NA & 1998 & 213 & ⋯ & 0 & 1 & 0 & 0 & 1 & 0 & 0 & 1 & 0 & NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 39\n",
       "\n",
       "| companyid &lt;dbl&gt; | personid &lt;dbl&gt; | proid &lt;dbl&gt; | profunctionid &lt;dbl&gt; | companyname &lt;chr&gt; | personname &lt;chr&gt; | profunctionname &lt;chr&gt; | yearborn &lt;dbl&gt; | yearfounded &lt;dbl&gt; | countryid &lt;dbl&gt; | ⋯ ⋯ | topkeyexecflag &lt;dbl&gt; | advisorflag &lt;dbl&gt; | graduateflag &lt;dbl&gt; | dealmakerflag &lt;dbl&gt; | sponsorflag &lt;dbl&gt; | undergraduateflag &lt;dbl&gt; | onlyoneflag &lt;dbl&gt; | companyflag &lt;dbl&gt; | hideflag &lt;dbl&gt; | committeeid &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 18493 | 66577 | 66578 | 10 | DC Venture Partners | Wakefield, Kevin | Senior Key Executive | NA | 1998 | 213 | ⋯ | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | NA |\n",
       "\n"
      ],
      "text/plain": [
       "  companyid personid proid profunctionid companyname         personname      \n",
       "1 18493     66577    66578 10            DC Venture Partners Wakefield, Kevin\n",
       "  profunctionname      yearborn yearfounded countryid <U+22EF>   topkeyexecflag\n",
       "1 Senior Key Executive NA       1998        213       <U+22EF> 0             \n",
       "  advisorflag graduateflag dealmakerflag sponsorflag undergraduateflag\n",
       "1 1           0            0             1           0                \n",
       "  onlyoneflag companyflag hideflag committeeid\n",
       "1 0           1           0        NA         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ciq_wrds_professional[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 6</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>gvkey</th><th scope=col>calldate</th><th scope=col>transcriptid</th><th scope=col>numest</th><th scope=col>n_analyst</th><th scope=col>n_company</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>001013</td><td>2009-06-03</td><td>23454</td><td>NA</td><td>6</td><td>6</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 6\n",
       "\\begin{tabular}{llllll}\n",
       " gvkey & calldate & transcriptid & numest & n\\_analyst & n\\_company\\\\\n",
       " <chr> & <date> & <int> & <dbl> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 001013 & 2009-06-03 & 23454 & NA & 6 & 6\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 6\n",
       "\n",
       "| gvkey &lt;chr&gt; | calldate &lt;date&gt; | transcriptid &lt;int&gt; | numest &lt;dbl&gt; | n_analyst &lt;int&gt; | n_company &lt;int&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| 001013 | 2009-06-03 | 23454 | NA | 6 | 6 |\n",
       "\n"
      ],
      "text/plain": [
       "  gvkey  calldate   transcriptid numest n_analyst n_company\n",
       "1 001013 2009-06-03 23454        NA     6         6        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysts = speaker[speakertypename=='Analysts'\n",
    "    ][f_ciq_transcript_detail_sp500[,.(transcriptid, gvkey, calldate=mostimportantdateutc)], on=.(transcriptid), nomatch=NULL\n",
    "    ][ciq_wrds_professional[, .(proid, companyid)], on=.(proid), nomatch=NULL\n",
    "    ][, .(n_analyst=uniqueN(proid), n_company=uniqueN(companyid)), keyby=.(gvkey, transcriptid, calldate)\n",
    "    ]\n",
    "\n",
    "\n",
    "analysts = earnings[, .(transcriptid, numest)\n",
    "    ][analysts, .(gvkey, calldate, transcriptid, numest, n_analyst, n_company), on=.(transcriptid)\n",
    "    ][order(gvkey, calldate, transcriptid)]\n",
    "\n",
    "analysts[1]\n",
    "\n",
    "analysts %>% fwrite('data/analysts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n",
       "   2.00    7.00   11.00   12.62   17.00   49.00   12183 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n",
       "  1.000   7.000   9.000   9.259  12.000  27.000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysts[, summary(numest)]\n",
    "analysts[, summary(n_analyst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.table: 1 × 136</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>docid</th><th scope=col>present_positive_chunk</th><th scope=col>present_positive_sent</th><th scope=col>present_neutral_chunk</th><th scope=col>present_neutral_sent</th><th scope=col>present_negative_chunk</th><th scope=col>present_negative_sent</th><th scope=col>qa_positive_chunk</th><th scope=col>qa_positive_sent</th><th scope=col>qa_neutral_chunk</th><th scope=col>⋯</th><th scope=col>volatility_norm</th><th scope=col>volume_norm</th><th scope=col>similarity_bigram_norm</th><th scope=col>qa_positive_sent_norm</th><th scope=col>outlier_flag1</th><th scope=col>i.gvkey</th><th scope=col>calldate</th><th scope=col>i.numest</th><th scope=col>n_analyst</th><th scope=col>n_company</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;lgl&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;date&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>001013-2010-05-05</td><td>0.7199231</td><td>0.3747692</td><td>0.1030769</td><td>0.5261538</td><td>0.1030769</td><td>0.5261538</td><td>0.5890883</td><td>0.2158689</td><td>0.09418803</td><td>⋯</td><td>1.021818</td><td>-0.1758587</td><td>-0.1371144</td><td>-0.7544068</td><td>FALSE</td><td>001013</td><td>2010-05-05</td><td>11</td><td>9</td><td>9</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.table: 1 × 136\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " docid & present\\_positive\\_chunk & present\\_positive\\_sent & present\\_neutral\\_chunk & present\\_neutral\\_sent & present\\_negative\\_chunk & present\\_negative\\_sent & qa\\_positive\\_chunk & qa\\_positive\\_sent & qa\\_neutral\\_chunk & ⋯ & volatility\\_norm & volume\\_norm & similarity\\_bigram\\_norm & qa\\_positive\\_sent\\_norm & outlier\\_flag1 & i.gvkey & calldate & i.numest & n\\_analyst & n\\_company\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <lgl> & <chr> & <date> & <dbl> & <int> & <int>\\\\\n",
       "\\hline\n",
       "\t 001013-2010-05-05 & 0.7199231 & 0.3747692 & 0.1030769 & 0.5261538 & 0.1030769 & 0.5261538 & 0.5890883 & 0.2158689 & 0.09418803 & ⋯ & 1.021818 & -0.1758587 & -0.1371144 & -0.7544068 & FALSE & 001013 & 2010-05-05 & 11 & 9 & 9\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.table: 1 × 136\n",
       "\n",
       "| docid &lt;chr&gt; | present_positive_chunk &lt;dbl&gt; | present_positive_sent &lt;dbl&gt; | present_neutral_chunk &lt;dbl&gt; | present_neutral_sent &lt;dbl&gt; | present_negative_chunk &lt;dbl&gt; | present_negative_sent &lt;dbl&gt; | qa_positive_chunk &lt;dbl&gt; | qa_positive_sent &lt;dbl&gt; | qa_neutral_chunk &lt;dbl&gt; | ⋯ ⋯ | volatility_norm &lt;dbl&gt; | volume_norm &lt;dbl&gt; | similarity_bigram_norm &lt;dbl&gt; | qa_positive_sent_norm &lt;dbl&gt; | outlier_flag1 &lt;lgl&gt; | i.gvkey &lt;chr&gt; | calldate &lt;date&gt; | i.numest &lt;dbl&gt; | n_analyst &lt;int&gt; | n_company &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 001013-2010-05-05 | 0.7199231 | 0.3747692 | 0.1030769 | 0.5261538 | 0.1030769 | 0.5261538 | 0.5890883 | 0.2158689 | 0.09418803 | ⋯ | 1.021818 | -0.1758587 | -0.1371144 | -0.7544068 | FALSE | 001013 | 2010-05-05 | 11 | 9 | 9 |\n",
       "\n"
      ],
      "text/plain": [
       "  docid             present_positive_chunk present_positive_sent\n",
       "1 001013-2010-05-05 0.7199231              0.3747692            \n",
       "  present_neutral_chunk present_neutral_sent present_negative_chunk\n",
       "1 0.1030769             0.5261538            0.1030769             \n",
       "  present_negative_sent qa_positive_chunk qa_positive_sent qa_neutral_chunk\n",
       "1 0.5261538             0.5890883         0.2158689        0.09418803      \n",
       "  <U+22EF>   volatility_norm volume_norm similarity_bigram_norm\n",
       "1 <U+22EF> 1.021818        -0.1758587  -0.1371144            \n",
       "  qa_positive_sent_norm outlier_flag1 i.gvkey calldate   i.numest n_analyst\n",
       "1 -0.7544068            FALSE         001013  2010-05-05 11       9        \n",
       "  n_company\n",
       "1 9        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = earnings[analysts, on=.(transcriptid)][!is.na(docid)]\n",
    "dt[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "lm(formula = car_0_30_norm ~ mcap_norm + sue + car_m1_m1 + car_m2_m2 + \n",
       "    car_m30_m3 + bm + roa + debt_asset + volatility + alpha + \n",
       "    numest + sstdest + smedest + volume + inflow + revision + \n",
       "    I(growth(n_analyst)), data = dt)\n",
       "\n",
       "Residuals:\n",
       "    Min      1Q  Median      3Q     Max \n",
       "-5.2185 -0.4066  0.0156  0.4200  7.9833 \n",
       "\n",
       "Coefficients:\n",
       "                       Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)           4.274e-02  2.960e-02   1.444  0.14880    \n",
       "mcap_norm            -4.464e-02  7.559e-03  -5.906 3.58e-09 ***\n",
       "sue                   3.860e+00  4.246e-01   9.091  < 2e-16 ***\n",
       "car_m1_m1            -6.860e-03  3.984e-03  -1.722  0.08508 .  \n",
       "car_m2_m2            -8.950e-03  4.084e-03  -2.192  0.02843 *  \n",
       "car_m30_m3           -3.325e-03  7.916e-04  -4.200 2.68e-05 ***\n",
       "bm                    1.347e-02  1.423e-02   0.947  0.34390    \n",
       "roa                   9.599e-02  6.735e-02   1.425  0.15415    \n",
       "debt_asset            2.091e-03  2.829e-02   0.074  0.94110    \n",
       "volatility           -7.095e-03  7.394e-03  -0.960  0.33726    \n",
       "alpha                -2.582e+00  4.816e-02 -53.617  < 2e-16 ***\n",
       "numest               -2.581e-03  8.642e-04  -2.986  0.00283 ** \n",
       "sstdest              -1.134e+00  6.107e-01  -1.857  0.06334 .  \n",
       "smedest              -1.468e-01  2.190e-01  -0.670  0.50265    \n",
       "volume               -8.396e-04  1.954e-04  -4.296 1.75e-05 ***\n",
       "inflow                2.153e-05  1.005e-06  21.425  < 2e-16 ***\n",
       "revision              4.885e-02  3.198e-03  15.277  < 2e-16 ***\n",
       "I(growth(n_analyst))  6.505e-04  1.305e-02   0.050  0.96025    \n",
       "---\n",
       "Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n",
       "\n",
       "Residual standard error: 0.7752 on 18222 degrees of freedom\n",
       "  (1 observation deleted due to missingness)\n",
       "Multiple R-squared:  0.1984,\tAdjusted R-squared:  0.1977 \n",
       "F-statistic: 265.4 on 17 and 18222 DF,  p-value: < 2.2e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm(car_0_30_norm ~ mcap_norm + sue + car_m1_m1 + car_m2_m2 + car_m30_m3 + bm + roa + debt_asset + \n",
    "    volatility + alpha + numest + sstdest + smedest + volume + inflow + revision + I(growth(n_analyst)), data=dt) %>% summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R-4.0.3",
   "language": "R",
   "name": "ir403"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.4"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
