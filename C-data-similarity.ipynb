{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: /home/yu/OneDrive/CC\n",
      "DATA_DIR: /home/yu/OneDrive/CC/data\n"
     ]
    }
   ],
   "source": [
    "import datatable as dt\n",
    "import numpy as np\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from datatable import f, join\n",
    "from spacy.tokens import Doc, DocBin, Span\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dt.init_styles()\n",
    "\n",
    "ROOT_DIR = '/home/yu/OneDrive/CC'\n",
    "DATA_DIR = f'{ROOT_DIR}/data'\n",
    "\n",
    "print(f'ROOT_DIR: {ROOT_DIR}')\n",
    "print(f'DATA_DIR: {DATA_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-gram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Computing similarity using bag-of-words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Doc to \"text tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74a781665574b64882529882c25081a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load DocBin from disk\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "docs = []\n",
    "for _ in tqdm(range(10)):\n",
    "    docs.extend(list(DocBin(store_user_data=True).from_disk(f'data/doc_sp500_lg_{_}.spacy').get_docs(nlp.vocab)))\n",
    "\n",
    "# register extension for Doc\n",
    "Doc.set_extension('transcriptid', default=None, force=True)\n",
    "\n",
    "# Register extension for Span\n",
    "Span.set_extension('transcriptid', default=None, force=True)\n",
    "Span.set_extension('componentid', default=None, force=True)\n",
    "Span.set_extension('componentorder', default=None, force=True)\n",
    "Span.set_extension('componenttypeid', default=None, force=True)\n",
    "Span.set_extension('speakerid', default=None, force=True)\n",
    "Span.set_extension('speakertypeid', default=None, force=True)\n",
    "Span.set_extension('is_component', default=False, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"text_component_sp500.feather\" (978.0 MB) loaded as \"text_component\" (3s)\n"
     ]
    }
   ],
   "source": [
    "# Select componentid that belongs to MD and QA\n",
    "ld('text_component_sp500', ldname='text_component')\n",
    "text_component = dt.Frame(text_component)\n",
    "\n",
    "# componentid: Management Discussion\n",
    "componentids_md = text_component[(f.transcriptcomponenttypeid==2) & (f.speakertypeid==2), f.transcriptcomponentid].to_list()[0]\n",
    "componentids_md = set(componentids_md)\n",
    "\n",
    "# componentid: Q & A\n",
    "componentids_qa = text_component[((f.transcriptcomponenttypeid==3) | (f.transcriptcomponenttypeid==4)) & ((f.speakertypeid==2)|(f.speakertypeid==3)), f.transcriptcomponentid].to_list()[0]\n",
    "componentids_qa = set(componentids_qa)\n",
    "\n",
    "\n",
    "del text_component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ae22b206a9e4f34b752a9e196ae608b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"texttoken_qa\" saved as \"texttoken_qa.pkl\" (1.2 GB) (45s)\n"
     ]
    }
   ],
   "source": [
    "# Convert Doc to \"text tokens\"\n",
    "\n",
    "# Filtering Rule:\n",
    "# - only keep lemma\n",
    "# - KEEP stop words (stop words is informative while comparing)\n",
    "# - no punctuation\n",
    "# - no \"like number\"\n",
    "\n",
    "def make_text_tokens(docs, componentids):\n",
    "    texttoken = {}\n",
    "    \n",
    "    # For every doc, join the required spans into a list of str\n",
    "    for doc in tqdm(docs):\n",
    "        txttok = []\n",
    "        for span in doc.spans['components']:\n",
    "            if span._.componentid in componentids:\n",
    "                txttok.extend([t.lemma_ for t in span \n",
    "                if ((not t.is_punct) & (not t.like_num))])\n",
    "\n",
    "        # If no text found, add an empty str\n",
    "        if len(txttok)==0:\n",
    "            txttok = ['']\n",
    "\n",
    "        # return\n",
    "        texttoken[doc._.transcriptid] = txttok\n",
    "    \n",
    "    return texttoken\n",
    "\n",
    "texttoken_md = make_text_tokens(docs, componentids_md)\n",
    "sv('texttoken_md')\n",
    "\n",
    "texttoken_qa = make_text_tokens(docs, componentids_qa)\n",
    "sv('texttoken_qa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to DTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"texttoken_qa.pkl\" (1.2 GB) loaded (14s)\n",
      "\"texttoken_md.pkl\" (894.5 MB) loaded (9s)\n"
     ]
    }
   ],
   "source": [
    "ld('texttoken_qa')\n",
    "ld('texttoken_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n",
      "Computing similarity...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "becd53455cb147659dbab31610cd9ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"similarity_allgram\" saved as \"similarity_allgram.feather\" (439.6 KB) (<1s)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Convert to DTM\n",
    "\n",
    "# Setting:\n",
    "# - keep ALL tokens\n",
    "\n",
    "def get_similarity(ngram_type:str):\n",
    "    if ngram_type == 'unigram':\n",
    "        ngram_range = (1,1)\n",
    "    elif ngram_type == 'bigram':\n",
    "        ngram_range = (2,2)\n",
    "    elif ngram_type == 'allgram':\n",
    "        ngram_range = (1,2)\n",
    "    else:\n",
    "        print('Wrong ngram_type!')\n",
    "    \n",
    "    print('Tokenizing...')\n",
    "    vectorizer = CountVectorizer(preprocessor=lambda x: x,\n",
    "                                 tokenizer=lambda x: x,\n",
    "                                 lowercase=False,\n",
    "                                 ngram_range=ngram_range)\n",
    "\n",
    "    # Learn vocabulary \n",
    "    vectorizer.fit(texttoken_md.values())\n",
    "    vectorizer.fit(texttoken_qa.values())\n",
    "\n",
    "    # Make DTM\n",
    "    dtm_md = vectorizer.transform(texttoken_md.values())\n",
    "    dtm_qa = vectorizer.transform(texttoken_qa.values())\n",
    "    \n",
    "    # get transcriptid\n",
    "    assert list(texttoken_md.keys())==list(texttoken_qa.keys()),\\\n",
    "           'transcriptids of MD and QA are different!'\n",
    "    transcriptids = list(texttoken_md.keys())\n",
    "    \n",
    "    # compute similarity\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    similarity = []\n",
    "    n = dtm_md.shape[0]\n",
    "\n",
    "    print('Computing similarity...')\n",
    "    for i in tqdm(range(n)):\n",
    "        s = cosine_similarity(dtm_md[i,:],dtm_qa[i,:])[0,0]\n",
    "        similarity.append(s)\n",
    "        \n",
    "    df = dt.Frame({'transcriptid':transcriptids, \n",
    "                   f'similarity_{ngram_type}':similarity})\n",
    "        \n",
    "    return df\n",
    "\n",
    "# similarity_unigram = get_similarity('unigram')\n",
    "# sv('similarity_unigram')\n",
    "\n",
    "# similarity_bigram = get_similarity('bigram')\n",
    "# sv('similarity_bigram')\n",
    "\n",
    "similarity_allgram = get_similarity('allgram')\n",
    "sv('similarity_allgram')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity_unigram (439.5 KB) already loaded, will NOT load again!\n",
      "similarity_bigram (439.4 KB) already loaded, will NOT load again!\n",
      "similarity_allgram (439.6 KB) already loaded, will NOT load again!\n"
     ]
    }
   ],
   "source": [
    "ld('similarity_unigram')\n",
    "ld('similarity_bigram')\n",
    "ld('similarity_allgram')\n",
    "\n",
    "similarity_unigram.key = 'transcriptid'\n",
    "similarity_bigram.key = 'transcriptid'\n",
    "similarity_allgram.key = 'transcriptid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = similarity_unigram[:,:,join(similarity_bigram)\n",
    "    ][:,:,join(similarity_allgram)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"similarity\" saved as \"similarity.feather\" (1022.2 KB) (<1s)\n"
     ]
    }
   ],
   "source": [
    "sv('similarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing similarity using FinBERT**\n",
    "\n",
    "Steps:\n",
    "- Load sentence sentence embeddings\n",
    "- Average embeddings for MD and QA\n",
    "- Compute similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.5 s, sys: 7.14 s, total: 48.7 s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# load all pre-embedding\n",
    "emb0 = torch.load(f'{DATA_DIR}/Embeddings/preembeddings_longformer_rank0.pt')\n",
    "emb1 = torch.load(f'{DATA_DIR}/Embeddings/preembeddings_longformer_rank1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa1b66baee949a9beee85474fbaad19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37448 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for tid, cid_emb in tqdm(emb1.items()):\n",
    "    for cid, emb in cid_emb.items():\n",
    "        emb0[tid].update({cid:emb})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tid-cid pairs\n",
    "def load_tid_cid_pair(tid_cid_pair_name):\n",
    "    '''load DataFrame tid_cid_pair, convert it into a Dict\n",
    "    \n",
    "    output: {tid:[cid1, cid2, ...]}\n",
    "    \n",
    "    tid_cid_pair_name: str. e.g., \"md\", \"qa\", \"all\"\n",
    "    '''\n",
    "    pair = feather.read_feather(f'data/tid_cid_pair_{tid_cid_pair_name}.feather')\n",
    "    tids = pair.transcriptid.tolist()\n",
    "    cids = [cid.tolist() for cid in pair.componentid]\n",
    "    \n",
    "    return dict(zip(tids, cids))\n",
    "\n",
    "tid_cid_pair_md = load_tid_cid_pair('md')\n",
    "tid_cid_pair_qa = load_tid_cid_pair('qa_manager')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130bb8756030453d927006c8dd51b215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/37630 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N calls with MD/QA missing: 904\n",
      "\"similarity\" saved as \"similarity_longformer.feather\" (337.9 KB) (<1s) (2021-03-10 7:16 PM)\n"
     ]
    }
   ],
   "source": [
    "# if have both MD and QA, compute similarity\n",
    "# else, similarity is 1\n",
    "null_similarity = 0\n",
    "outputs = {}\n",
    "\n",
    "for i, (tid, components) in enumerate(tqdm(emb0.items())):\n",
    "        \n",
    "    cids_md = tid_cid_pair_md.get(tid,{})\n",
    "    cids_qa = tid_cid_pair_qa.get(tid,{})\n",
    "    \n",
    "    if len(cids_md)>0 and len(cids_qa)>0:\n",
    "        emb_md = [emb['embedding'] for cid, emb in components.items()\n",
    "                  if cid in cids_md]\n",
    "        emb_md = torch.stack(emb_md).max(dim=0).values.unsqueeze(dim=0)\n",
    "        \n",
    "        emb_qa = [emb['embedding'] for cid, emb in components.items()\n",
    "                  if cid in cids_qa]\n",
    "        emb_qa = torch.stack(emb_qa).max(dim=0).values.unsqueeze(dim=0)\n",
    "        \n",
    "        similarity = F.cosine_similarity(emb_md, emb_qa).item()\n",
    "    else:\n",
    "        similarity = 1\n",
    "        null_similarity += 1\n",
    "    \n",
    "    outputs[tid] = similarity\n",
    "    \n",
    "print(f'N calls with MD/QA missing: {null_similarity}')\n",
    "\n",
    "similarity = dt.Frame({'transcriptid':list(outputs.keys()),\n",
    "                       'similarity_longformer':list(outputs.values())})\n",
    "sv('similarity', 'similarity_longformer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37630, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
