{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       ".datatable .frame thead tr.colnames {  background-image: url('data:image/png;base64,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');  background-repeat: repeat-x;  background-size: 14px;  height: 28px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR: .\n",
      "DATA_DIR: ./data\n",
      "CHECKPOINT_DIR: d:/checkpoints/earnings-call\n",
      "\n",
      "2 GPUs found:\n",
      "    GeForce RTX 2080 Ti (cuda0)\n",
      "    GeForce RTX 2080 Ti (cuda1)\n",
      "\n",
      "GPU memory:\n",
      "GPU 0:  0.00/ 11.00 (GB)\n",
      "GPU 1:  0.00/ 11.00 (GB)\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "import comet_ml\n",
    "import copy\n",
    "import datatable as dt\n",
    "import gc\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pytorch_lightning as pl\n",
    "import spacy\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import pyarrow.feather as feather\n",
    "\n",
    "from collections import OrderedDict, defaultdict\n",
    "from datatable import f, update\n",
    "from spacy.lang.en import English\n",
    "from argparse import Namespace\n",
    "from scipy.sparse import coo_matrix\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "from operator import itemgetter\n",
    "from torch import nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# working directory\n",
    "ROOT_DIR = '.'\n",
    "DATA_DIR = f'{ROOT_DIR}/data'\n",
    "CHECKPOINT_DIR = 'd:/checkpoints/earnings-call'\n",
    "CHECKPOINT_TEMP_DIR = f'{ROOT_DIR}/checkpoint/earnings-call/temp'\n",
    "\n",
    "print(f'ROOT_DIR: {ROOT_DIR}')\n",
    "print(f'DATA_DIR: {DATA_DIR}')\n",
    "print(f'CHECKPOINT_DIR: {CHECKPOINT_DIR}')\n",
    "\n",
    "# COMET API KEY\n",
    "COMET_API_KEY = 'tOoHzzV1S039683RxEr2Hl9PX'\n",
    "\n",
    "# set random seed\n",
    "torch.backends.cudnn.deterministic = False;\n",
    "torch.backends.cudnn.benchmark = True;\n",
    "torch.backends.cudnn.enabled = True\n",
    "\n",
    "# set device 'cuda' or 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    n_cuda = torch.cuda.device_count();\n",
    "    \n",
    "    def log_gpu_memory(verbose=False):\n",
    "        torch.cuda.empty_cache()\n",
    "        if verbose:\n",
    "            for _ in range(n_cuda):\n",
    "                print(f'GPU {_}:')\n",
    "                print(f'{torch.cuda.memory_summary(_, abbreviated=True)}')\n",
    "        else:\n",
    "            for _ in range(n_cuda):\n",
    "                memory_total = torch.cuda.get_device_properties(_).total_memory/(1024**3)\n",
    "                memory_allocated = torch.cuda.memory_allocated(_)/(1024**3)\n",
    "                print(f'GPU {_}: {memory_allocated: .2f}/{memory_total: .2f} (GB)')\n",
    "            \n",
    "    print(f'\\n{n_cuda} GPUs found:');\n",
    "    for _ in range(n_cuda):\n",
    "        globals()[f'cuda{_}'] = torch.device(f'cuda:{_}');\n",
    "        print(f'    {torch.cuda.get_device_name(_)} (cuda{_})');\n",
    "        \n",
    "    print('\\nGPU memory:');\n",
    "    log_gpu_memory();\n",
    "else:\n",
    "    print('GPU NOT enabled');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper: tensor_to_list\n",
    "def tensor_to_str(tensor, tailing='\\n'):\n",
    "    '''Given a 1d tensor, convert it to a list of string\n",
    "    \n",
    "    tailing: str. Added to the end of every element\n",
    "    '''\n",
    "    assert isinstance(tensor, torch.Tensor), 'Give me a tensor please!'\n",
    "    assert len(tensor.shape)==1, 'Must be 1D tensor!'\n",
    "    tensor = tensor.to('cpu').tolist()\n",
    "    tensor = [f'{str(x)}{tailing}' for x in tensor]\n",
    "    return tensor\n",
    "\n",
    "# helper: str_to_int\n",
    "def str_to_int(string):\n",
    "    '''Given a string, convert it into int\n",
    "    '''\n",
    "    str_as_bytes = string.encode('utf-8')\n",
    "    return int.from_bytes(str_as_bytes, 'little')\n",
    "\n",
    "# helper: int_to_str\n",
    "def int_to_str(integer):\n",
    "    '''Given a int, convert it into str\n",
    "    '''\n",
    "    int_as_bytes = integer.to_bytes((integer.bit_length() + 7) // 8, 'little')\n",
    "    return int_as_bytes.decode('utf-8')\n",
    "\n",
    "# helper: refresh cuda memory\n",
    "def refresh_cuda_memory():\n",
    "    \"\"\"\n",
    "    Re-allocate all cuda memory to help alleviate fragmentation\n",
    "    \"\"\"\n",
    "    # Run a full garbage collect first so any dangling tensors are released\n",
    "    gc.collect()\n",
    "\n",
    "    # Then move all tensors to the CPU\n",
    "    for obj in gc.get_objects():\n",
    "        if isinstance(obj, torch.Tensor) and obj.device!=torch.device('cpu'):\n",
    "            obj.data = torch.empty(0)\n",
    "            if isinstance(obj, torch.nn.Parameter) and obj.grad is not None:\n",
    "                obj.grad.data = torch.empty(0)\n",
    "\n",
    "    # Now empty the cache to flush the allocator\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# helper: flush chpt\n",
    "def refresh_ckpt():\n",
    "    '''\n",
    "    move all `.ckpt` files to `/temp`\n",
    "    '''\n",
    "    # create ckpt_dir if not exists\n",
    "    if not os.path.exists(CHECKPOINT_DIR):\n",
    "        os.makedirs(CHECKPOINT_DIR)\n",
    "    \n",
    "    # create ckpt_temp_dir if not exists\n",
    "    if not os.path.exists(CHECKPOINT_TEMP_DIR):\n",
    "        os.makedirs(CHECKPOINT_TEMP_DIR)\n",
    "    \n",
    "    for name in os.listdir(CHECKPOINT_DIR):\n",
    "        if name.endswith('.ckpt'):\n",
    "            shutil.move(f'{CHECKPOINT_DIR}/{name}', f'{CHECKPOINT_DIR}/temp/{name}')\n",
    "\n",
    "# helpers: load targets\n",
    "def load_targets(targets_name, force=False):\n",
    "    if ('targets_df' not in globals()) or (force==True):\n",
    "        print(f'Loading targets...@{Now()}')\n",
    "        globals()['targets_df'] = pd.read_feather(f'{DATA_DIR}/{targets_name}.feather')\n",
    "        print(f'Loading finished. @{Now()}')\n",
    "        \n",
    "        global targets_df\n",
    "        targets_df = targets_df[targets_df.outlier_flag1==False]\n",
    "        \n",
    "# helpers: load preembeddings\n",
    "def load_preembeddings(preembedding_type):\n",
    "    if 'preembeddings' not in globals():\n",
    "        print(f'Loading preembeddings: {preembedding_type}...@{Now()}')\n",
    "        globals()['preembeddings'] = torch.load(f\"{DATA_DIR}/embeddings/preembeddings_{preembedding_type}.pt\")\n",
    "        print(f'Loading preembeddings finished. @{Now()}')\n",
    "        \n",
    "# helpers: load split_df\n",
    "def load_split_df(roll_type):\n",
    "    split_df = pd.read_csv(f'{DATA_DIR}/split_dates.csv')\n",
    "    globals()['split_df'] = split_df.loc[split_df.roll_type==roll_type]\n",
    "    \n",
    "# helper: log_ols_rmse\n",
    "def log_ols_rmse(logger, yqtr):\n",
    "    '''\n",
    "    Given yqtr, find the corresponding ols_rmse from `performance_by_model.feather`.\n",
    "    Always compare to the same model: 'ols: car_norm ~ fr'\n",
    "    then log to Comet\n",
    "    '''\n",
    "    performance = dt.Frame(pd.read_feather('data/performance_by_yqtr.feather'))\n",
    "\n",
    "    ols_rmse_norm = performance[(f.model_name=='ols: car_norm ~ fr') & (f.roll_type=='3y') & (f.yqtr==yqtr), f.rmse][0,0]\n",
    "    logger.experiment.log_parameter('ols_rmse_norm', ols_rmse_norm)\n",
    "    \n",
    "def log_test_start(logger, roll_type, yqtr):\n",
    "    '''\n",
    "    Given window, find the corresponding star/end date of the training/test periods, \n",
    "    then log to Comet\n",
    "    '''\n",
    "    split_df = pd.read_csv(f'data/split_dates.csv')\n",
    "\n",
    "    _, train_start, train_end, test_start, test_end, _, _, _ = tuple(split_df.loc[(split_df.yqtr==yqtr) & (split_df.roll_type==roll_type)].iloc[0])\n",
    "    \n",
    "    logger.experiment.log_parameter('train_start', train_start)\n",
    "    logger.experiment.log_parameter('train_end', train_end)\n",
    "    logger.experiment.log_parameter('test_start', test_start)\n",
    "    logger.experiment.log_parameter('test_end', test_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset\n",
    "class CCDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, yqtr, split_type, text_in_dataset, roll_type, preembeddings, targets_df, split_df, valid_transcriptids=None):\n",
    "        '''\n",
    "        Args:\n",
    "            preembeddings (from globals): list of embeddings. Each element is a tensor (S, E) where S is number of sentences in a call\n",
    "            targets_df (from globals): DataFrame of targets variables.\n",
    "            split_df (from globals):\n",
    "            ytqr: str. e.g., \"2008-q3\"\n",
    "            split_type: str. 'train', 'val', or 'test'\n",
    "            text_only: only output CAR and transcripts if true, otherwise also output financial ratios\n",
    "            transcriptids: list. If provided, only the given transcripts will be used in generating the Dataset. `transcriptids` is applied **on top of** `yqtr` and `split_type`\n",
    "        '''\n",
    "\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        # Given the stage (train/val/test), find the valid `transcriptids` from `targets_df`\n",
    "        # ----------------------------------------------------------------------------------\n",
    "        \n",
    "        # get split dates from `split_df`\n",
    "        _, train_start, train_end, test_start, test_end, _, yqtr, is_test = tuple(split_df.loc[(split_df.yqtr==yqtr) & (split_df.roll_type==roll_type)].iloc[0])\n",
    "        \n",
    "        # print current window\n",
    "        print(f'Current window: {yqtr} ({roll_type}) \\n(train: {train_start} to {train_end}) (test: {test_start} to {test_end})')\n",
    "        \n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d').date()\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d').date()\n",
    "        test_start = datetime.strptime(test_start, '%Y-%m-%d').date()\n",
    "        test_end = datetime.strptime(test_end, '%Y-%m-%d').date()\n",
    "        \n",
    "        # select valid transcriptids (preemb_keys) according to split dates \n",
    "        if split_type=='train':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(train_start, train_end)].transcriptid.sample(frac=1, random_state=42).tolist()\n",
    "            transcriptids = transcriptids[:int(len(transcriptids)*0.9)]\n",
    "            # print(f'Dateset -> N train: {len(transcriptids)}')\n",
    "            \n",
    "        if split_type=='val':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(train_start, train_end)].transcriptid.sample(frac=1, random_state=42).tolist()\n",
    "            transcriptids = transcriptids[int(len(transcriptids)*0.9):]\n",
    "            # print(f'Dataset -> N val: {len(transcriptids)}')\n",
    "\n",
    "        elif split_type=='test':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(test_start, test_end)].transcriptid.tolist()\n",
    "            # print(f'Dataset -> N test: {len(transcriptids)}')\n",
    "\n",
    "        # ----------------------------------------------------------------------------\n",
    "        # Select valid sentence embeddings from `preembeddings` \n",
    "        # ----------------------------------------------------------------------------\n",
    "        preembeddings = {k: v['embedding'] for k, v in preembeddings.items() if 5<=v['seq_len']<=384}\n",
    "        transcriptids_from_preembeddings = preembeddings.keys()\n",
    "        \n",
    "        self.valid_preemb_keys = set(transcriptids).intersection(set(transcriptids_from_preembeddings))\n",
    "        \n",
    "        if valid_transcriptids is not None:\n",
    "            self.valid_preemb_keys = self.valid_preemb_keys.intersection(set(valid_transcriptids))\n",
    "        \n",
    "        # ----------------------------------------------------------------------------\n",
    "        # Consolidate`preembeddings` by `transcriptid` \n",
    "        # ----------------------------------------------------------------------------\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        # self attributes\n",
    "        self.text_in_dataset = text_in_dataset\n",
    "        if text_in_dataset:\n",
    "            self.preembeddings = preembeddings\n",
    "        self.targets_df = targets_df\n",
    "        self.train_start = train_start\n",
    "        self.train_end = train_end\n",
    "        self.test_start = test_start\n",
    "        self.test_end = test_end\n",
    "        self.n_samples = len(self.sent_len)\n",
    "        self.split_type = split_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.valid_preemb_keys))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        transcriptid = self.valid_preemb_keys[idx]\n",
    "        targets = self.targets_df[self.targets_df.transcriptid==transcriptid].iloc[0]\n",
    "        \n",
    "        # all of the following targests are\n",
    "        # of type `numpy.float64`\n",
    "        transcriptid = targets.transcriptid\n",
    "        car_0_30 = targets.car_0_30\n",
    "        car_0_30_norm = targets.car_0_30_norm\n",
    "        revision = targets.revision\n",
    "        revision_norm = targets.revision_norm\n",
    "        inflow = targets.inflow\n",
    "        inflow_norm = targets.inflow_norm\n",
    "        \n",
    "        # using the normalized features\n",
    "        similarity = targets.similarity_bigram_norm\n",
    "        sentiment = targets.qa_positive_sent_norm\n",
    "        sue = targets.sue_norm\n",
    "        sest = targets.sest_norm        \n",
    "        alpha = targets.alpha_norm\n",
    "        volatility = targets.volatility_norm\n",
    "        mcap = targets.mcap_norm\n",
    "        bm = targets.bm_norm\n",
    "        roa = targets.roa_norm\n",
    "        debt_asset = targets.debt_asset_norm\n",
    "        numest = targets.numest_norm\n",
    "        smedest = targets.smedest_norm\n",
    "        sstdest = targets.sstdest_norm\n",
    "        car_m1_m1 = targets.car_m1_m1_norm\n",
    "        car_m2_m2 = targets.car_m2_m2_norm\n",
    "        car_m30_m3 = targets.car_m30_m3_norm\n",
    "        volume = targets.volume_norm\n",
    "\n",
    "        # using the unnormalized features\n",
    "#         similarity = targets.similarity_bigram\n",
    "#         sentiment = targets.qa_positive_sent\n",
    "#         sue = targets.sue\n",
    "#         sest = targets.sest        \n",
    "#         alpha = targets.alpha\n",
    "#         volatility = targets.volatility\n",
    "#         mcap = targets.mcap\n",
    "#         bm = targets.bm\n",
    "#         roa = targets.roa\n",
    "#         debt_asset = targets.debt_asset\n",
    "#         numest = targets.numest\n",
    "#         smedest = targets.smedest\n",
    "#         sstdest = targets.sstdest\n",
    "#         car_m1_m1 = targets.car_m1_m1\n",
    "#         car_m2_m2 = targets.car_m2_m2\n",
    "#         car_m30_m3 = targets.car_m30_m3\n",
    "#         volume = targets.volume\n",
    "        \n",
    "        if self.text_in_dataset:\n",
    "            # inputs: preembeddings\n",
    "            embeddings = self.preembeddings[transcriptid]\n",
    "            \n",
    "            [for kself.preembeddings]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1381852-37'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time embedding = torch.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%time x = [(k, v['embedding']) for k, v in embedding.items() if 5<=v['seq_len']<=384]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.35 s\n"
     ]
    }
   ],
   "source": [
    "# sort by (sentence_id)\n",
    "%time x.sort(key=itemgetter(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# group by transcriptid\n",
    "preembeddings_bytid = defaultdict(list)\n",
    "for sentence_id, emb in x:\n",
    "    transcriptid = sentence_id.split('-')[0]\n",
    "    preembeddings_bytid[transcriptid].append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2691848"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(preembeddings_bytid.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b231ab28afa547e58f87523a06c70918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2691848.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 3min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preembeddings_bytid_stacked = {}\n",
    "\n",
    "for tid, emb in tqdm(preembeddings_bytid.items()):\n",
    "    preembeddings_bytid_stacked[tid] = torch.stack(emb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preembeddings_bytid_stacked = {}\n",
    "for k, v in tqdm(preembeddings_bytid.items()):\n",
    "    preembeddings_bytid_stacked[k] = torch.tensor(np.array(v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tid = '1381852'\n",
    "y = [v for k, v in x.items() if k.split('-')==tid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.3656e-02,  2.3253e-01,  2.0231e-01,  2.4657e-01,  4.6641e-01,\n",
       "        -1.2559e-02, -3.6655e-01,  4.6476e-01,  5.5063e-02, -3.6583e-01,\n",
       "         1.2985e-02, -1.2972e-01,  2.3559e-02,  2.0235e-01,  1.1747e-02,\n",
       "         4.4340e-01,  2.1462e-03,  7.3564e-02,  2.2835e-02,  2.3315e-02,\n",
       "        -2.5114e-02, -2.0746e-01,  2.9869e-01,  7.4307e-01,  3.0696e-01,\n",
       "        -2.1563e-01, -1.6620e-02,  4.6268e-02, -2.7606e-01,  5.9830e-02,\n",
       "         4.9956e-01,  1.3490e-01, -3.1527e-02, -1.7059e-01, -8.4302e-02,\n",
       "        -1.4236e-01, -3.1760e-01, -9.9316e-03, -3.8102e-01,  6.6118e-02,\n",
       "        -5.5576e-01, -1.9150e-01,  1.3999e-01,  1.9407e-02, -2.9719e-01,\n",
       "        -4.2952e-02,  2.2184e-01,  1.1191e-01, -5.3483e-02, -8.9890e-03,\n",
       "        -5.4763e-01, -9.1499e-02,  5.9650e-02,  1.5307e-01,  9.7298e-02,\n",
       "         2.8254e-01, -1.4394e-02, -2.4715e-01, -1.2995e-01, -3.1836e-01,\n",
       "         1.6169e-01, -1.8035e-01, -1.0518e-01,  2.5295e-02,  9.0924e-02,\n",
       "         1.0816e-01,  4.8091e-01, -1.1789e-02, -4.4807e-01, -1.5193e-01,\n",
       "        -9.4754e-02,  5.9170e-02, -1.9682e-01, -1.0953e-02, -1.0644e-01,\n",
       "        -1.4896e-01,  3.7228e-02, -5.3805e-02,  2.9527e-02,  4.0776e-02,\n",
       "        -2.8546e-02,  3.6019e-01, -4.3416e-01,  3.6507e-01, -2.8346e-02,\n",
       "         1.1092e-01,  1.5296e-01,  1.3128e-01, -6.3886e-02,  4.5519e-02,\n",
       "         1.6632e-02, -4.2587e-02,  4.0645e-01,  4.1720e-02,  2.9740e-01,\n",
       "        -8.6825e-02,  8.3586e-02, -9.3457e-02,  9.2976e-02,  5.5937e-01,\n",
       "        -1.6639e-01, -1.0509e-01,  1.4883e-01,  1.8770e-01, -1.0078e-01,\n",
       "        -1.9507e-01, -8.1350e-02,  3.7481e-01, -1.3065e-01,  2.3004e-01,\n",
       "         1.7937e-01, -7.8575e-02, -1.6689e-01, -3.5069e-01, -1.3846e-01,\n",
       "         1.3850e-01, -3.7131e-02, -1.0246e-01, -9.5607e-02, -1.3891e-01,\n",
       "        -1.5385e-01,  4.1367e-01, -2.8680e-02,  7.0649e-01, -3.9536e-01,\n",
       "        -3.5411e-01,  1.0524e-01,  5.2030e-01, -2.4093e-01, -2.0372e-01,\n",
       "        -3.3100e-03,  3.8147e-01,  1.3885e-01, -3.1067e-01, -7.1535e-02,\n",
       "         8.3211e-02,  5.5843e-02, -1.8392e-01,  1.5515e-02, -1.2002e-01,\n",
       "        -3.8284e-01, -3.2577e-01,  5.9701e-01,  7.5507e-02, -9.5155e-02,\n",
       "        -2.1469e-02, -3.3745e-03, -1.3994e-01, -8.2786e-02, -7.0325e-02,\n",
       "         3.3667e-01,  3.7155e-01, -2.4001e-01, -1.8634e-01, -8.9117e-02,\n",
       "         1.2605e-01, -1.1682e-01,  2.5224e-01, -3.7841e-01, -3.1006e-01,\n",
       "         3.5435e-01, -3.0239e-02, -3.9681e-02,  1.0836e-01, -6.8537e-02,\n",
       "        -1.4772e-01, -6.5952e-02,  3.4847e-01,  5.0632e-02,  2.6533e-01,\n",
       "         3.9819e-02,  8.1673e-03,  3.5506e-01, -4.0099e-01, -4.1559e-01,\n",
       "         1.9656e-01,  2.0023e-01,  2.2357e-01,  1.0726e-01, -8.5921e-02,\n",
       "        -8.9314e-01,  5.3972e-01, -7.6968e-02, -2.9391e-01,  6.5604e-03,\n",
       "        -4.8945e-02,  5.0456e-01, -2.1243e-01,  5.7586e-02, -1.7442e-01,\n",
       "        -4.9718e-01, -1.4076e-01,  5.1610e-02, -2.7004e-01,  3.9524e-01,\n",
       "        -9.0054e-02,  4.4996e-02,  3.8832e-02, -2.5245e-01,  2.1184e-01,\n",
       "        -3.7353e-03,  2.5960e-01,  2.7924e-01, -2.1393e-01, -2.8158e-01,\n",
       "        -3.8154e-01,  8.6457e-02, -1.3912e-01,  2.8118e-01,  3.0772e-01,\n",
       "        -3.6732e-01,  2.1600e-01,  1.2134e-01, -8.6652e-02,  1.3935e-01,\n",
       "         8.1563e-02,  7.9038e-02, -3.9129e-02,  3.0534e-01, -2.3496e-01,\n",
       "         1.9535e-01, -7.9978e-02, -2.7326e-01,  4.1704e-01, -3.5324e-01,\n",
       "         4.5768e-01,  2.9457e-01, -4.8028e-01,  1.7339e-01,  3.5572e-01,\n",
       "         9.0886e-02, -3.0870e-01,  3.2835e-01, -1.1085e-01, -2.2811e-02,\n",
       "        -1.5999e-01, -3.2181e-01,  1.0374e-01, -3.6557e-02, -2.7621e-01,\n",
       "        -1.0857e-01,  3.0676e-01,  2.7803e-01,  1.2181e-01, -7.4334e-03,\n",
       "        -7.3960e-02, -1.0816e-02,  4.5603e-02, -5.5855e-02, -3.9736e-01,\n",
       "        -2.4339e-01, -4.2789e-01,  1.4700e-01,  9.2436e-03, -1.5578e-01,\n",
       "        -3.3576e-01, -1.4405e-01, -4.9872e-02,  3.1531e-01,  5.1394e-02,\n",
       "         3.3075e-01, -5.5040e-02,  3.6283e-02, -7.4115e-03, -2.0076e-01,\n",
       "        -5.0758e-01,  1.1184e-01, -2.3087e-03, -3.3790e-02,  4.1165e-01,\n",
       "         7.0560e-02, -1.0396e-01,  2.4359e-02,  4.8223e-01, -1.6459e-01,\n",
       "         9.2739e-02,  4.2253e-01, -7.0056e-02, -2.8820e-01, -1.1958e-01,\n",
       "        -3.2629e-02,  1.3722e-01,  8.4066e-02, -1.0964e-02, -2.9931e-01,\n",
       "        -1.5446e-01, -4.9192e-02, -1.6167e-01,  7.8425e-02, -6.4872e-02,\n",
       "         2.1390e-01, -1.3385e-01, -3.3206e-01, -1.8746e-01,  6.2643e-01,\n",
       "         1.2475e-01,  1.7189e-01,  1.5605e-01,  7.5945e-02, -1.2317e-01,\n",
       "         1.1237e-01, -4.1486e-01, -2.1567e-03,  1.5077e-01, -3.6716e-01,\n",
       "         1.0347e-01, -2.1389e-01, -2.8160e-01, -4.7972e+00, -1.7731e-01,\n",
       "         1.4306e-01, -2.9214e-01,  1.5535e-01, -1.9059e-01, -3.8221e-01,\n",
       "        -7.1565e-03, -2.9852e-01,  3.8879e-01, -1.4453e-01,  6.7597e-02,\n",
       "         6.8128e-02,  5.5901e-01,  2.9505e-01, -1.2746e-01,  1.6497e-01,\n",
       "        -3.8600e-02, -9.4112e-02,  5.2695e-01, -2.9558e-02, -4.9182e-01,\n",
       "         5.2052e-03, -2.9605e-01,  1.7240e-01,  2.8997e-01, -3.2694e-01,\n",
       "         2.6263e-02, -5.1214e-01, -1.4658e-01, -1.8500e-01, -2.9857e-01,\n",
       "         2.3562e-02,  1.6413e-02,  3.8934e-02, -2.5483e-01,  1.0660e-01,\n",
       "        -9.1835e-02, -2.9702e-01, -3.7098e-01,  1.2472e-01, -3.7976e-01,\n",
       "        -8.6892e-03,  1.3519e-01,  6.1612e-01,  8.2204e-02, -2.0426e-01,\n",
       "        -2.2392e-01,  4.9231e-02,  9.7702e-03,  3.4826e-01,  7.3871e-02,\n",
       "         3.0488e-02, -1.5668e-01,  3.6424e-02, -2.1381e-02,  3.8180e-01,\n",
       "         7.6915e-02, -2.8777e-01, -1.2949e-01, -2.5136e-01, -2.1590e-01,\n",
       "        -4.7791e-01,  2.6581e-01, -1.8032e-01, -3.2965e-02, -5.7414e-01,\n",
       "        -2.7878e-03,  6.1393e-02,  1.7944e-01,  2.7696e-01,  1.9159e-01,\n",
       "        -1.4187e-01, -6.7018e-01,  3.8500e-02, -4.6382e-01, -1.4125e-01,\n",
       "         9.5890e-02, -1.0024e-01, -1.3713e-01, -3.6947e-01, -1.9667e-01,\n",
       "         2.5667e-01, -1.0380e-01,  6.5657e-02,  1.1715e-01,  1.9237e-01,\n",
       "        -1.1191e-01, -3.8497e-01, -3.5193e-01,  3.6668e-01, -3.4712e-02,\n",
       "        -1.1038e-01, -1.6835e-01,  6.3978e-01, -3.9727e-02,  2.0361e-01,\n",
       "         1.1724e-01,  3.7682e-01, -2.0653e-01, -2.5499e-02,  4.3124e-02,\n",
       "         2.4405e-01,  1.2412e-01,  1.1119e-02,  1.8058e-01, -2.6006e-01,\n",
       "         1.3848e-01,  2.6431e-01, -8.6164e-02,  4.0706e-01, -8.0588e-02,\n",
       "         3.9648e-01,  1.7328e-01, -1.1710e-01,  1.3496e-01,  9.6839e-02,\n",
       "         1.8271e-01, -1.4311e-01, -2.6064e-01,  4.3269e-02,  4.3113e-01,\n",
       "        -2.9013e-01, -1.1499e-01,  1.0715e-01, -6.1385e-02, -2.3749e-01,\n",
       "         2.7210e-01, -3.7566e-01, -2.7357e-01, -2.3370e-01, -8.0854e-02,\n",
       "        -2.9061e-02,  1.1663e-01,  1.2615e-01,  1.0172e-01, -3.6715e-01,\n",
       "        -4.7474e-01, -2.1788e-01,  1.1181e-02, -1.0683e-01,  3.2827e-01,\n",
       "         4.5134e-02, -5.1647e-02,  3.3296e-01,  3.4658e-01,  1.8483e-02,\n",
       "        -2.2592e-02,  2.3940e-03,  5.9505e-02, -7.2415e-02, -4.0504e-01,\n",
       "        -3.8456e-02,  4.4015e-04,  2.6972e-02, -6.2992e-02,  4.3642e-01,\n",
       "        -2.5241e-01, -7.3705e-02, -3.0824e-01,  9.1270e-02,  1.9775e-01,\n",
       "         6.0023e-02, -2.1757e-01, -5.9711e-03,  3.8243e-01, -6.3916e-02,\n",
       "        -1.1808e-01,  1.1088e-01,  3.1774e-01, -9.6434e-02, -1.6483e-01,\n",
       "        -2.0737e-01, -2.8779e-01,  1.3977e-01,  5.7678e-02,  3.1557e-02,\n",
       "        -4.6018e-01, -1.6886e-02,  3.0747e-01, -2.0525e-01, -5.5468e-02,\n",
       "        -5.6172e-02,  1.9608e-02,  4.3213e-01,  3.4137e-03,  1.5075e-01,\n",
       "        -2.5365e-01, -3.0568e-01,  1.4775e-01,  1.4071e-01, -9.0518e-02,\n",
       "        -1.1743e-02, -3.1429e-01, -2.6029e-01, -1.0860e-01,  3.2240e-01,\n",
       "        -2.3966e-01, -1.9166e-02,  1.3911e-01, -8.4143e-02, -3.9308e-01,\n",
       "        -1.4188e-01, -7.3805e-03,  1.2693e-01, -1.2163e-01, -1.9440e-01,\n",
       "         1.5092e-01, -2.2786e-01, -9.2650e-02,  1.8102e-01, -3.5632e-02,\n",
       "        -1.3959e-01,  2.3211e-01,  1.6544e-01, -2.0905e-02, -8.3749e-02,\n",
       "         3.3803e-03, -2.6782e-01,  1.2229e-01,  1.7117e-01, -1.7324e-01,\n",
       "        -1.9859e-01, -1.6578e-01, -9.1533e-02, -4.8661e-02,  1.3158e-01,\n",
       "        -1.5803e-01, -2.5266e-01,  1.1450e-02, -1.4972e-01, -8.9381e-01,\n",
       "         1.6877e-01, -5.0424e-02, -1.9026e-01, -1.4221e-02, -1.1838e-01,\n",
       "        -7.2530e-03,  2.6735e-01,  1.3863e-01,  8.5619e-02,  1.3407e-01,\n",
       "         4.2260e-02,  2.1871e-01,  1.7142e-02,  8.1713e-02, -7.0840e-02,\n",
       "         2.3488e-02,  6.1933e-02,  2.4537e-01, -4.1280e-01,  1.6629e-01,\n",
       "         1.5483e-02, -6.8392e-02,  4.5806e-01, -2.7437e-01, -1.8411e-01,\n",
       "         3.0742e-01, -3.6166e-01, -4.1031e-03, -2.0410e-01, -1.5627e-01,\n",
       "        -2.1422e-01,  4.1484e-01,  4.6404e-01, -6.6309e-02, -8.4792e-02,\n",
       "        -3.6151e-02,  2.3710e-01,  2.3539e-02, -3.7409e-02,  1.1331e-01,\n",
       "        -1.6827e-01,  1.8836e-01,  4.3399e-01,  9.0580e-02, -2.0840e-01,\n",
       "        -2.2318e-01,  1.5210e-01, -3.3289e-01, -1.1812e-01, -2.6456e-01,\n",
       "        -3.1711e-03, -4.8044e-02,  7.4574e-02,  6.5041e-02, -8.8143e-02,\n",
       "        -1.6002e-01,  5.0442e-02, -1.5712e-01,  4.2074e-01, -2.9929e-02,\n",
       "         5.6763e-02, -2.2300e-01, -7.4378e-02, -6.7216e-02,  4.5894e-01,\n",
       "         8.0954e-02,  1.1834e-01,  1.0311e-01, -2.7422e-01,  1.4496e-01,\n",
       "         8.2685e-02, -3.0763e-01, -9.2893e-02,  1.4703e-01,  2.2526e-01,\n",
       "        -4.3966e-01, -2.4738e-01,  6.6204e-02,  2.6302e-01, -2.0603e-01,\n",
       "         4.0153e-01,  1.6326e-01,  6.6339e-02, -1.2210e-01,  1.1436e-01,\n",
       "        -1.4669e-01, -3.8271e-02,  5.2229e-02,  3.2596e-01,  1.3290e-01,\n",
       "         3.1031e-01, -1.3849e-01,  6.3296e-02,  3.0029e-01, -3.4248e-01,\n",
       "        -2.5592e-01, -1.8574e-01,  2.1916e-01,  1.7352e-01,  1.7147e-01,\n",
       "        -3.1901e-01,  4.0991e-01,  7.0178e-03,  3.5506e-02,  3.2766e-01,\n",
       "         4.0749e-02, -1.0290e-01, -9.7245e-02,  4.5210e-01,  4.6709e-02,\n",
       "         1.7427e-01,  2.3732e-01,  5.6425e-01,  3.7752e-02,  1.4734e-01,\n",
       "         1.9016e-01,  3.4614e-01,  3.4446e-01,  2.9236e-03, -3.6015e-01,\n",
       "         1.0650e-01, -1.0365e-01,  3.4861e-02,  1.0131e-01,  6.4516e-03,\n",
       "        -1.0484e-02,  1.5699e-01,  4.9738e-01,  2.6194e-02,  3.6724e-01,\n",
       "         1.3382e-01, -2.9161e-01, -9.7005e-02,  1.2982e-01,  3.3890e-01,\n",
       "        -5.4204e-02, -1.5105e-01, -2.1579e-01,  1.1183e-01,  2.4980e-02,\n",
       "        -3.1664e-01, -3.3790e-01,  6.0472e-02,  2.0275e-01, -8.6640e-02,\n",
       "        -2.9163e-02,  9.5267e-03,  3.5362e-02,  8.1188e-02, -2.1971e-01,\n",
       "         1.0025e-01, -1.3943e-02, -1.2176e-01, -4.9726e-01,  1.1853e-01,\n",
       "        -4.6791e-03, -1.6540e-01, -4.5154e-01, -1.2512e-01, -2.2641e-01,\n",
       "         2.6596e-01,  1.4370e-01, -2.6909e-01,  2.5717e-02,  4.7222e-01,\n",
       "         1.4228e-01,  3.4424e-01, -5.5136e-02, -5.2087e-02, -7.7236e-02,\n",
       "         2.4292e-01,  1.1906e-01,  3.2669e-01,  6.1031e-02, -9.1180e-02,\n",
       "         7.7520e-02, -1.8451e-01,  1.2228e-02,  2.0667e-01,  2.5910e-01,\n",
       "        -6.1447e-01,  1.0633e-01, -1.5110e-02, -2.2575e-01, -2.3267e-01,\n",
       "        -3.2914e-01,  2.1025e-01, -1.4292e-01, -1.2407e-01, -4.0627e-01,\n",
       "         1.8016e-01,  3.5700e-01, -1.0689e-01, -6.8411e-02,  1.1073e-01,\n",
       "         1.8771e-01, -8.4637e-02, -4.9590e-03, -8.9621e-03,  2.8255e-01,\n",
       "        -9.0213e-02,  6.0549e-02,  4.1770e-02, -3.3377e-01, -2.7403e-01,\n",
       "        -2.6684e-01,  1.3645e-01, -6.2138e-02,  1.9662e-01,  2.2702e-01,\n",
       "        -1.1248e-02, -3.5499e-01,  5.7840e-01, -2.8644e-01,  2.4657e-01,\n",
       "        -1.5747e-01, -1.8962e-01, -2.2637e-02,  7.8396e-02, -2.5250e-01,\n",
       "         7.2613e-02, -1.8043e-01,  7.2186e-03, -3.5207e-01,  3.3767e-02,\n",
       "        -4.4806e-02, -8.5632e-02, -3.4900e-01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['1381852-37']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "            \n",
    "            return car_0_30, car_0_30_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "                   transcriptid, embeddings, \\\n",
    "                   [alpha, car_m1_m1, car_m2_m2, car_m30_m3, sest, sue, numest, sstdest, smedest, mcap, roa, bm, debt_asset, volatility, volume]\n",
    "        else:\n",
    "            return torch.tensor(transcriptid,dtype=torch.int64), \\\n",
    "                   torch.tensor(car_0_30,dtype=torch.float32), \\\n",
    "                   torch.tensor(car_0_30_norm,dtype=torch.float32), \\\n",
    "                   torch.tensor([similarity, sentiment],dtype=torch.float32),\\\n",
    "                   torch.tensor([alpha, car_m1_m1, car_m2_m2, car_m30_m3, sest, sue, numest, sstdest, smedest, mcap, roa, bm, debt_asset, volatility, volume], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time embedding = torch.load('data/Embeddings/preembeddings_finBERT_without_special_tokens.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.86 s\n"
     ]
    }
   ],
   "source": [
    "%time d = {k: v['embedding'] for k, v in embedding.items() if 5<=v['seq_len']<=384}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then define DataModule\n",
    "class CCDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, yqtr, preembedding_type, targets_name,\n",
    "                 batch_size, val_batch_size, test_batch_size, text_in_dataset, roll_type):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.yqtr = yqtr\n",
    "        self.preembedding_type = preembedding_type\n",
    "        self.targets_name = targets_name\n",
    "        self.batch_size = batch_size\n",
    "        self.val_batch_size = val_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "        self.text_in_dataset = text_in_dataset\n",
    "        self.roll_type = roll_type\n",
    "        \n",
    "    # Dataset\n",
    "    def setup(self):\n",
    "        # read the preembedding, targests, and split_df\n",
    "        global preembeddings, targets_df, split_df\n",
    "        \n",
    "        load_preembeddings(self.preembedding_type)\n",
    "        load_targets(self.targets_name, force=True)\n",
    "        load_split_df(self.roll_type)\n",
    "        \n",
    "        self.preembeddings = preembeddings\n",
    "        self.targets_df = targets_df\n",
    "        self.split_df = split_df\n",
    "        \n",
    "        self.train_dataset = CCDataset(self.yqtr, split_type='train', text_in_dataset=self.text_in_dataset,\n",
    "                                       roll_type=self.roll_type,\n",
    "                                       preembeddings=self.preembeddings,\n",
    "                                       targets_df=self.targets_df, split_df=self.split_df)\n",
    "        print(f'N train = {len(self.train_dataset)}')\n",
    "        \n",
    "        self.val_dataset = CCDataset(self.yqtr, split_type='val', text_in_dataset=self.text_in_dataset,\n",
    "                                     roll_type=self.roll_type,\n",
    "                                     preembeddings=self.preembeddings,\n",
    "                                     targets_df=self.targets_df, split_df=self.split_df)\n",
    "        print(f'N val = {len(self.val_dataset)}')\n",
    "        print(f'N train+val = {len(self.train_dataset)+len(self.val_dataset)}')\n",
    "\n",
    "        self.test_dataset = CCDataset(self.yqtr, split_type='test', text_in_dataset=self.text_in_dataset, \n",
    "                                      roll_type=self.roll_type,\n",
    "                                      preembeddings=self.preembeddings,\n",
    "                                      targets_df=self.targets_df, split_df=self.split_df)\n",
    "        print(f'N test = {len(self.test_dataset)}')\n",
    "\n",
    "    # DataLoader\n",
    "    def train_dataloader(self):\n",
    "        # Caution:\n",
    "        # - If you enable `BatchNorm`, then must set `drop_last=True`.\n",
    "\n",
    "        collate_fn = self.collate_fn if self.text_in_dataset else None\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, \n",
    "                          shuffle=True, drop_last=False, num_workers=0, pin_memory=True, collate_fn=collate_fn)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        # Caution: \n",
    "        # - To improve the validation speed, I'll set val_batch_size to 4. \n",
    "        # - Must set `drop_last=True`, otherwise the `val_loss` tensors for different batches won't match and hence give you error.\n",
    "        # - Not to set `val_batch_size` too large (e.g., 16), otherwise you'll lose precious validation data points\n",
    "        \n",
    "        collate_fn = self.collate_fn if self.text_in_dataset else None\n",
    "        return DataLoader(self.val_dataset, batch_size=self.val_batch_size, num_workers=0, \n",
    "                          pin_memory=True, collate_fn=collate_fn, drop_last=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        collate_fn = self.collate_fn if self.text_in_dataset else None\n",
    "        return DataLoader(self.test_dataset, batch_size=4, num_workers=0, \n",
    "                          pin_memory=True, collate_fn=collate_fn, drop_last=False)\n",
    "    \n",
    "    def collate_fn(self, data):\n",
    "        '''create mini-batch\n",
    "\n",
    "        Retures:\n",
    "            embeddings: tensor, (N, S, E)\n",
    "            mask: tensor, (N, S)\n",
    "            sue,car,selead,sest: tensor, (N,)\n",
    "        '''\n",
    "        \n",
    "        # embeddings: (N, S, E)\n",
    "        car_0_30, car_0_30_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, \\\n",
    "        fin_ratios = zip(*data)\n",
    "        \n",
    "        # pad sequence\n",
    "        # the number of `padding_value` is irrelevant, since we'll \n",
    "        # apply a mask in the Transformer encoder, which will \n",
    "        # eliminate the padded positions.\n",
    "        valid_seq_len = [emb.shape[-2] for emb in embeddings]\n",
    "        embeddings = pad_sequence(embeddings, batch_first=True, padding_value=0) # (N, T, E)\n",
    "\n",
    "        # mask: (N, T)\n",
    "        mask = torch.ones((embeddings.shape[0], embeddings.shape[1]))\n",
    "        for i, length in enumerate(valid_seq_len):\n",
    "            mask[i, :length] = 0\n",
    "        mask = mask == 1\n",
    "        \n",
    "        return torch.tensor(car_0_30, dtype=torch.float32), torch.tensor(car_0_30_norm, dtype=torch.float32), \\\n",
    "               torch.tensor(inflow, dtype=torch.float32), torch.tensor(inflow_norm, dtype=torch.float32), \\\n",
    "               torch.tensor(revision, dtype=torch.float32), torch.tensor(revision_norm, dtype=torch.float32), \\\n",
    "               torch.tensor(transcriptid, dtype=torch.float32), embeddings.float(), mask, \\\n",
    "               torch.tensor(fin_ratios, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: position encoder\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-np.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # pe: (max_len, 1, d_model)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :] # (S, N, E)\n",
    "        return self.dropout(x)\n",
    "    \n",
    "    \n",
    "# Model: FeatureMixer\n",
    "class FeatureMixerLayer(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        '''\n",
    "        d_model: the dimension in the FC layers. For text, usually be 1024; for fin-ratios, should be 15\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(d_model)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x.size = [bsz, d_model]\n",
    "        '''\n",
    "        x = self.dropout(self.batch_norm(x))\n",
    "        y = F.relu(self.fc(x))\n",
    "        \n",
    "        return y\n",
    "    \n",
    "class FrMixerLayer(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        '''\n",
    "        d_model: the dimension in the FC layers. For text, usually be 1024; for fin-ratios, should be 15\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(d_model)\n",
    "        self.dropout = nn.Dropout()\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        x.size = [bsz, d_model]\n",
    "        '''\n",
    "        x = self.dropout(self.batch_norm(x))\n",
    "        y = F.relu(self.fc(x))\n",
    "        \n",
    "        return y\n",
    "\n",
    "class FeatureMixer(nn.Module):\n",
    "    def __init__(self, featuremixer_layer, n_layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers = nn.ModuleList([copy.deepcopy(featuremixer_layer) for i in range(n_layers)])\n",
    "        self.n_layers = n_layers\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = x\n",
    "        for layer in self.layers:\n",
    "            output = layer(output)\n",
    "            \n",
    "        return output\n",
    "\n",
    "        \n",
    "# Model: Base\n",
    "class CC(pl.LightningModule):\n",
    "    '''Mainly define the `*_step_end` methods\n",
    "    '''\n",
    "    def __init__(self, learning_rate):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "    # forward\n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    # loss\n",
    "    def mse_loss(self, y, t):\n",
    "        return F.mse_loss(y, t)\n",
    "        \n",
    "    # def training_step_end\n",
    "    def training_step_end(self, outputs):\n",
    "        y = outputs['y_car']\n",
    "        t = outputs['t_car']\n",
    "        loss = self.mse_loss(y, t)\n",
    "        \n",
    "        return {'loss':loss}\n",
    "    \n",
    "    # def validation_step_end\n",
    "    def validation_step_end(self, outputs):\n",
    "        y_car = outputs['y_car']\n",
    "        t_car = outputs['t_car']\n",
    "        \n",
    "        return {'y_car':y_car, 't_car':t_car}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        '''\n",
    "        outputs: a list. len(outputs) == num_steps.\n",
    "            e.g., outputs = [{'val_loss': 3}, {'val_loss': 4}]\n",
    "        '''\n",
    "        y_car = torch.cat([x['y_car'] for x in outputs])\n",
    "        t_car = torch.cat([x['t_car'] for x in outputs])\n",
    "        \n",
    "        rmse = torch.sqrt(self.mse_loss(y_car, t_car))\n",
    "        self.log('val_rmse', rmse, on_step=False)\n",
    "        \n",
    "    # test step\n",
    "    def test_step_end(self, outputs):\n",
    "        transcriptid = outputs['transcriptid']\n",
    "        \n",
    "        y_car = outputs['y_car']\n",
    "        t_car = outputs['t_car']\n",
    "        \n",
    "        return {'y_car':y_car, 't_car':t_car, 'transcriptid':transcriptid}\n",
    "    \n",
    "    def test_epoch_end(self, outputs):\n",
    "        \n",
    "        transcriptid = torch.cat([x['transcriptid'] for x in outputs])\n",
    "        y_car = torch.cat([x['y_car'] for x in outputs])\n",
    "        t_car = torch.cat([x['t_car'] for x in outputs])\n",
    "        \n",
    "        rmse = torch.sqrt(self.mse_loss(y_car, t_car))\n",
    "        self.log('test_rmse', rmse, on_step=False)\n",
    "        \n",
    "        if 'test_loss_car' in outputs[0]:\n",
    "            rmse_car = torch.sqrt(torch.stack([x['test_loss_car'] for x in outputs]).mean())\n",
    "            self.log('test_rmse_car', rmse_car, on_step=False)\n",
    "            \n",
    "        if 'test_loss_inflow' in outputs[0]:\n",
    "            rmse_inflow = torch.sqrt(torch.stack([x['test_loss_inflow'] for x in outputs]).mean())\n",
    "            self.log('test_rmse_inflow', rmse_inflow, on_step=False)\n",
    "\n",
    "        if 'test_loss_revision' in outputs[0]:\n",
    "            rmse_revision = torch.sqrt(torch.stack([x['test_loss_revision'] for x in outputs]).mean())\n",
    "            self.log('test_rmse_revision', rmse_revision, on_step=False)\n",
    "        \n",
    "        # save & log `y_car`\n",
    "        y_car_filename = f'{DATA_DIR}/y_car.feather'\n",
    "        \n",
    "        df = pd.DataFrame({'transcriptid':transcriptid.to('cpu'), 'y_car':y_car.to('cpu')})\n",
    "        feather.write_feather(df, y_car_filename)\n",
    "            \n",
    "        self.logger.experiment.log_asset(y_car_filename)\n",
    "            \n",
    "    # optimizer\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## def train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop one\n",
    "def train_one(Model, yqtr, data_hparams, model_hparams, trainer_hparams):\n",
    "\n",
    "    # ----------------------\n",
    "    # `hparams` sanity check\n",
    "    # ----------------------\n",
    "    \n",
    "    # check: batch_size//len(gpus)==0\n",
    "    assert data_hparams['batch_size']%len(trainer_hparams['gpus'])==0, \\\n",
    "        f\"`batch_size` must be divisible by `len(gpus)`. Currently batch_size={model_hparams['batch_size']}, gpus={trainer_hparams['gpus']}\"\n",
    "    \n",
    "    # check: val_batch_size//len(gpus)==0\n",
    "    assert data_hparams['val_batch_size']%len(trainer_hparams['gpus'])==0, \\\n",
    "        f\"`val_batch_size` must be divisible by `len(gpus)`. Currently batch_size={model_hparams['val_batch_size']}, gpus={trainer_hparams['gpus']}\"\n",
    "    \n",
    "    # check: val_batch_size//len(gpus)==0\n",
    "    assert data_hparams['test_batch_size']%len(trainer_hparams['gpus'])==0, \\\n",
    "        f\"`test_batch_size` must be divisible by `len(gpus)`. Currently batch_size={model_hparams['test_batch_size']}, gpus={trainer_hparams['gpus']}\"\n",
    "    \n",
    "        \n",
    "    # init model\n",
    "    model = Model(**model_hparams)\n",
    "\n",
    "    # checkpoint\n",
    "    ckpt_prefix = f\"{trainer_hparams['note']}_{data_hparams['yqtr']}_\".replace('*', '')\n",
    "    \n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        verbose=True,\n",
    "        mode='min',\n",
    "        monitor='val_rmse',\n",
    "        filepath=CHECKPOINT_DIR,\n",
    "        prefix=ckpt_prefix,\n",
    "        save_top_k=trainer_hparams['save_top_k'],\n",
    "        period=trainer_hparams['checkpoint_period'])\n",
    "\n",
    "    # logger\n",
    "    logger = pl.loggers.CometLogger(\n",
    "        api_key=COMET_API_KEY,\n",
    "        save_dir='/data/logs',\n",
    "        project_name='earnings-call',\n",
    "        experiment_name=data_hparams['yqtr'],\n",
    "        workspace='amiao',\n",
    "        display_summary_level=0)\n",
    "\n",
    "    # early stop\n",
    "    early_stop_callback = pl.callbacks.EarlyStopping(\n",
    "        monitor='val_rmse',\n",
    "        min_delta=0,\n",
    "        patience=trainer_hparams['early_stop_patience'],\n",
    "        verbose=True,\n",
    "        mode='min')\n",
    "\n",
    "    # trainer\n",
    "    trainer = pl.Trainer(gpus=trainer_hparams['gpus'], \n",
    "                         precision=trainer_hparams['precision'],\n",
    "                         checkpoint_callback=checkpoint_callback, \n",
    "                         callbacks=[early_stop_callback],\n",
    "                         overfit_batches=trainer_hparams['overfit_batches'], \n",
    "                         log_every_n_steps=trainer_hparams['log_every_n_steps'],\n",
    "                         val_check_interval=trainer_hparams['val_check_interval'], \n",
    "                         progress_bar_refresh_rate=5, \n",
    "                         distributed_backend='dp', \n",
    "                         accumulate_grad_batches=trainer_hparams['accumulate_grad_batches'],\n",
    "                         min_epochs=trainer_hparams['min_epochs'],\n",
    "                         max_epochs=trainer_hparams['max_epochs'], \n",
    "                         max_steps=trainer_hparams['max_steps'], \n",
    "                         logger=logger)\n",
    "\n",
    "    # add n_model_params\n",
    "    trainer_hparams['n_model_params'] = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    # upload hparams\n",
    "    logger.experiment.log_parameters(data_hparams)\n",
    "    logger.experiment.log_parameters(model_hparams)\n",
    "    logger.experiment.log_parameters(trainer_hparams)\n",
    "    \n",
    "    # upload ols_rmse (for reference)\n",
    "    log_ols_rmse(logger, data_hparams['yqtr'])\n",
    "    \n",
    "    # upload test_start\n",
    "    log_test_start(logger, data_hparams['roll_type'], data_hparams['yqtr'])\n",
    "    \n",
    "    # If run on ASU, upload code explicitly\n",
    "    if trainer_hparams['machine'] == 'ASU':\n",
    "        codefile = [name for name in os.listdir('.') if name.endswith('.py')]\n",
    "        assert len(codefile)==1, f'There must be only one `.py` file in the current directory! {len(codefile)} files detected: {codefile}'\n",
    "        logger.experiment.log_asset(codefile[0])\n",
    "    \n",
    "    \n",
    "    # refresh GPU memory\n",
    "    refresh_cuda_memory()\n",
    "\n",
    "    # fit and test\n",
    "    try:\n",
    "        # create datamodule\n",
    "        datamodule = CCDataModule(**data_hparams)\n",
    "        datamodule.setup()\n",
    "\n",
    "        # train the model\n",
    "        trainer.fit(model, datamodule)\n",
    "\n",
    "        # test on the best model\n",
    "        trainer.test(ckpt_path='best')\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        raise e\n",
    "    finally:\n",
    "        del model, trainer\n",
    "        refresh_cuda_memory()\n",
    "        logger.finalize('finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP\n",
    "class CCMLP(CC):\n",
    "    def __init__(self, learning_rate, dropout, model_type='MLP'):\n",
    "        super().__init__(learning_rate)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # dropout layers\n",
    "        # self.dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        # self.dropout_2 = nn.Dropout(self.hparams.dropout)\n",
    "        \n",
    "        # fc layers\n",
    "        self.fc_1 = nn.Linear(17, 32)\n",
    "        self.fc_2 = nn.Linear(32, 1)\n",
    "        #self.fc_3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    def shared_step(self, batch):\n",
    "        transcriptid, car, car_norm, manual_txt, fin_ratios = batch\n",
    "        x = torch.cat([fin_ratios, manual_txt], dim=-1) # (N, 2+15)\n",
    "\n",
    "        x_car = F.relu(self.fc_1(x))\n",
    "        y_car = self.fc_2(x_car) # (N, 1)    \n",
    "        \n",
    "        t_car = car_norm\n",
    "        \n",
    "        return transcriptid.squeeze(), y_car.squeeze(), t_car.squeeze() \n",
    "        \n",
    "    # train step\n",
    "    def training_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'y_car': y_car, 't_car': t_car}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'y_car': y_car, 't_car': t_car}\n",
    "        \n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'transcriptid':transcriptid, 'y_car':y_car, 't_car': t_car}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choose Model\n",
    "Model = CCMLP\n",
    "\n",
    "# data hparams\n",
    "data_hparams = {\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded', # key!\n",
    "    'targets_name': 'f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_sentiment_text_norm_wsrz', # key!\n",
    "\n",
    "    'batch_size': 128,\n",
    "    'val_batch_size':64,\n",
    "    'test_batch_size':32,\n",
    "    \n",
    "    'text_in_dataset': False,\n",
    "    'roll_type': '6y', # key!\n",
    "}\n",
    "\n",
    "# model hparams\n",
    "model_hparams = {\n",
    "    'learning_rate': 1e-3,\n",
    "    'dropout': 0.5,\n",
    "}\n",
    "\n",
    "# train hparams\n",
    "trainer_hparams = {\n",
    "    # random seed\n",
    "    'seed': 42,    # key\n",
    "    \n",
    "    # gpus\n",
    "    'gpus': [0,1], # key\n",
    "\n",
    "    # checkpoint & log\n",
    "    \n",
    "    # last: MLP-22\n",
    "    'machine': 'yu-workstation', # key!\n",
    "    'note': f\"MLP-23,(car~fr+mtxt),hidden=32,hiddenLayer=1,fc_dropout=no,NormCAR=yes,bsz={data_hparams['batch_size']},log(mcap)=yes,lr={model_hparams['learning_rate']:.1e}\", # key!\n",
    "    'log_every_n_steps': 10,\n",
    "    'save_top_k': 1,\n",
    "    'val_check_interval': 1.0,\n",
    "\n",
    "    # data size\n",
    "    'precision': 32, # key!\n",
    "    'overfit_batches': 0.0,\n",
    "    'min_epochs': 10, # default: 10\n",
    "    'max_epochs': 20, \n",
    "    'max_steps': None,\n",
    "    'accumulate_grad_batches': 1,\n",
    "\n",
    "    # Caution:\n",
    "    # The check of patience depends on **how often you compute your val_loss** (`val_check_interval`). \n",
    "    # Say you check val every N baches, then `early_stop_callback` will compare to your latest N **baches**.\n",
    "    # If you compute val_loss every N **epoches**, then `early_stop_callback` will compare to the latest N **epochs**.\n",
    "    'early_stop_patience': 3,\n",
    "\n",
    "    # Caution:\n",
    "    # In pervious versions, if you check validatoin multiple times within a epoch,\n",
    "    # you have to set `check_point_period=0`. However, starting from 1.0.7, even if \n",
    "    # you check validation multiples times within an epoch, you still need to set\n",
    "    # `checkpoint_period=1`.\n",
    "    'checkpoint_period': 1}\n",
    "\n",
    "# delete all existing .ckpt files\n",
    "refresh_ckpt()\n",
    "\n",
    "# load split_df\n",
    "load_split_df(data_hparams['roll_type'])\n",
    "    \n",
    "# loop over windows\n",
    "np.random.seed(trainer_hparams['seed'])\n",
    "torch.manual_seed(trainer_hparams['seed'])\n",
    "\n",
    "for yqtr in split_df.yqtr:\n",
    "    \n",
    "    # update current period\n",
    "    data_hparams.update({'yqtr': yqtr})\n",
    "    \n",
    "    # train on select periods\n",
    "    # if data_hparams['yqtr']=='2014-q1':\n",
    "    train_one(Model, yqtr, data_hparams, model_hparams, trainer_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true toc-hr-collapsed=true toc-nb-collapsed=true",
    "toc-hr-collapsed": true,
    "toc-nb-collapsed": true
   },
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CCGRU\n",
    "class CCGRU(CC):\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__(hparams)\n",
    "        \n",
    "        self.hparams = hparams\n",
    "        \n",
    "        # set model types\n",
    "        self.task_type = 'single'\n",
    "        self.feature_type = 'univariate'\n",
    "        self.model_type = 'gru'\n",
    "        self.attn_type = 'dotprod'\n",
    "        self.text_in_dataset = True if self.feature_type!='fin-ratio' else False \n",
    "        \n",
    "        # layers\n",
    "        self.gru_expert = nn.GRU(hparams.d_model, hparams.rnn_hidden_size, num_layers=4, batch_first=True,\n",
    "                                 dropout=0.1, bidirectional=True)\n",
    "        self.dropout_expert = nn.Dropout(hparams.dropout)\n",
    "        self.linear_car = nn.Linear(hparams.rnn_hidden_size*2, 1)\n",
    "\n",
    "    # forward\n",
    "    def forward(self, inp, valid_seq_len):\n",
    "        # Note: inp is [N, S, E] and **already** been packed\n",
    "        self.gru_expert.flatten_parameters()\n",
    "        \n",
    "        # if S is longer than `max_seq_len`, cut\n",
    "        inp = inp[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        valid_seq_len[valid_seq_len>self.hparams.max_seq_len] = self.hparams.max_seq_len # (N,)\n",
    "        \n",
    "        # RNN layers\n",
    "        inp = pack_padded_sequence(inp, valid_seq_len, batch_first=True, enforce_sorted=False)\n",
    "        x_expert = pad_packed_sequence(self.gru_expert(inp)[0], batch_first=True)[0][:,-1,:] # (N, E)\n",
    "        \n",
    "        # final FC layers\n",
    "        y_car = self.linear_car(x_expert) # (N, E)\n",
    "        \n",
    "        return y_car\n",
    "    \n",
    "    # train step\n",
    "    def training_step(self, batch, idx):\n",
    "        \n",
    "        car, transcriptid, embeddings, mask, alpha, car_m1_m1, car_m2_m2, car_m30_m3,\\\n",
    "        sest, sue, numest, sstdest, smedest, \\\n",
    "        mcap, roa, bm, debt_asset, volatility = batch\n",
    "        \n",
    "        # get valid seq_len\n",
    "        valid_seq_len = torch.sum(~mask, -1)\n",
    "        \n",
    "        # forward\n",
    "        y_car = self.forward(embeddings, valid_seq_len) # (N, 1)\n",
    "\n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car.unsqueeze(-1)) # ()\n",
    "        \n",
    "        # logging\n",
    "        return {'loss': loss_car, 'log': {'trainer_loss': loss_car}}\n",
    "            \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        \n",
    "        car, transcriptid, embeddings, mask, alpha, car_m1_m1, car_m2_m2, car_m30_m3,\\\n",
    "        sest, sue, numest, sstdest, smedest, \\\n",
    "        mcap, roa, bm, debt_asset, volatility = batch\n",
    "        \n",
    "        # get valid seq_len\n",
    "        valid_seq_len = torch.sum(~mask, -1)\n",
    "        \n",
    "        # forward\n",
    "        y_car = self.forward(embeddings, valid_seq_len) # (N, 1)\n",
    "\n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car.unsqueeze(-1)) # ()\n",
    "        \n",
    "        # logging\n",
    "        return {'val_loss': loss_car}        \n",
    "    \n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        \n",
    "        car, transcriptid, embeddings, mask, alpha, car_m1_m1, car_m2_m2, car_m30_m3,\\\n",
    "        sest, sue, numest, sstdest, smedest, \\\n",
    "        mcap, roa, bm, debt_asset, volatility = batch\n",
    "        \n",
    "        # get valid seq_len\n",
    "        valid_seq_len = torch.sum(~mask, -1)\n",
    "        \n",
    "        # forward\n",
    "        y_car = self.forward(embeddings, valid_seq_len) # (N, 1)\n",
    "\n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car.unsqueeze(-1)) # ()\n",
    "        \n",
    "        # logging\n",
    "        return {'test_loss': loss_car}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true"
   },
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over 24 windows\n",
    "load_split_df()\n",
    "load_targets()\n",
    "\n",
    "# model hparams\n",
    "model_hparams = {\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded', # key\n",
    "    'batch_size': 8, # key\n",
    "    'val_batch_size': 1, # key\n",
    "    \n",
    "    'max_seq_len': 1024, \n",
    "    'learning_rate': 3e-4,\n",
    "    'task_weight': 1,\n",
    "\n",
    "    'n_layers_encoder': 6,\n",
    "    'n_head_encoder': 8, # optional\n",
    "    'd_model': 1024,\n",
    "    'rnn_hidden_size': 64,\n",
    "    'final_tdim': 1024, # optional\n",
    "    'dff': 2048,\n",
    "    'attn_dropout': 0.1,\n",
    "    'dropout': 0.5,\n",
    "    'n_head_decoder': 8} # optional\n",
    "\n",
    "# train hparams\n",
    "trainer_hparams = {\n",
    "    # checkpoint & log\n",
    "    'note': 'temp',\n",
    "    'checkpoint_path': 'D:\\Checkpoints\\earnings-call',\n",
    "    'row_log_interval': 1,\n",
    "    'save_top_k': 1,\n",
    "    'val_check_interval': 0.25,\n",
    "\n",
    "    # data size\n",
    "    'overfit_pct': 1,\n",
    "    'min_epochs': 0,\n",
    "    'max_epochs': 1,\n",
    "    'max_steps': None,\n",
    "    'accumulate_grad_batches': 1,\n",
    "\n",
    "    # Caution:\n",
    "    # The check of patience depends on **how often you compute your val_loss** (`val_check_interval`). \n",
    "    # Say you check val every N baches, then `early_stop_callback` will compare to your latest N **baches**.\n",
    "    # If you compute val_loss every N **epoches**, then `early_stop_callback` will compare to the latest N **epochs**.\n",
    "    'early_stop_patience': 5,\n",
    "\n",
    "    # Caution:\n",
    "    # If set to 1, then save ckpt every 1 epoch\n",
    "    # If set to 0, then save ckpt on every val!!! (if val improves)\n",
    "    'checkpoint_period': 0}\n",
    "\n",
    "# delete all existing .ckpt files\n",
    "refresh_ckpt(trainer_hparams['checkpoint_path'])\n",
    "    \n",
    "# loop over 24!\n",
    "for window_i in range(len(split_df)):\n",
    "    # load preembeddings\n",
    "    load_preembeddings(model_hparams['preembedding_type'])\n",
    "\n",
    "    # train one window\n",
    "    trainer_one(CCGRU, window_i, model_hparams, trainer_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CCTransformerSTLTxt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car ~ txt\n",
    "class CCTransformerSTLTxt(CC):\n",
    "    def __init__(self, d_model, learning_rate, attn_dropout, n_head_encoder, n_layers_encoder, dff, max_seq_len, model_type='STL', dropout=0.5):\n",
    "        '''\n",
    "        d_model: dimension of embedding. (default=1024)\n",
    "        dff: fully-connected layer inside the transformer block. (default=2048)\n",
    "        '''\n",
    "        # `self.hparams` will be created by super().__init__\n",
    "        super().__init__(learning_rate)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # positional encoding\n",
    "        self.encoder_pos = PositionalEncoding(self.hparams.d_model, self.hparams.attn_dropout)\n",
    "        \n",
    "        # encoder layers for input, expert, nonexpert\n",
    "        encoder_layers_expert = nn.TransformerEncoderLayer(self.hparams.d_model, self.hparams.n_head_encoder, self.hparams.dff, self.hparams.attn_dropout)\n",
    "        \n",
    "        # atten layers for CAR\n",
    "        # self.attn_layers_car = nn.Linear(self.hparams.d_model, 1)\n",
    "        # self.attn_dropout_1 = nn.Dropout(self.hparams.attn_dropout)\n",
    "        \n",
    "        # Build Encoder and Decoder\n",
    "        self.encoder_expert = nn.TransformerEncoder(encoder_layers_expert, self.hparams.n_layers_encoder)\n",
    "        \n",
    "        # linear layer to produce final result\n",
    "        self.fc_1 = nn.Linear(self.hparams.d_model, 32)\n",
    "        self.fc_2 = nn.Linear(32, 1)\n",
    "        self.dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        \n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    # forward\n",
    "    def shared_step(self, batch):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, src_key_padding_mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # if S is longer than max_seq_len, cut\n",
    "        embeddings = embeddings[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        src_key_padding_mask = src_key_padding_mask[:,:self.hparams.max_seq_len] # (N, S)\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1) # (S, N, E)\n",
    "        \n",
    "        # positional encoding\n",
    "        x = self.encoder_pos(embeddings) # (S, N, E)\n",
    "        \n",
    "        # encode\n",
    "        x_expert = self.encoder_expert(x, src_key_padding_mask=src_key_padding_mask).transpose(0,1) # (N, S, E)\n",
    "        \n",
    "        # decode with attn\n",
    "        # x_attn = self.attn_dropout_1(F.softmax(self.attn_layers_car(x_expert), dim=1)) # (N, S, 1)\n",
    "        # x_expert = torch.bmm(x_expert.transpose(-1,-2), x_attn).squeeze(-1) # (N, E)\n",
    "        \n",
    "        # decode with avgpool\n",
    "        x_expert = x_expert.mean(1) # (N, E)\n",
    "        \n",
    "        # decode with maxpool\n",
    "        # x_expert_maxpool = x_expert.max(1)[0] # (N, E)\n",
    "        \n",
    "        # concat\n",
    "        # x_expert = torch.cat([x_expert_avgpool, x_expert_maxpool], dim=-1) # (N, 2E)\n",
    "\n",
    "        # final FC\n",
    "        y_car = F.relu(self.fc_1(x_expert)) # (N, 1)\n",
    "        y_car = self.fc_2(y_car)\n",
    "        \n",
    "        t_car = car_norm\n",
    "        \n",
    "        # final output\n",
    "        return transcriptid.squeeze(), y_car.squeeze(), t_car.squeeze() \n",
    "    \n",
    "    # traning step\n",
    "    def training_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'y_car': y_car, 't_car': t_car}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'y_car': y_car, 't_car': t_car}\n",
    "\n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'transcriptid':transcriptid, 'y_car':y_car, 't_car': t_car}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `CCTransformerSTLTxtFr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# car ~ txt + fr\n",
    "class CCTransformerSTLTxtFr(CC):\n",
    "    def __init__(self, d_model, learning_rate, attn_dropout, n_head_encoder, \n",
    "                 n_layers_encoder, dff, max_seq_len, model_type='STL', n_finratios=15, dropout=0.5):\n",
    "        '''\n",
    "        d_model: dimension of embedding. (default=1024)\n",
    "        dff: fully-connected layer inside the transformer block. (default=2048)\n",
    "        '''\n",
    "        # `self.hparams` will be created by super().__init__\n",
    "        super().__init__(learning_rate)\n",
    "        \n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        # positional encoding\n",
    "        self.encoder_pos = PositionalEncoding(self.hparams.d_model, self.hparams.attn_dropout)\n",
    "        \n",
    "        # encoder layers for input, expert, nonexpert\n",
    "        encoder_layers_expert = nn.TransformerEncoderLayer(self.hparams.d_model, self.hparams.n_head_encoder, self.hparams.dff, self.hparams.attn_dropout)\n",
    "        \n",
    "        # atten layers \n",
    "        # self.attn_layers_car = nn.Linear(self.hparams.d_model, 1)\n",
    "        # self.attn_dropout_1 = nn.Dropout(self.hparams.attn_dropout)\n",
    "        \n",
    "        # Build Encoder and Decoder\n",
    "        self.encoder_expert = nn.TransformerEncoder(encoder_layers_expert, self.hparams.n_layers_encoder)\n",
    "        \n",
    "        # linear layer to produce final result\n",
    "        # txt_mixer_layer = TxtMixerLayer(self.hparams.d_model)\n",
    "        # self.txt_mixer = FeatureMixer(txt_mixer_layer, self.hparams.n_layers_txtmixer)\n",
    "        \n",
    "        # fr_mixer_layers = FrMixerLayer(self.n_covariate)\n",
    "        # self.fr_mixer = FeatureMixer(fr_mixer_layers, self.hparams.n_layers_frmixer)\n",
    "        \n",
    "        # final prediction layer\n",
    "        # final_fc_mixer_layer = FeatureMixerLayer(self.hparams.d_model+self.n_covariate)\n",
    "        # self.final_fc_mixer_layer = FeatureMixer(final_fc_mixer_layer, self.hparams.n_layers_finalfc)\n",
    "        # self.fc_batchnorm = nn.BatchNorm1d(self.hparams.d_model+self.n_covariate)\n",
    "        self.final_fc = nn.Linear(self.hparams.d_model+self.hparams.n_finratios, 1)\n",
    "        \n",
    "        # self.txt_fc_1 = nn.Linear(self.hparams.d_model, self.hparams.final_tdim)\n",
    "        # self.txt_fc_2 = nn.Linear(self.hparams.d_model, self.hparams.final_tdim)\n",
    "        # self.fc_1 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        # self.fc_2 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        # self.fc_3 = nn.Linear(self.hparams.final_tdim+self.n_covariate, 1)\n",
    "        \n",
    "        # dropout for final fc layers\n",
    "        # self.txt_dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        # self.fc_dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        # self.fc_dropout_2 = nn.Dropout(self.hparams.dropout)\n",
    "        # self.fc_dropout_3 = nn.Dropout(self.hparams.dropout) \n",
    "        \n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    def shared_step(self, batch):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, src_key_padding_mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # if S is longer than max_seq_len, cut\n",
    "        embeddings = embeddings[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        src_key_padding_mask = src_key_padding_mask[:,:self.hparams.max_seq_len] # (N, S)\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1) # (S, N, E)\n",
    "        \n",
    "        # positional encoding\n",
    "        x = self.encoder_pos(embeddings) # (S, N, E)\n",
    "        \n",
    "        # encode\n",
    "        x_expert = self.encoder_expert(x, src_key_padding_mask=src_key_padding_mask).transpose(0,1) # (N, S, E)\n",
    "        \n",
    "        # decode with attn\n",
    "        # x_attn = self.attn_dropout_1(F.softmax(self.attn_layers_car(x_expert), dim=1)) # (N, S, 1)\n",
    "        # x_expert = torch.bmm(x_expert.transpose(-1,-2), x_attn).squeeze(-1) # (N, E)\n",
    "        \n",
    "        x_expert = x_expert.max(1)[0] # (N, E)\n",
    "        \n",
    "        \n",
    "        # project text embedding to a lower dimension\n",
    "        # x_expert = self.txt_dropout_1(F.relu(self.txt_fc_1(x_expert)))\n",
    "        # x_expert = F.relu(self.txt_fc_2(x_expert))\n",
    "        \n",
    "        # x_expert = self.txt_mixer(x_expert)\n",
    "        \n",
    "        # Mix fin_ratios\n",
    "        # fin_ratios = self.batch_norm(fin_ratios)\n",
    "        # x_fr = self.fr_mixer(fin_ratios)\n",
    "        \n",
    "        # concate `x_final` with `fin_ratios`\n",
    "        x_final = torch.cat([x_expert, fin_ratios], dim=-1) # (N, E+X) where X is the number of covariate (n_finratios)\n",
    "        \n",
    "        # final FC\n",
    "        # x_final = self.fc_dropout_1(F.relu(self.fc_1(x_expert))) # (N, E+X)\n",
    "        # x_car = self.final_fc_mixer_layer(x_final) # (N, E+X)\n",
    "        y_car = self.final_fc(x_final)\n",
    "        \n",
    "        t_car = car_norm\n",
    "        \n",
    "        # final output\n",
    "        return transcriptid.squeeze(), y_car.squeeze(), t_car.squeeze() \n",
    "    \n",
    "    # traning step\n",
    "    def training_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'y_car': y_car, 't_car': t_car}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'y_car': y_car, 't_car': t_car}\n",
    "\n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        transcriptid, y_car, t_car = self.shared_step(batch)\n",
    "        return {'transcriptid':transcriptid, 'y_car':y_car, 't_car': t_car}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a444189610>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\utilities\\distributed.py:45: UserWarning: Checkpoint directory d:/checkpoints/earnings-call exists and is not empty. With save_top_k=1, all files in this directory will be deleted when a checkpoint is saved!\n",
      "  warnings.warn(*args, **kwargs)\n",
      "CometLogger will be initialized in online mode\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/amiao/earnings-call/b5c3769d279740e8a995aa0d907b271e\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preembeddings: all_sbert_roberta_nlistsb_encoded...@03:57:36\n",
      "Loading preembeddings finished. @03:58:13\n",
      "Loading targets...@03:58:13\n",
      "Loading finished. @03:58:16\n",
      "Current window: 2012-q4 (3y) \n",
      "(train: 2010-01-01 to 2012-12-31) (test: 2013-01-01 to 2013-03-31)\n",
      "N train = 3912\n",
      "N val = 432\n",
      "N train+val = 4344\n",
      "N test = 345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name           | Type               | Params\n",
      "------------------------------------------------------\n",
      "0 | encoder_pos    | PositionalEncoding | 0     \n",
      "1 | encoder_expert | TransformerEncoder | 33 M  \n",
      "2 | fc_1           | Linear             | 32 K  \n",
      "3 | fc_2           | Linear             | 33    \n",
      "4 | dropout_1      | Dropout            | 0     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf7c65cc710f4e0ebd36333d4fde6190",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c851b00de5d24e5ea672fa4a94597bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: Uploading stats to Comet before program termination (may take several seconds)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 576.00 MiB (GPU 0; 11.00 GiB total capacity; 8.82 GiB already allocated; 382.94 MiB free; 8.87 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-0d3f406d824a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;31m# train on select periods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[0mtrainer_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myqtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_hparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_hparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer_hparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-c4bf34dc9e96>\u001b[0m in \u001b[0;36mtrainer_one\u001b[1;34m(Model, yqtr, data_hparams, model_hparams, trainer_hparams)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-c4bf34dc9e96>\u001b[0m in \u001b[0;36mtrainer_one\u001b[1;34m(Model, yqtr, data_hparams, model_hparams, trainer_hparams)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m# test on the best model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'on_fit_start'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\accelerators\\dp_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m# train or test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m                 \u001b[1;31m# run train epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 485\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    542\u001b[0m             \u001b[1;31m# TRAINING_STEP + TRAINING_STEP_END\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m             \u001b[1;31m# ------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m             \u001b[0mbatch_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[1;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m                         \u001b[1;31m# optimizer step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    450\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"optimizer_step\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;31m# optimizer step lightningModule hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m             self.trainer.accelerator_backend.optimizer_step(\n\u001b[0m\u001b[0;32m    453\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             )\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\accelerators\\accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, optimizer, batch_idx, opt_idx, lambda_closure)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# model hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         model_ref.optimizer_step(\n\u001b[0m\u001b[0;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\core\\lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m     def optimizer_zero_grad(\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[1;34m()\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m                         \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[0;32m    704\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m                                 \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[1;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[0;32m    796\u001b[0m         \"\"\"\n\u001b[0;32m    797\u001b[0m         \u001b[1;31m# lightning module hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\trainer\\training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model_forward\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_train_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m             \u001b[0mtraining_step_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m             \u001b[0mtraining_step_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_step_end\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_step_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\accelerators\\dp_accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\overrides\\data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mResult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\overrides\\data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\overrides\\data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[1;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\pytorch_lightning\\overrides\\data_parallel.py\u001b[0m in \u001b[0;36m_worker\u001b[1;34m(i, module, input, kwargs, device)\u001b[0m\n\u001b[0;32m    261\u001b[0m                 \u001b[1;31m# CHANGE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 263\u001b[1;33m                     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    264\u001b[0m                     \u001b[0mfx_called\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'training_step'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-dcf96d968b4a>\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, batch, idx)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;31m# traning step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mtranscriptid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_car\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_car\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'y_car'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_car\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m't_car'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mt_car\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-dcf96d968b4a>\u001b[0m in \u001b[0;36mshared_step\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;31m# encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mx_expert\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder_expert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (N, S, E)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# decode with attn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msrc_key_padding_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\transformer.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    291\u001b[0m             \u001b[0msee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mTransformer\u001b[0m \u001b[1;32mclass\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m         \"\"\"\n\u001b[1;32m--> 293\u001b[1;33m         src2 = self.self_attn(src, src, src, attn_mask=src_mask,\n\u001b[0m\u001b[0;32m    294\u001b[0m                               key_padding_mask=src_key_padding_mask)[0]\n\u001b[0;32m    295\u001b[0m         \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msrc\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask)\u001b[0m\n\u001b[0;32m    976\u001b[0m                 v_proj_weight=self.v_proj_weight)\n\u001b[0;32m    977\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             return F.multi_head_attention_forward(\n\u001b[0m\u001b[0;32m    979\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Software\\Anaconda\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v)\u001b[0m\n\u001b[0;32m   4304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkey_padding_mask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4305\u001b[0m         \u001b[0mattn_output_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattn_output_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbsz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4306\u001b[1;33m         attn_output_weights = attn_output_weights.masked_fill(\n\u001b[0m\u001b[0;32m   4307\u001b[0m             \u001b[0mkey_padding_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4308\u001b[0m             \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 576.00 MiB (GPU 0; 11.00 GiB total capacity; 8.82 GiB already allocated; 382.94 MiB free; 8.87 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# choose Model\n",
    "Model = CCTransformerSTLTxt\n",
    "\n",
    "# data hparams\n",
    "data_hparams = {\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded', # key!\n",
    "    'targets_name': 'f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_sentiment_text_norm_wsrz', # key!\n",
    "\n",
    "    'batch_size': 32,\n",
    "    'val_batch_size':32,\n",
    "    'test_batch_size':32,\n",
    "    \n",
    "    'text_in_dataset': True,\n",
    "    'roll_type': '3y', # key!\n",
    "}\n",
    "\n",
    "# hparams\n",
    "model_hparams = {\n",
    "    'max_seq_len': 768, \n",
    "    'learning_rate':3e-4, # key!\n",
    "    'n_layers_encoder': 4,\n",
    "    'n_head_encoder': 16, \n",
    "    'd_model': 1024,\n",
    "    'dff': 2048, # default: 2048\n",
    "    'attn_dropout': 0.1,\n",
    "    # 'dropout': 0.5\n",
    "} \n",
    "\n",
    "# train hparams\n",
    "trainer_hparams = {\n",
    "    # random seed\n",
    "    'seed': 42,    # key\n",
    "    \n",
    "    # gpus\n",
    "    'gpus': [0,1], # key\n",
    "\n",
    "    # last: STL-39\n",
    "    'machine': 'yu-workstation', # key!\n",
    "    'note': f\"STL-50\", # key!\n",
    "    'log_every_n_steps': 10,\n",
    "    'save_top_k': 1,\n",
    "    'val_check_interval': 0.2, # key! (0.25: check 4 times in a epoch)\n",
    "\n",
    "    # data size\n",
    "    'precision': 32, # key!\n",
    "    'overfit_batches': 0.0,\n",
    "    'min_epochs': 3, # default: 3\n",
    "    'max_epochs': 20, # default: 20\n",
    "    'max_steps': None,\n",
    "    'accumulate_grad_batches': 1,\n",
    "\n",
    "    # Caution:\n",
    "    # The check of patience depends on **how often you compute your val_loss** (`val_check_interval`). \n",
    "    # Say you check val every N baches, then `early_stop_callback` will compare to your latest N **baches**.\n",
    "    # If you compute val_loss every N **epoches**, then `early_stop_callback` will compare to the latest N **epochs**.\n",
    "    'early_stop_patience': 8,\n",
    "\n",
    "    # Caution:\n",
    "    # In pervious versions, if you check validatoin multiple times within a epoch,\n",
    "    # you have to set `check_point_period=0`. However, starting from 1.0.7, even if \n",
    "    # you check validation multiples times within an epoch, you still need to set\n",
    "    # `checkpoint_period=1`.\n",
    "    'checkpoint_period': 1}\n",
    "\n",
    "# delete all existing .ckpt files\n",
    "refresh_ckpt()\n",
    "\n",
    "# load split_df\n",
    "load_split_df(data_hparams['roll_type'])\n",
    "    \n",
    "# loop over 24!\n",
    "np.random.seed(trainer_hparams['seed'])\n",
    "torch.manual_seed(trainer_hparams['seed'])\n",
    "\n",
    "\n",
    "# Customize preembeddings\n",
    "\n",
    "\n",
    "for yqtr in split_df.yqtr:\n",
    "\n",
    "    # Enforce yqtr>='2012-q4' (the earliest yqtr in roll_type=='3y')\n",
    "    if yqtr>='2012-q4':\n",
    "\n",
    "        # update current period\n",
    "        data_hparams.update({'yqtr': yqtr})\n",
    "\n",
    "        # train on select periods\n",
    "        train_one(Model, yqtr, data_hparams, model_hparams, trainer_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (MTL, hardshare) car + inf/rev ~ txt + fr\n",
    "class CCTransformerMTLHard(CC):\n",
    "    def __init__(self, hparams):\n",
    "        # `self.hparams` will be created by super().__init__\n",
    "        super().__init__(hparams)\n",
    "        \n",
    "        # check task weights sum to one\n",
    "        assert self.hparams.car_weight+self.hparams.inflow_weight+self.hparams.revision_weight==1, 'car_weight + inflow_weight + revision_weight != 1'\n",
    "        \n",
    "        # specify model type\n",
    "        self.model_type = 'TSFM'\n",
    "        self.target_type = f'{self.hparams.car_weight:.2f}*car+{self.hparams.inflow_weight:.2f}*inf+{self.hparams.revision_weight:.2f}*rev' # key!\n",
    "        self.feature_type = 'txt'    # key!\n",
    "        self.emb_share = 'hard'      # key!\n",
    "        self.normalize_target = True\n",
    "        \n",
    "        self.attn_type = 'dotprod'\n",
    "        self.text_in_dataset = True if self.feature_type!='fr' else False \n",
    "        self.n_covariate = 15\n",
    "        \n",
    "        # positional encoding\n",
    "        self.encoder_pos = PositionalEncoding(self.hparams.d_model, self.hparams.attn_dropout)\n",
    "        \n",
    "        # encoder layers for input, expert, nonexpert\n",
    "        encoder_layers_expert = nn.TransformerEncoderLayer(self.hparams.d_model, self.hparams.n_head_encoder, self.hparams.dff, self.hparams.attn_dropout)\n",
    "        \n",
    "        # atten layers\n",
    "        self.attn_layers_car = nn.Linear(self.hparams.d_model, 1)\n",
    "        self.attn_dropout_1 = nn.Dropout(self.hparams.attn_dropout)\n",
    "        \n",
    "        # Build Encoder\n",
    "        self.encoder_expert = nn.TransformerEncoder(encoder_layers_expert, self.hparams.n_layers_encoder)\n",
    "        \n",
    "        # linear layer to produce final result\n",
    "        self.fc_car_1 = nn.Linear(self.hparams.d_model, 1)\n",
    "        # self.fc_inflow_1 = nn.Linear(self.hparams.d_model, 1)\n",
    "        self.fc_revision_1 = nn.Linear(self.hparams.d_model, 1)\n",
    "        \n",
    "    # forward\n",
    "    def forward(self, embeddings, src_key_padding_mask, fin_ratios):\n",
    "        \n",
    "        # if S is longer than max_seq_len, cut\n",
    "        embeddings = embeddings[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        src_key_padding_mask = src_key_padding_mask[:,:self.hparams.max_seq_len] # (N, S)\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1) # (S, N, E)\n",
    "        \n",
    "        # positional encoding\n",
    "        x = self.encoder_pos(embeddings) # (S, N, E)\n",
    "        \n",
    "        # encode\n",
    "        x_expert = self.encoder_expert(x, src_key_padding_mask=src_key_padding_mask).transpose(0,1) # (N, S, E)\n",
    "        \n",
    "        # aggregate with attn\n",
    "        x_attn = self.attn_dropout_1(F.softmax(self.attn_layers_car(x_expert), dim=1)) # (N, S, 1)\n",
    "        x_expert = torch.bmm(x_expert.transpose(-1,-2), x_attn).squeeze(-1) # (N, E)\n",
    "        \n",
    "        # final FC\n",
    "        y_car = self.fc_car_1(x_expert) # (N, 1)\n",
    "        # y_inflow = self.fc_inflow_1(x_expert) # (N,1)\n",
    "        y_revision = self.fc_revision_1(x_expert)\n",
    "        \n",
    "        # log hist: x_expert\n",
    "        if self.global_step%50==True:\n",
    "            self.logger.experiment.log_histogram_3d(x_expert.detach().cpu().numpy(), name='feature:x_expert', step=self.global_step)\n",
    "            # self.logger.experiment.log_histogram_3d(x_car.detach().cpu().numpy(), name='feature:x_car', step=self.global_step)\n",
    "            # self.logger.experiment.log_histogram_3d(x_inflow.detach().cpu().numpy(), name='feature:x_inflow', step=self.global_step)\n",
    "        \n",
    "        # final output\n",
    "        return y_car, y_revision\n",
    "    \n",
    "    # traning step\n",
    "    def training_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # decide if log activation histogram\n",
    "        # log_histogram = True if idx%50==0 else False\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_revision = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        # loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_revision = self.mse_loss(y_revision, revision_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = self.hparams.car_weight*loss_car + self.hparams.revision_weight*loss_revision\n",
    "        \n",
    "        # logging\n",
    "        return {'loss': loss, 'log': {'trainer_loss': loss}}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_revision = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        # loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_revision = self.mse_loss(y_revision, revision_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = self.hparams.car_weight*loss_car + self.hparams.revision_weight*loss_revision\n",
    "        \n",
    "        # logging\n",
    "        # return {'val_loss': loss, 'val_loss_car': loss_car, 'val_loss_inflow': loss_inflow}\n",
    "        return {'val_loss': loss, 'val_loss_car': loss_car, 'val_loss_revision': loss_revision}\n",
    "\n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_revision = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        # loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_revision = self.mse_loss(y_revision, revision_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = self.hparams.car_weight*loss_car + self.hparams.revision_weight*loss_revision\n",
    "        \n",
    "        # logging\n",
    "        # return {'test_loss': loss, 'test_loss_car': loss_car, 'test_loss_inflow': loss_inflow}  \n",
    "        return {'test_loss': loss, 'test_loss_car': loss_car, 'test_loss_revision': loss_revision}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (MTL, softshare) x*car + (1-x)*inf ~ txt + fr\n",
    "class CCTransformerMTLSoft(CC):\n",
    "    def __init__(self, hparams):\n",
    "        # `self.hparams` will be created by super().__init__\n",
    "        super().__init__(hparams)\n",
    "        \n",
    "        # specify model type\n",
    "        self.model_type = 'TSFM'\n",
    "        self.target_type = 'car+inf'\n",
    "        self.feature_type = 'txt+fr'\n",
    "        self.emb_share = 'hard'\n",
    "        self.normalize_target = True\n",
    "        \n",
    "        self.attn_type = 'dotprod'\n",
    "        self.text_in_dataset = True if self.feature_type!='fr' else False \n",
    "        self.n_covariate = 15\n",
    "        \n",
    "        # positional encoding\n",
    "        self.encoder_pos = PositionalEncoding(self.hparams.d_model, self.hparams.attn_dropout)\n",
    "        \n",
    "        # encoder layers for input, expert, nonexpert\n",
    "        encoder_layers_expert = nn.TransformerEncoderLayer(self.hparams.d_model, self.hparams.n_head_encoder, self.hparams.dff, self.hparams.attn_dropout)\n",
    "        \n",
    "        # atten layers\n",
    "        self.attn_layers_car = nn.Linear(self.hparams.d_model, 1)\n",
    "        self.attn_dropout_1 = nn.Dropout(self.hparams.attn_dropout)\n",
    "        \n",
    "        # Build Encoder\n",
    "        self.encoder_expert = nn.TransformerEncoder(encoder_layers_expert, self.hparams.n_layers_encoder)\n",
    "        \n",
    "        # linear layer to produce final result\n",
    "        self.linear_car_1 = nn.Linear(self.hparams.d_model, self.hparams.d_model)\n",
    "        self.linear_car_2 = nn.Linear(self.hparams.d_model, self.hparams.final_tdim)\n",
    "        self.linear_car_3 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        self.linear_car_4 = nn.Linear(self.hparams.final_tdim+self.n_covariate, self.hparams.final_tdim+self.n_covariate)\n",
    "        self.linear_car_5 = nn.Linear(self.hparams.final_tdim+self.n_covariate, 1)\n",
    "        \n",
    "        self.linear_inflow = nn.Linear(self.hparams.final_tdim, 1)\n",
    "        # self.linear_revision = nn.Linear(hparam.final_tdim, 1)\n",
    "        \n",
    "        # dropout for final fc layers\n",
    "        self.final_dropout_1 = nn.Dropout(self.hparams.dropout)\n",
    "        self.final_dropout_2 = nn.Dropout(self.hparams.dropout)\n",
    "        self.final_dropout_3 = nn.Dropout(self.hparams.dropout)\n",
    "        \n",
    "        # layer normalization\n",
    "        if self.hparams.normalize_layer:\n",
    "            self.layer_norm = nn.LayerNorm(self.hparams.final_tdim+self.n_covariate)\n",
    "            \n",
    "        # batch normalization\n",
    "        if self.hparams.normalize_batch:\n",
    "            self.batch_norm = nn.BatchNorm1d(self.n_covariate)\n",
    "\n",
    "    # forward\n",
    "    def forward(self, embeddings, src_key_padding_mask, fin_ratios):\n",
    "        \n",
    "        # if S is longer than max_seq_len, cut\n",
    "        embeddings = embeddings[:,:self.hparams.max_seq_len,] # (N, S, E)\n",
    "        src_key_padding_mask = src_key_padding_mask[:,:self.hparams.max_seq_len] # (N, S)\n",
    "        \n",
    "        embeddings = embeddings.transpose(0, 1) # (S, N, E)\n",
    "        \n",
    "        # positional encoding\n",
    "        x = self.encoder_pos(embeddings) # (S, N, E)\n",
    "        \n",
    "        # encode\n",
    "        x_expert = self.encoder_expert(x, src_key_padding_mask=src_key_padding_mask).transpose(0,1) # (N, S, E)\n",
    "        \n",
    "        # multiply with attn\n",
    "        x_attn = self.attn_dropout_1(F.softmax(self.attn_layers_car(x_expert), dim=1)) # (N, S, 1)\n",
    "        x_expert = torch.bmm(x_expert.transpose(-1,-2), x_attn).squeeze(-1) # (N, E)\n",
    "        \n",
    "        # mix with covariate\n",
    "        x_expert = self.final_dropout_1(F.relu(self.linear_car_1(x_expert))) # (N, E)\n",
    "        x_expert = F.relu(self.linear_car_2(x_expert)) # (N, final_tdim)\n",
    "        \n",
    "        # batch normalization\n",
    "        if self.hparams.normalize_batch:\n",
    "            fin_ratio = self.batch_norm(fin_ratios)\n",
    "        \n",
    "        x_car = torch.cat([x_expert, fin_ratios], dim=-1) # (N, X + final_tdim) where X is the number of covariate (n_covariate)\n",
    "\n",
    "            \n",
    "        # final FC\n",
    "        y_inflow = self.linear_inflow(x_expert)\n",
    "        # y_revision = self.linear_revision(x_expert)\n",
    "        \n",
    "        x_car = self.final_dropout_2(F.relu(self.linear_car_3(x_car))) # (N, X + final_tdim)\n",
    "        y_car = self.linear_car_5(x_car) # (N,1)\n",
    "        \n",
    "        # final output\n",
    "        return y_car, y_inflow\n",
    "    \n",
    "    # traning step\n",
    "    def training_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_inflow = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        \n",
    "        assert self.hparams.car_weight+self.hparams.inflow_weight==1, 'car_weight + inflow_weight != 1'\n",
    "        \n",
    "        loss = self.hparams.car_weight*loss_car + self.hparams.inflow_weight*loss_inflow\n",
    "        \n",
    "        # logging\n",
    "        return {'loss': loss, 'log': {'trainer_loss': loss}}\n",
    "        \n",
    "    # validation step\n",
    "    def validation_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_inflow = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = loss_car + loss_inflow\n",
    "        \n",
    "        # logging\n",
    "        return {'val_loss': loss, 'val_loss_car': loss_car, 'val_loss_inflow': loss_inflow}\n",
    "\n",
    "    # test step\n",
    "    def test_step(self, batch, idx):\n",
    "        car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "        transcriptid, embeddings, mask, \\\n",
    "        fin_ratios = batch\n",
    "        \n",
    "        # forward\n",
    "        y_car, y_inflow = self.forward(embeddings, mask, fin_ratios) # (N, 1)\n",
    "        \n",
    "        # compute loss\n",
    "        loss_car = self.mse_loss(y_car, car_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        loss_inflow = self.mse_loss(y_inflow, inflow_norm.unsqueeze(-1)).unsqueeze(-1) # (1,)\n",
    "        \n",
    "        loss = loss_car + loss_inflow\n",
    "\n",
    "        # logging\n",
    "        return {'test_loss': loss, 'test_loss_car': loss_car, 'test_loss_inflow': loss_inflow} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# choose Model\n",
    "Model = CCTransformerSTLTxtFr\n",
    "\n",
    "# hparams\n",
    "model_hparams = {\n",
    "    'seed': 42, # key!\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded', # key!\n",
    "    'targets_name': 'f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_sentiment_text_norm_wsrz', # key!\n",
    "    'roll_type': '3y',  # key!\n",
    "    'gpus': [0,1],\n",
    "    \n",
    "    # task weight\n",
    "    'car_weight': 1,      # Key!\n",
    "    'inflow_weight': 0,   # key!\n",
    "    'revision_weight': 0, # key!\n",
    "    \n",
    "    'batch_size': 28,     # key!\n",
    "    'val_batch_size': 28,\n",
    "    'max_seq_len': 768, \n",
    "    'learning_rate':1e-4, # key!\n",
    "    'task_weight': 1,\n",
    "    'n_layers_encoder': 4,\n",
    "    'n_layers_txtmixer': 2, # key!\n",
    "    'n_layers_frmixer': 2,  # key!\n",
    "    'n_layers_finalfc': 2,  # key!\n",
    "    'n_head_encoder': 8, \n",
    "    'd_model': 1024,\n",
    "    'final_tdim': 1024, # key!\n",
    "    'dff': 2048,\n",
    "    'attn_dropout': 0.1,\n",
    "    'dropout': 0.5,\n",
    "    'n_head_decoder': 8} \n",
    "\n",
    "trainer_hparams = {\n",
    "    # log\n",
    "    'machine': 'yu-workstation',  # key!\n",
    "    'note': f\"STL-37,(car~txt+fr 3y BatchNormFr BatchNormTxt),txtMixer=2({model_hparams['final_tdim']}),fcMixer=2,standCAR=yes,standFr=no,bsz={model_hparams['batch_size']},seed={model_hparams['seed']},log(mcap)=yes,lr={model_hparams['learning_rate']:.2g}\", # key!\n",
    "    'row_log_interval': 10,\n",
    "    'save_top_k': 1,\n",
    "    'val_check_interval': 0.2,\n",
    "\n",
    "    # data size\n",
    "    'precision': 32,\n",
    "    'overfit_batches': 0.0,\n",
    "    'min_epochs': 3,\n",
    "    'max_epochs': 20,\n",
    "    'max_steps': None,\n",
    "    'accumulate_grad_batches': 1,\n",
    "\n",
    "    # Caution:\n",
    "    # The check of patience depends on **how often you compute your val_loss** (`val_check_interval`). \n",
    "    # Say you check val every N baches, then `early_stop_callback` will compare to your latest N **baches**.\n",
    "    # If you compute val_loss every N **epoches**, then `early_stop_callback` will compare to the latest N **epochs**.\n",
    "    'early_stop_patience': 8,\n",
    "\n",
    "    # Caution:\n",
    "    # If set to 1, then save ckpt every 1 epoch\n",
    "    # If set to 0, then save ckpt on every val!!! (if val improves)\n",
    "    'checkpoint_period': 0}\n",
    "\n",
    "# delete all existing .ckpt files\n",
    "refresh_ckpt()\n",
    "\n",
    "# load split_df\n",
    "load_split_df(model_hparams['roll_type'])\n",
    "    \n",
    "# load targets_df\n",
    "load_targets(model_hparams['targets_name'])\n",
    "\n",
    "# load preembeddings\n",
    "load_preembeddings(model_hparams['preembedding_type'])\n",
    "    \n",
    "# loop over 24!\n",
    "np.random.seed(model_hparams['seed'])\n",
    "torch.manual_seed(model_hparams['seed'])\n",
    "\n",
    "for window_i in range(len(split_df)):\n",
    "\n",
    "    # train one window\n",
    "    trainer_one(Model, window_i, model_hparams, trainer_hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hparams = {\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded', # key!\n",
    "    'targets_name': 'f_sue_keydevid_car_finratio_vol_transcriptid_sim_inflow_revision_text_norm', # key!\n",
    "    'roll_type': '3y',  # key!\n",
    "}    \n",
    "\n",
    "# load split_df\n",
    "load_split_df(data_hparams['roll_type'])\n",
    "    \n",
    "# load targets_df\n",
    "load_targets(model_hparams['targets_name'])\n",
    "\n",
    "# load preembeddings\n",
    "load_preembeddings(model_hparams['preembedding_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current window: roll-01 (3y) \n",
      "(train: 2008-01-01 to 2010-12-31) (test: 2011-01-01 to 2011-03-31)\n"
     ]
    }
   ],
   "source": [
    "model = CCTransformerMTLInfHard.load_from_checkpoint('D:/Checkpoints/earnings-call/3y-TSFM-(0.5car+0.5inf~txt+fr)-hardshare-norm/TSFM_roll-01_epoch=9_v0.ckpt')\n",
    "\n",
    "model.freeze()\n",
    "\n",
    "model.prepare_data()\n",
    "dataloader = model.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extractor = torch.nn.Sequential(*list(model.children())[:-8])\n",
    "\n",
    "for i, batch in enumerate(tqdm(dataloader)):\n",
    "    if i > 1: break\n",
    "    car, car_norm, inflow, inflow_norm, revision, revision_norm, \\\n",
    "    transcriptid, embeddings, mask, \\\n",
    "    fin_ratios = batch\n",
    "\n",
    "    # forward\n",
    "    output = extractor(embeddings, mask, fin_ratios)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test on one batch\n",
    "def test_step_fr(model, batch):\n",
    "    # get input\n",
    "    docid, car, inp = batch\n",
    "\n",
    "    # forward\n",
    "    y_car = model(inp).item() # (N, 1)\n",
    "\n",
    "    return y_car, docid[0]\n",
    "    \n",
    "    \n",
    "def test_step_text(model, batch):\n",
    "    car, transcriptid, embeddings, mask, alpha, car_m1_m1, car_m2_m2, car_m30_m3,\\\n",
    "    sest, sue, numest, sstdest, smedest, \\\n",
    "    mcap, roa, bm, debt_asset, volatility, volume = batch\n",
    "\n",
    "    # forward\n",
    "    y_car = model(embeddings, mask).item() # (N, 1)\n",
    "    transcriptid = transcriptid.int().item()\n",
    "    docid = targets_df.loc[targets_df.transcriptid==transcriptid].docid.iloc[0]\n",
    "\n",
    "    return y_car, docid\n",
    "\n",
    "def test_step_text_fr(model, batch):\n",
    "    car, transcriptid, embeddings, mask, alpha, car_m1_m1, car_m2_m2, car_m30_m3,\\\n",
    "    sest, sue, numest, sstdest, smedest, \\\n",
    "    mcap, roa, bm, debt_asset, volatility, volume = batch\n",
    "\n",
    "    # forward\n",
    "    y_car = model(embeddings, mask, alpha, car_m1_m1, car_m2_m2, car_m30_m3, sest, sue, numest, sstdest, \\\n",
    "                  smedest, mcap, roa, bm, debt_asset, volatility, volume).item() # (N, 1)\n",
    "    transcriptid = transcriptid.int().item()\n",
    "    docid = targets_df.loc[targets_df.transcriptid==transcriptid].docid.iloc[0]\n",
    "\n",
    "    return y_car, docid\n",
    "\n",
    "# test on one window\n",
    "def test_one_window(model, dataloader):\n",
    "    # select test_step\n",
    "    if type(model) in [CCMLP]:\n",
    "        test_step = test_step_fr\n",
    "    elif type(model) in [CCTransformerSTLTxtFr]:\n",
    "        test_step = test_step_text_fr\n",
    "    # elif type(model) in [CCTransformerSTLTxtFr]:\n",
    "    #    test_step = test_step_text_fr\n",
    "    \n",
    "    ys = []\n",
    "    for i, batch in enumerate(tqdm(dataloader)):\n",
    "        ys.append(test_step(model, batch))\n",
    "        # if i>=2: break\n",
    "    return pd.DataFrame(ys, columns=['y_car', 'docid'])\n",
    "\n",
    "# get prediction\n",
    "def predict_car():\n",
    "    global hparams\n",
    "    hparams = Namespace(**hparams)\n",
    "\n",
    "    # get roll_type\n",
    "    hparams.roll_type = hparams.ckpt_folder.split('/')[-1].split('-')[0]\n",
    "    \n",
    "    # load split_df\n",
    "    load_split_df(hparams.roll_type)\n",
    "\n",
    "    # load targets_df\n",
    "    load_targets(hparams.targets_name)\n",
    "\n",
    "    # load preembedding\n",
    "    load_preembeddings(hparams.preembedding_type)\n",
    "    \n",
    "    car_prediction = []\n",
    "    for i, name in enumerate(sorted(os.listdir(f'D:/Checkpoints/earnings-call/{hparams.ckpt_folder}'))):\n",
    "        # if i>=1: break\n",
    "            \n",
    "        if name.endswith('.ckpt'):\n",
    "\n",
    "            # get window\n",
    "            window = re.search(r'roll-\\d{2}', name).group()\n",
    "\n",
    "            # load model\n",
    "            model = hparams.Model.load_from_checkpoint(f'D:/Checkpoints/earnings-call/{hparams.ckpt_folder}/{name}')\n",
    "\n",
    "            # get testloader\n",
    "            model.prepare_data()\n",
    "            test_dataloader = model.test_dataloader()\n",
    "            model.freeze()\n",
    "            \n",
    "            # predict\n",
    "            y = test_one_window(model, test_dataloader)\n",
    "            y['window'] = window\n",
    "            y['roll_type'] = hparams.roll_type\n",
    "\n",
    "            # append to ys\n",
    "            car_prediction.append(y)\n",
    "    car_prediction = pd.concat(car_prediction)\n",
    "    \n",
    "    car_prediction.reset_index().to_feather(f'data/{hparams.save_name}.feather')\n",
    "    return car_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'Model': CCTransformerSTLTxtFr, # key!\n",
    "    'ckpt_folder': '3y-TSFM-txt-fr', # key!\n",
    "    'save_name': 'car_pred_tsfm_txt_fr', # key!\n",
    "\n",
    "    'targets_name': 'f_sue_keydevid_car_finratio_vol_transcriptid_sim_text',\n",
    "    'preembedding_type': 'all_sbert_roberta_nlistsb_encoded',\n",
    "}\n",
    "\n",
    "# get car_ranking_predict\n",
    "car_pred_mlp = predict_car()\n",
    "\n",
    "# car_pred_mlp.reset_index().to_feather('data/car_pred_mlp.feather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_car</th>\n",
       "      <th>docid</th>\n",
       "      <th>window</th>\n",
       "      <th>roll_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>15.298223</td>\n",
       "      <td>031122-2011-01-10</td>\n",
       "      <td>roll-01</td>\n",
       "      <td>3y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         y_car              docid   window roll_type\n",
       "224  15.298223  031122-2011-01-10  roll-01        3y"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "car_pred_mlp.loc[car_pred_mlp.docid=='031122-2011-01-10']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "incorrectly_encoded_metadata": "toc-hr-collapsed=true toc-nb-collapsed=true"
   },
   "source": [
    "### `val` is after `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Txt + Fin-ratio\n",
    "class CCDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, split_window, split_type, text_in_dataset, roll_type, print_window, valid_transcriptids=None, transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "            preembeddings (from globals): list of embeddings. Each element is a tensor (S, E) where S is number of sentences in a call\n",
    "            targets_df (from globals): DataFrame of targets variables.\n",
    "            split_df (from globals):\n",
    "            split_window: str. e.g., \"roll-09\"\n",
    "            split_type: str. 'train' or 'test'\n",
    "            text_only: only output CAR and transcripts if true, otherwise also output financial ratios\n",
    "            transcriptids: list. If provided, only the given transcripts will be used in generating the Dataset. `transcriptids` is applied **on top of** `split_window` and `split_type`\n",
    "        '''\n",
    "\n",
    "        self.text_in_dataset = text_in_dataset\n",
    "        \n",
    "        # decalre data as globals so don't   need to create/reload\n",
    "        global preembeddings, targets_df, split_df\n",
    "        \n",
    "        # get split dates from `split_df`\n",
    "        _, train_start, train_end, val_start, val_end, test_start, test_end, _ = tuple(split_df.loc[(split_df.window==split_window) & (split_df.roll_type==roll_type)].iloc[0])\n",
    "        # print current window\n",
    "        print(f'Current window: {split_window} ({roll_type}) \\n(train: {train_start} to {train_end}) (val: {val_start} to {val_end}) (test: {test_start} to {test_end})')\n",
    "        \n",
    "        train_start = datetime.strptime(train_start, '%Y-%m-%d').date()\n",
    "        train_end = datetime.strptime(train_end, '%Y-%m-%d').date()\n",
    "        val_start = datetime.strptime(val_start, '%Y-%m-%d').date()\n",
    "        val_end = datetime.strptime(val_end, '%Y-%m-%d').date()\n",
    "        test_start = datetime.strptime(test_start, '%Y-%m-%d').date()\n",
    "        test_end = datetime.strptime(test_end, '%Y-%m-%d').date()\n",
    "        \n",
    "        # select valid transcriptids (preemb_keys) according to split dates \n",
    "        if split_type=='train':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(train_start, train_end)].transcriptid.tolist()\n",
    "        if split_type=='val':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(val_start, val_end)].transcriptid.tolist()\n",
    "        elif split_type=='test':\n",
    "            transcriptids = targets_df[targets_df.ciq_call_date.between(test_start, test_end)].transcriptid.tolist()\n",
    "\n",
    "        self.valid_preemb_keys = set(transcriptids).intersection(set(preembeddings.keys()))\n",
    "        \n",
    "        if valid_transcriptids is not None:\n",
    "            self.valid_preemb_keys = self.valid_preemb_keys.intersection(set(valid_transcriptids))\n",
    "        \n",
    "        # self attributes\n",
    "        self.targets_df = targets_df\n",
    "        self.preembeddings = preembeddings\n",
    "        self.transform = transform\n",
    "        self.sent_len = sorted([(k, preembeddings[k].shape[0]) for k in self.valid_preemb_keys], key=itemgetter(1))\n",
    "        self.train_start = train_start\n",
    "        self.train_end = train_end\n",
    "        self.test_start = test_start\n",
    "        self.test_end = test_end\n",
    "        self.n_samples = len(self.sent_len)\n",
    "        self.split_window = split_window\n",
    "        self.split_type = split_type\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (len(self.valid_preemb_keys))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "            \n",
    "        transcriptid = self.sent_len[idx][0]\n",
    "        targets = self.targets_df[self.targets_df.transcriptid==transcriptid].iloc[0]\n",
    "        \n",
    "        # inputs: preembeddings\n",
    "        embeddings = self.preembeddings[transcriptid]\n",
    "        \n",
    "        # all of the following targests are\n",
    "        # of type `numpy.float64`\n",
    "        sue = targets.sue\n",
    "        sest = targets.sest\n",
    "        car_0_30 = targets.car_0_30\n",
    "        \n",
    "        alpha = targets.alpha\n",
    "        volatility = targets.volatility\n",
    "        mcap = targets.mcap/1e6\n",
    "        bm = targets.bm\n",
    "        roa = targets.roa\n",
    "        debt_asset = targets.debt_asset\n",
    "        numest = targets.numest\n",
    "        smedest = targets.smedest\n",
    "        sstdest = targets.sstdest\n",
    "        car_m1_m1 = targets.car_m1_m1\n",
    "        car_m2_m2 = targets.car_m2_m2\n",
    "        car_m30_m3 = targets.car_m30_m3\n",
    "        volume = targets.volume\n",
    "        \n",
    "        if self.text_in_dataset:\n",
    "            return car_0_30, transcriptid, embeddings, alpha, car_m1_m1, car_m2_m2, car_m30_m3, \\\n",
    "                   sest, sue, numest, sstdest, smedest, \\\n",
    "                   mcap, roa, bm, debt_asset, volatility, volume\n",
    "        else:\n",
    "            return torch.tensor(car_0_30,dtype=torch.float32), \\\n",
    "                   torch.tensor([alpha, car_m1_m1, car_m2_m2, car_m30_m3, sest, sue, numest, sstdest, smedest, mcap, roa, bm, debt_asset, volatility, volume], dtype=torch.float32)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
